<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LiuYang&#39;s BLOG</title>
  
  <subtitle>On the way to become a Software Architect</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://runnerliu.github.io/"/>
  <updated>2021-07-10T12:42:14.983Z</updated>
  <id>http://runnerliu.github.io/</id>
  
  <author>
    <name>william</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python functools系列 - lru_cache</title>
    <link href="http://runnerliu.github.io/2021/07/10/py-functools-cache/"/>
    <id>http://runnerliu.github.io/2021/07/10/py-functools-cache/</id>
    <published>2021-07-10T09:47:40.000Z</published>
    <updated>2021-07-10T12:42:14.983Z</updated>
    
    <content type="html"><![CDATA[<p>缓存在实际开发工作中的应用是非常常见的，比如内存缓存、redis缓存、本地文件缓存等，其主要的目的是方便数据的下一次访问，减少应用程序重复计算的次数和资源消耗，缓存是一种典型的空间换时间的方案。那么我们就来看看在开发Python程序时，functools提供的 <a href="https://docs.python.org/zh-cn/3/library/functools.html" target="_blank" rel="noopener">cache</a> 装饰器是如何工作的。</p><h3 id="从一个小例子开始"><a href="#从一个小例子开始" class="headerlink" title="从一个小例子开始"></a>从一个小例子开始</h3><p>首先我们看一下阶乘的实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def factorial(n):</span><br><span class="line">    print(&apos;compute: &#123;&#125;&apos;.format(n))</span><br><span class="line">    return n * factorial(n - 1) if n else 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a = factorial(5)</span><br><span class="line">print(a)</span><br><span class="line">b = factorial(10)</span><br><span class="line">print(b)</span><br><span class="line"></span><br><span class="line">compute: 5</span><br><span class="line">compute: 4</span><br><span class="line">compute: 3</span><br><span class="line">compute: 2</span><br><span class="line">compute: 1</span><br><span class="line">compute: 0</span><br><span class="line">120</span><br><span class="line">compute: 10</span><br><span class="line">compute: 9</span><br><span class="line">compute: 8</span><br><span class="line">compute: 7</span><br><span class="line">compute: 6</span><br><span class="line">compute: 5</span><br><span class="line">compute: 4</span><br><span class="line">compute: 3</span><br><span class="line">compute: 2</span><br><span class="line">compute: 1</span><br><span class="line">compute: 0</span><br><span class="line">3628800</span><br></pre></td></tr></table></figure><p>我们分别计算了 <code>5！</code> 和 <code>10！</code> ，从程序的运行输出看，在计算 <code>10!</code> 时，把 <code>5!</code> 重复计算了一遍，在计算阶乘数字较小的情况下是没问题的，但是当阶乘数非常大时，重复的计算会占用CPU很多资源，而这些重复的计算完全是没必要的，那我们会想到实现一个缓存，将计算过的数据存起来，当下次请求时直接返回。</p><h3 id="实现一个缓存"><a href="#实现一个缓存" class="headerlink" title="实现一个缓存"></a>实现一个缓存</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">class MyCache(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.cache = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    def get_cache(self, key) -&gt; object:</span><br><span class="line">        return self.cache.get(key, None)</span><br><span class="line"></span><br><span class="line">    def set_cache(self, key, value) -&gt; bool:</span><br><span class="line">        if key not in self.cache:</span><br><span class="line">            self.cache[key] = value</span><br><span class="line">        return True</span><br><span class="line"></span><br><span class="line">    def is_in_cache(self, key: str) -&gt; bool:</span><br><span class="line">        return key in self.cache</span><br><span class="line"></span><br><span class="line">    def get_all_cache(self) -&gt; dict:</span><br><span class="line">        return self.cache</span><br><span class="line"></span><br><span class="line">def factorial(n: int, cache: MyCache):</span><br><span class="line">    print(&apos;compute: &#123;&#125;&apos;.format(n))</span><br><span class="line">    if cache.is_in_cache(n):</span><br><span class="line">        print(&apos;hit cache: &#123;&#125;&apos;.format(n))</span><br><span class="line">        return cache.get_cache(n)</span><br><span class="line">    tmp = n * factorial(n - 1, cache) if n else 1</span><br><span class="line">    cache.set_cache(n, tmp)</span><br><span class="line">    return tmp</span><br><span class="line"></span><br><span class="line">cache = MyCache()</span><br><span class="line">a = factorial(5, cache)</span><br><span class="line">print(a)</span><br><span class="line">b = factorial(10, cache)</span><br><span class="line">print(b)</span><br><span class="line">c = factorial(4, cache)</span><br><span class="line">print(c)</span><br><span class="line">print(cache.get_all_cache())</span><br></pre></td></tr></table></figure><p>我们简单实现了一个缓存类，使用了 <code>dict</code> 数据类型，存储了中间的计算结果，我们看下输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">compute: 5</span><br><span class="line">compute: 4</span><br><span class="line">compute: 3</span><br><span class="line">compute: 2</span><br><span class="line">compute: 1</span><br><span class="line">compute: 0</span><br><span class="line">120</span><br><span class="line">compute: 10</span><br><span class="line">compute: 9</span><br><span class="line">compute: 8</span><br><span class="line">compute: 7</span><br><span class="line">compute: 6</span><br><span class="line">compute: 5</span><br><span class="line">hit cache: 5</span><br><span class="line">3628800</span><br><span class="line">compute: 4</span><br><span class="line">hit cache: 4</span><br><span class="line">24</span><br><span class="line">&#123;0: 1, 1: 1, 2: 2, 3: 6, 4: 24, 5: 120, 6: 720, 7: 5040, 8: 40320, 9: 362880, 10: 3628800&#125;</span><br></pre></td></tr></table></figure><p> 从输出能看出，<code>5!</code> 和 <code>4!</code> 都命中了缓存，直接拿到了结果，这就节省了CPU的计算资源，当然，如果数据量很小，就没有必要使用缓存了。</p><h3 id="functools中的lru-cache"><a href="#functools中的lru-cache" class="headerlink" title="functools中的lru_cache"></a>functools中的lru_cache</h3><p>从3.2版本开始，Python的functools模块提供了 <code>lru_cache</code> 函数，用于缓存计算的中间结果，函数定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@functools.lru_cache(user_function)</span><br><span class="line">@functools.lru_cache(maxsize=128, typed=False)</span><br></pre></td></tr></table></figure><p>一个为函数提供缓存功能的装饰器，缓存 <code>maxsize</code> 传入参数，在下次以相同参数调用时直接返回上一次的结果。用以节约高开销或I/O函数的调用时间。由于使用了字典存储缓存，所以该函数的固定参数和关键字参数必须是可哈希的。</p><p>不同模式的参数可能被视为不同从而产生多个缓存项，例如, f(a=1, b=2) 和 f(b=2, a=1) 因其参数顺序不同，可能会被缓存两次。</p><p>如果指定了 <code>user_function</code>，它必须是一个可调用对象。 这允许 <code>lru_cache</code> 装饰器被直接应用于一个用户自定义函数，<code>maxsize</code> 默认值为128。</p><p>我们使用这个装饰器重写一下上边的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">from functools import lru_cache</span><br><span class="line"></span><br><span class="line">@lru_cache(None)</span><br><span class="line">def factorial(n: int):</span><br><span class="line">    return n * factorial(n - 1) if n else 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a = factorial(5)</span><br><span class="line">print(a)</span><br><span class="line">b = factorial(10)</span><br><span class="line">print(b)</span><br><span class="line">c = factorial(4)</span><br><span class="line">print(c)</span><br><span class="line"></span><br><span class="line">print(factorial.cache_info())</span><br><span class="line"></span><br><span class="line">120</span><br><span class="line">3628800</span><br><span class="line">24</span><br><span class="line">CacheInfo(hits=2, misses=11, maxsize=None, currsize=11)</span><br></pre></td></tr></table></figure><p>从输出可以看到，<code>hits=2</code> 表示命中了2次缓存。</p><p>那我们就来看下这个装饰器的实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">def lru_cache(maxsize=128, typed=False):</span><br><span class="line">    &quot;&quot;&quot;Least-recently-used cache decorator.</span><br><span class="line"></span><br><span class="line">    If *maxsize* is set to None, the LRU features are disabled and the cache</span><br><span class="line">    can grow without bound.</span><br><span class="line"></span><br><span class="line">    If *typed* is True, arguments of different types will be cached separately.</span><br><span class="line">    For example, f(3.0) and f(3) will be treated as distinct calls with</span><br><span class="line">    distinct results.</span><br><span class="line"></span><br><span class="line">    Arguments to the cached function must be hashable.</span><br><span class="line"></span><br><span class="line">    View the cache statistics named tuple (hits, misses, maxsize, currsize)</span><br><span class="line">    with f.cache_info().  Clear the cache and statistics with f.cache_clear().</span><br><span class="line">    Access the underlying function with f.__wrapped__.</span><br><span class="line"></span><br><span class="line">    See:  http://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # Users should only access the lru_cache through its public API:</span><br><span class="line">    #       cache_info, cache_clear, and f.__wrapped__</span><br><span class="line">    # The internals of the lru_cache are encapsulated for thread safety and</span><br><span class="line">    # to allow the implementation to change (including a possible C version).</span><br><span class="line"></span><br><span class="line">    # Early detection of an erroneous call to @lru_cache without any arguments</span><br><span class="line">    # resulting in the inner function being passed to maxsize instead of an</span><br><span class="line">    # integer or None.  Negative maxsize is treated as 0.</span><br><span class="line">    if isinstance(maxsize, int):</span><br><span class="line">        if maxsize &lt; 0:</span><br><span class="line">            maxsize = 0</span><br><span class="line">    elif maxsize is not None:</span><br><span class="line">        raise TypeError(&apos;Expected maxsize to be an integer or None&apos;)</span><br><span class="line"></span><br><span class="line">    def decorating_function(user_function):</span><br><span class="line">        wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo)</span><br><span class="line">        return update_wrapper(wrapper, user_function)</span><br><span class="line"></span><br><span class="line">    return decorating_function</span><br></pre></td></tr></table></figure><p>如果 <code>maxsize</code> 设为 <code>None</code>，LRU 特性将被禁用且缓存可无限增长。</p><p>如果 <code>typed</code> 设置为true，不同类型的函数参数将被分别缓存。例如， <code>f(3)</code> 和 <code>f(3.0)</code> 将被视为不同而分别缓存。</p><p>被装饰的函数带有一个 <code>cache_info()</code> 函数。当调用 <code>cache_info()</code> 函数时，返回一个具名元组，包含命中次数 <code>hits</code>，未命中次数 <code>misses</code> ，最大缓存数量 <code>maxsize</code> 和 当前缓存大小 <code>currsize</code>。在多线程环境中，命中数与未命中数是不完全准确的。</p><p>该装饰器也提供了一个用于清理/使缓存失效的函数 <code>cache_clear()</code> 。</p><p>原始的未经装饰的函数可以通过 <code>__wrapped__</code> 属性访问。它可以用于检查、绕过缓存，或使用不同的缓存再次装饰原始函数。</p><p><a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU" target="_blank" rel="noopener">LRU（最久未使用算法）缓存</a>) 在最近的调用是即将到来的调用的最佳预测值时性能最好（例如，新闻服务器上最热门文章倾向于每天更改）。 缓存的大小限制可确保缓存不会在长期运行进程如网站服务器上无限制地增长。</p><p>下面我们再看下 <code>_lru_cache_wrapper</code> 的具体实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line">def _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo):</span><br><span class="line">    # Constants shared by all lru cache instances:</span><br><span class="line">    sentinel = object()          # unique object used to signal cache misses</span><br><span class="line">    make_key = _make_key         # build a key from the function arguments</span><br><span class="line">    PREV, NEXT, KEY, RESULT = 0, 1, 2, 3   # names for the link fields</span><br><span class="line"></span><br><span class="line">    cache = &#123;&#125;</span><br><span class="line">    hits = misses = 0</span><br><span class="line">    full = False</span><br><span class="line">    cache_get = cache.get    # bound method to lookup a key or return None</span><br><span class="line">    cache_len = cache.__len__  # get cache size without calling len()</span><br><span class="line">    lock = RLock()           # because linkedlist updates aren&apos;t threadsafe</span><br><span class="line">    root = []                # root of the circular doubly linked list</span><br><span class="line">    root[:] = [root, root, None, None]     # initialize by pointing to self</span><br><span class="line"></span><br><span class="line">    if maxsize == 0:</span><br><span class="line"></span><br><span class="line">        def wrapper(*args, **kwds):</span><br><span class="line">            # No caching -- just a statistics update</span><br><span class="line">            nonlocal misses</span><br><span class="line">            misses += 1</span><br><span class="line">            result = user_function(*args, **kwds)</span><br><span class="line">            return result</span><br><span class="line"></span><br><span class="line">    elif maxsize is None:</span><br><span class="line"></span><br><span class="line">        def wrapper(*args, **kwds):</span><br><span class="line">            # Simple caching without ordering or size limit</span><br><span class="line">            nonlocal hits, misses</span><br><span class="line">            key = make_key(args, kwds, typed)</span><br><span class="line">            result = cache_get(key, sentinel)</span><br><span class="line">            if result is not sentinel:</span><br><span class="line">                hits += 1</span><br><span class="line">                return result</span><br><span class="line">            misses += 1</span><br><span class="line">            result = user_function(*args, **kwds)</span><br><span class="line">            cache[key] = result</span><br><span class="line">            return result</span><br><span class="line"></span><br><span class="line">    else:</span><br><span class="line"></span><br><span class="line">        def wrapper(*args, **kwds):</span><br><span class="line">            # Size limited caching that tracks accesses by recency</span><br><span class="line">            nonlocal root, hits, misses, full</span><br><span class="line">            key = make_key(args, kwds, typed)</span><br><span class="line">            with lock:</span><br><span class="line">                link = cache_get(key)</span><br><span class="line">                if link is not None:</span><br><span class="line">                    # Move the link to the front of the circular queue</span><br><span class="line">                    link_prev, link_next, _key, result = link</span><br><span class="line">                    link_prev[NEXT] = link_next</span><br><span class="line">                    link_next[PREV] = link_prev</span><br><span class="line">                    last = root[PREV]</span><br><span class="line">                    last[NEXT] = root[PREV] = link</span><br><span class="line">                    link[PREV] = last</span><br><span class="line">                    link[NEXT] = root</span><br><span class="line">                    hits += 1</span><br><span class="line">                    return result</span><br><span class="line">                misses += 1</span><br><span class="line">            result = user_function(*args, **kwds)</span><br><span class="line">            with lock:</span><br><span class="line">                if key in cache:</span><br><span class="line">                    # Getting here means that this same key was added to the</span><br><span class="line">                    # cache while the lock was released.  Since the link</span><br><span class="line">                    # update is already done, we need only return the</span><br><span class="line">                    # computed result and update the count of misses.</span><br><span class="line">                    pass</span><br><span class="line">                elif full:</span><br><span class="line">                    # Use the old root to store the new key and result.</span><br><span class="line">                    oldroot = root</span><br><span class="line">                    oldroot[KEY] = key</span><br><span class="line">                    oldroot[RESULT] = result</span><br><span class="line">                    # Empty the oldest link and make it the new root.</span><br><span class="line">                    # Keep a reference to the old key and old result to</span><br><span class="line">                    # prevent their ref counts from going to zero during the</span><br><span class="line">                    # update. That will prevent potentially arbitrary object</span><br><span class="line">                    # clean-up code (i.e. __del__) from running while we&apos;re</span><br><span class="line">                    # still adjusting the links.</span><br><span class="line">                    root = oldroot[NEXT]</span><br><span class="line">                    oldkey = root[KEY]</span><br><span class="line">                    oldresult = root[RESULT]</span><br><span class="line">                    root[KEY] = root[RESULT] = None</span><br><span class="line">                    # Now update the cache dictionary.</span><br><span class="line">                    del cache[oldkey]</span><br><span class="line">                    # Save the potentially reentrant cache[key] assignment</span><br><span class="line">                    # for last, after the root and links have been put in</span><br><span class="line">                    # a consistent state.</span><br><span class="line">                    cache[key] = oldroot</span><br><span class="line">                else:</span><br><span class="line">                    # Put result in a new link at the front of the queue.</span><br><span class="line">                    last = root[PREV]</span><br><span class="line">                    link = [last, root, key, result]</span><br><span class="line">                    last[NEXT] = root[PREV] = cache[key] = link</span><br><span class="line">                    # Use the cache_len bound method instead of the len() function</span><br><span class="line">                    # which could potentially be wrapped in an lru_cache itself.</span><br><span class="line">                    full = (cache_len() &gt;= maxsize)</span><br><span class="line">            return result</span><br><span class="line"></span><br><span class="line">    def cache_info():</span><br><span class="line">        &quot;&quot;&quot;Report cache statistics&quot;&quot;&quot;</span><br><span class="line">        with lock:</span><br><span class="line">            return _CacheInfo(hits, misses, maxsize, cache_len())</span><br><span class="line"></span><br><span class="line">    def cache_clear():</span><br><span class="line">        &quot;&quot;&quot;Clear the cache and cache statistics&quot;&quot;&quot;</span><br><span class="line">        nonlocal hits, misses, full</span><br><span class="line">        with lock:</span><br><span class="line">            cache.clear()</span><br><span class="line">            root[:] = [root, root, None, None]</span><br><span class="line">            hits = misses = 0</span><br><span class="line">            full = False</span><br><span class="line"></span><br><span class="line">    wrapper.cache_info = cache_info</span><br><span class="line">    wrapper.cache_clear = cache_clear</span><br><span class="line">    return wrapper</span><br></pre></td></tr></table></figure><p>函数根据 <code>maxsize</code> 不同，定义不同的 <code>wrapper</code>。</p><ul><li><code>maxsize == 0</code>，其实也就是没有缓存，那么每次函数调用都不会命中，并且没有命中的次数 <code>misses</code> 加 1。</li><li><code>maxsize is None</code>，不限制缓存大小，如果函数调用不命中，将没有命中次数 <code>misses</code> 加 1，否则将命中次数 <code>hits</code> 加 1。</li><li>限制缓存的大小，那么需要根据 LRU 算法来更新 <code>cache</code><ul><li>如果缓存命中 key，那么将命中节点移到双向循环链表的结尾，<code>hits += 1</code> ，并且返回结果。<strong>这里通过字典加双向循环链表的组合数据结构，实现了用 O(1) 的时间复杂度删除给定的节点。</strong></li><li>如果没有命中，并且缓存满了，那么需要将最久没有使用的节点（root 的下一个节点）删除，并且将新的节点添加到链表结尾。在实现中有一个优化，直接将当前的 root 的 key 和 result 替换成新的值，将 root 的下一个节点置为新的 root，这样得到的双向循环链表结构跟删除 root 的下一个节点并且将新节点加到链表结尾是一样的，但是避免了删除和添加节点的操作</li><li>如果没有命中，并且缓存没满，那么直接将新节点添加到双向循环链表的开头</li></ul></li></ul><p>最后给 <code>wrapper</code> 添加两个属性函数 <code>cache_info</code> 和 <code>cache_clear</code>，<code>cache_info</code> 显示当前缓存的命中情况的统计数据，<code>cache_clear</code> 用于清空缓存。</p><p>最后需要说明的是，<strong>对于有多个关键字参数的函数，如果两次调用函数关键字参数传入的顺序不同，会被认为是不同的调用，不会命中缓存。另外，被 lru_cache 装饰的函数不能包含可变类型参数如 list，因为它们不支持 hash。</strong></p><p>Read More:</p><blockquote><p><a href="https://docs.python.org/zh-cn/3/library/functools.html" target="_blank" rel="noopener">functools — 高阶函数和可调用对象上的操作</a></p><p><a href="https://www.cnblogs.com/zikcheng/p/14322577.html" target="_blank" rel="noopener">Python 中 lru_cache 的使用和实现</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;缓存在实际开发工作中的应用是非常常见的，比如内存缓存、redis缓存、本地文件缓存等，其主要的目的是方便数据的下一次访问，减少应用程序重复计算的次数和资源消耗，缓存是一种典型的空间换时间的方案。那么我们就来看看在开发Python程序时，functools提供的 &lt;a hre
      
    
    </summary>
    
      <category term="Python" scheme="http://runnerliu.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="http://runnerliu.github.io/tags/Python/"/>
    
      <category term="functools" scheme="http://runnerliu.github.io/tags/functools/"/>
    
      <category term="lru_cache" scheme="http://runnerliu.github.io/tags/lru-cache/"/>
    
  </entry>
  
  <entry>
    <title>HTTPS的加密原理</title>
    <link href="http://runnerliu.github.io/2021/07/04/https/"/>
    <id>http://runnerliu.github.io/2021/07/04/https/</id>
    <published>2021-07-04T10:25:34.000Z</published>
    <updated>2021-07-04T13:31:47.455Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为什么需要加密？"><a href="#为什么需要加密？" class="headerlink" title="为什么需要加密？"></a>为什么需要加密？</h3><p>因为HTTP的内容是明文传输的，明文数据会经过中间代理服务器、路由器、WIFI热点、通信服务运营商等多个物理节点，如果信息在传输过程中被劫持，传输的内容就完全暴露了。劫持者还可以篡改传输的信息且不被双方察觉，这就是<code>中间人攻击</code>。所以我们才需要对信息进行加密。最容易理解的就是<code>对称加密</code> 。</p><h3 id="什么是对称加密？"><a href="#什么是对称加密？" class="headerlink" title="什么是对称加密？"></a>什么是对称加密？</h3><p>简单说就是有一个密钥，它可以加密一段信息，也可以对加密后的信息进行解密，和我们日常生活中用的钥匙作用差不多。</p><p><img src="/images/2021-7-4182803.png" alt="2021-7-4182803.png"></p><h3 id="用对称加密可行吗？"><a href="#用对称加密可行吗？" class="headerlink" title="用对称加密可行吗？"></a>用对称加密可行吗？</h3><p><strong>如果通信双方都各自持有同一个密钥，且没有别人知道，这两方的通信安全当然是可以被保证的（除非密钥被破解）。</strong></p><p>然而最大的问题就是<strong>这个密钥怎么让传输的双方知晓，同时不被别人知道</strong>。如果由服务器生成一个密钥并传输给浏览器，那在这个传输过程中密钥被别人劫持到手了怎么办？之后他就能用密钥解开双方传输的任何内容了，所以这么做当然不行。</p><p>换种思路？试想一下，如果浏览器内部就预存了网站A的密钥，且可以确保除了浏览器和网站A，不会有任何外人知道该密钥，那理论上用对称加密是可以的，这样浏览器只要预存好世界上所有HTTPS网站的密钥就行了！这么做显然不现实。<br>怎么办？所以我们就需要<code>非对称加密</code> 。</p><h3 id="什么是非对称加密？"><a href="#什么是非对称加密？" class="headerlink" title="什么是非对称加密？"></a>什么是非对称加密？</h3><p>简单说就是有两把密钥，通常一把叫做公钥、一把叫私钥，用公钥加密的内容必须用私钥才能解开，同样，私钥加密的内容只有公钥能解开。</p><p><img src="/images/2021-7-4182912.png" alt="2021-7-4182912.png"></p><h3 id="用非对称加密可行吗？"><a href="#用非对称加密可行吗？" class="headerlink" title="用非对称加密可行吗？"></a>用非对称加密可行吗？</h3><p>鉴于非对称加密的机制，我们可能会有这种思路：服务器先把公钥以明文方式传输给浏览器，之后浏览器向服务器传数据前都先用这个公钥加密好再传，这条数据的安全似乎可以保障了！<strong>因为只有服务器有相应的私钥能解开公钥加密的数据</strong>。</p><p>然而反过来<strong>由服务器到浏览器的这条路怎么保障安全？</strong>如果服务器用它的私钥加密数据传给浏览器，那么浏览器用公钥可以解密它，而这个公钥是一开始通过明文传输给浏览器的，若这个公钥被中间人劫持到了，那他也能用该公钥解密服务器传来的信息了。所以<strong>目前似乎只能保证由浏览器向服务器传输数据的安全性</strong>（其实仍有漏洞，下文会说），那利用这点你能想到什么解决方案吗？</p><h3 id="改良的非对称加密方案，似乎可以？"><a href="#改良的非对称加密方案，似乎可以？" class="headerlink" title="改良的非对称加密方案，似乎可以？"></a>改良的非对称加密方案，似乎可以？</h3><p>我们已经理解通过一组公钥私钥，可以保证单个方向传输的安全性，那用两组公钥私钥，是否就能保证双向传输都安全了？请看下面的过程：</p><ol><li>某网站服务器拥有公钥A与对应的私钥A’；浏览器拥有公钥B与对应的私钥B’。</li><li>浏览器把公钥B明文传输给服务器。</li><li>服务器把公钥A明文给传输浏览器。</li><li>之后浏览器向服务器传输的内容都用公钥A加密，服务器收到后用私钥A’解密。由于只有服务器拥有私钥A’，所以能保证这条数据的安全。</li><li>同理，服务器向浏览器传输的内容都用公钥B加密，浏览器收到后用私钥B’解密。同上也可以保证这条数据的安全。</li></ol><p>的确可以！抛开这里面仍有的漏洞不谈（下文会讲），HTTPS的加密却没使用这种方案，为什么？很重要的原因是非对称加密算法非常耗时，而对称加密快很多。那我们能不能运用非对称加密的特性解决前面提到的对称加密的漏洞？</p><h3 id="非对称加密-对称加密？"><a href="#非对称加密-对称加密？" class="headerlink" title="非对称加密+对称加密？"></a>非对称加密+对称加密？</h3><p>既然非对称加密耗时，那非对称加密+对称加密结合可以吗？而且得尽量减少非对称加密的次数。当然是可以的，且非对称加密、解密各只需用一次即可。<br>请看一下这个过程：</p><ol><li>某网站拥有用于非对称加密的公钥A、私钥A’。</li><li>浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。</li><li>浏览器随机生成一个用于对称加密的密钥X，用公钥A加密后传给服务器。</li><li>服务器拿到后用私钥A’解密得到密钥X。</li><li>这样双方就都拥有密钥X了，且别人无法知道它。之后双方所有数据都通过密钥X加密解密即可。</li></ol><p>完美！HTTPS基本就是采用了这种方案。完美？还是有漏洞的。</p><h3 id="中间人攻击"><a href="#中间人攻击" class="headerlink" title="中间人攻击"></a>中间人攻击</h3><p><img src="/images/2021-7-4183232.png" alt="2021-7-4183232.png"></p><p>如果在数据传输过程中，中间人劫持到了数据，此时他的确无法得到浏览器生成的密钥X，这个密钥本身被公钥A加密了，只有服务器才有私钥A’解开它，然而中间人却完全不需要拿到私钥A’就能干坏事了。请看：</p><ol><li>某网站有用于非对称加密的公钥A、私钥A’。</li><li>浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。</li><li><strong>中间人劫持到公钥A，保存下来，把数据包中的公钥A替换成自己伪造的公钥B（它当然也拥有公钥B对应的私钥B’）</strong>。</li><li>浏览器生成一个用于对称加密的密钥X，用<strong>公钥B</strong>（浏览器无法得知公钥被替换了）加密后传给服务器。</li><li><strong>中间人劫持后用私钥B’解密得到密钥X，再用公钥A加密后传给服务器</strong>。</li><li>服务器拿到后用私钥A’解密得到密钥X。</li></ol><p>这样在双方都不会发现异常的情况下，中间人通过一套“狸猫换太子”的操作，掉包了服务器传来的公钥，进而得到了密钥X。<strong>根本原因是浏览器无法确认收到的公钥是不是网站自己的，</strong>因为公钥本身是明文传输的，难道还得对公钥的传输进行加密？这似乎变成鸡生蛋、蛋生鸡的问题了。解法是什么？</p><h3 id="如何证明浏览器收到的公钥一定是该网站的公钥？"><a href="#如何证明浏览器收到的公钥一定是该网站的公钥？" class="headerlink" title="如何证明浏览器收到的公钥一定是该网站的公钥？"></a>如何证明浏览器收到的公钥一定是该网站的公钥？</h3><p>其实所有证明的源头都是一条或多条不证自明的“公理”（可以回想一下数学上公理），由它推导出一切。比如现实生活中，若想证明某身份证号一定是小明的，可以看他身份证，而身份证是由政府作证的，这里的“公理”就是“政府机构可信”，这也是社会正常运作的前提。</p><p>那能不能类似地有个机构充当互联网世界的“公理”呢？让它作为一切证明的源头，给网站颁发一个“身份证”？</p><p>它就是<strong>CA机构</strong>，它是如今互联网世界正常运作的前提，而CA机构颁发的“身份证”就是<strong>数字证书</strong>。</p><h3 id="数字证书"><a href="#数字证书" class="headerlink" title="数字证书"></a>数字证书</h3><p><img src="/images/2021-7-4183437.png" alt="2021-7-4183437.png"></p><p>网站在使用HTTPS前，需要向<strong>CA机构</strong>申领一份<strong>数字证书</strong>，数字证书里含有证书持有者信息、公钥信息等。服务器把证书传输给浏览器，浏览器从证书里获取公钥就行了，证书就如身份证，证明“该公钥对应该网站”。而这里又有一个显而易见的问题，“<strong>证书本身的传输过程中，如何防止被篡改”</strong>？即如何证明证书本身的真实性？身份证运用了一些防伪技术，而数字证书怎么防伪呢？解决这个问题我们就接近胜利了！</p><h3 id="如何放防止数字证书被篡改？"><a href="#如何放防止数字证书被篡改？" class="headerlink" title="如何放防止数字证书被篡改？"></a>如何放防止数字证书被篡改？</h3><p>我们把证书原本的内容生成一份“签名”，比对证书内容和签名是否一致就能判别是否被篡改。这就是数字证书的“防伪技术”，这里的“签名”就叫<code>数字签名</code>：</p><h4 id="数字签名"><a href="#数字签名" class="headerlink" title="数字签名"></a>数字签名</h4><p>这部分内容建议看下图并结合后面的文字理解，图中左侧是数字签名的制作过程，右侧是验证过程：</p><p><img src="/images/2021-7-4183542.png" alt="2021-7-4183542.png"></p><p>数字签名的制作过程：</p><ol><li>CA机构拥有非对称加密的私钥和公钥。</li><li>CA机构对证书明文数据T进行hash。</li><li>对hash后的值用私钥加密，得到数字签名S。</li></ol><p>明文和数字签名共同组成了数字证书，这样一份数字证书就可以颁发给网站了。<br>那浏览器拿到服务器传来的数字证书后，如何验证它是不是真的？（有没有被篡改、掉包）</p><p>浏览器验证过程：</p><ol><li>拿到证书，得到明文T，签名S。</li><li>用CA机构的公钥对S解密（由于是浏览器信任的机构，所以浏览器保有它的公钥。详情见下文），得到S’。</li><li>用证书里指明的hash算法对明文T进行hash得到T’。</li><li>显然通过以上步骤，T’应当等于S‘，除非明文或签名被篡改。所以此时比较S’是否等于T’，等于则表明证书可信。</li></ol><p>为何么这样可以保证证书可信呢？我们来仔细想一下。</p><h4 id="中间人有可能篡改该证书吗？"><a href="#中间人有可能篡改该证书吗？" class="headerlink" title="中间人有可能篡改该证书吗？"></a>中间人有可能篡改该证书吗？</h4><p>假设中间人篡改了证书的原文，由于他没有CA机构的私钥，所以无法得到此时加密后签名，无法相应地篡改签名。浏览器收到该证书后会发现原文和签名解密后的值不一致，则说明证书已被篡改，证书不可信，从而终止向服务器传输信息，防止信息泄露给中间人。</p><p>既然不可能篡改，那整个证书被掉包呢？</p><h4 id="中间人有可能把证书掉包吗？"><a href="#中间人有可能把证书掉包吗？" class="headerlink" title="中间人有可能把证书掉包吗？"></a>中间人有可能把证书掉包吗？</h4><p>假设有另一个网站B也拿到了CA机构认证的证书，它想劫持网站A的信息。于是它成为中间人拦截到了A传给浏览器的证书，然后替换成自己的证书，传给浏览器，之后浏览器就会错误地拿到B的证书里的公钥了，这确实会导致上文“中间人攻击”那里提到的漏洞？</p><p>其实这并不会发生，因为证书里包含了网站A的信息，包括域名，浏览器把证书里的域名与自己请求的域名比对一下就知道有没有被掉包了。</p><h4 id="为什么制作数字签名时需要hash一次？"><a href="#为什么制作数字签名时需要hash一次？" class="headerlink" title="为什么制作数字签名时需要hash一次？"></a>为什么制作数字签名时需要hash一次？</h4><p>我初识HTTPS的时候就有这个疑问，因为似乎那里的hash有点多余，把hash过程去掉也能保证证书没有被篡改。</p><p>最显然的是性能问题，前面我们已经说了非对称加密效率较差，证书信息一般较长，比较耗时。而hash后得到的是固定长度的信息（比如用md5算法hash后可以得到固定的128位的值），这样加解密就快很多。</p><p>当然也有安全上的原因，这部分内容相对深一些，感兴趣的可以看这篇解答：<a href="https://link.zhihu.com/?target=https%3A//link.juejin.im/%3Ftarget%3Dhttps%3A%2F%2Fcrypto.stackexchange.com%2Fa%2F12780" target="_blank" rel="noopener">crypto.stackexchange.com/a/12780</a></p><h4 id="怎么证明CA机构的公钥是可信的？"><a href="#怎么证明CA机构的公钥是可信的？" class="headerlink" title="怎么证明CA机构的公钥是可信的？"></a>怎么证明CA机构的公钥是可信的？</h4><p>你们可能会发现上文中说到CA机构的公钥，我几乎一笔带过，“浏览器保有它的公钥”，这是个什么保有法？怎么证明这个公钥是否可信？</p><p>让我们回想一下数字证书到底是干啥的？没错，为了证明某公钥是可信的，即“该公钥是否对应该网站”，那CA机构的公钥是否也可以用数字证书来证明？没错，操作系统、浏览器本身会预装一些它们信任的根证书，如果其中会有CA机构的根证书，这样就可以拿到它对应的可信公钥了。</p><p>实际上证书之间的认证也可以不止一层，可以A信任B，B信任C，以此类推，我们把它叫做<code>信任链</code>或<code>数字证书链</code>。也就是一连串的数字证书，由根证书为起点，透过层层信任，使终端实体证书的持有者可以获得转授的信任，以证明身份。</p><p>另外，不知你们是否遇到过网站访问不了、提示需安装证书的情况？这里安装的就是根证书。说明浏览器不认给这个网站颁发证书的机构，那么你就得手动下载安装该机构的根证书（风险自己承担）。安装后，你就有了它的公钥，就可以用它验证服务器发来的证书是否可信了。</p><p><img src="/images/2021-7-4212126.png" alt="2021-7-4212126.png"></p><h3 id="每次进行HTTPS请求时都必须在SSL-TLS层进行握手传输密钥吗？"><a href="#每次进行HTTPS请求时都必须在SSL-TLS层进行握手传输密钥吗？" class="headerlink" title="每次进行HTTPS请求时都必须在SSL/TLS层进行握手传输密钥吗？"></a><strong>每次进行HTTPS请求时都</strong>必须在SSL/TLS层进行握手传输密钥吗？</h3><p>这也是我当时的困惑之一，显然每次请求都经历一次密钥传输过程非常耗时，那怎么达到只传输一次呢？</p><p>服务器会为每个浏览器（或客户端软件）维护一个session ID，在TLS握手阶段传给浏览器，浏览器生成好密钥传给服务器后，服务器会把该密钥存到相应的session ID下，之后浏览器每次请求都会携带session ID，服务器会根据session ID找到相应的密钥并进行解密加密操作，这样就不必要每次重新制作、传输密钥了！</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>可以看下这张图，梳理一下整个流程（SSL、TLS握手有一些区别，不同版本间也有区别，不过大致过程就是这样）：</p><p><img src="/images/2021-7-4212218.png" alt="2021-7-4212218.png"></p><p>Read More:</p><blockquote><p><a href="https://zhuanlan.zhihu.com/p/43789231" target="_blank" rel="noopener">彻底搞懂HTTPS的加密原理</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;为什么需要加密？&quot;&gt;&lt;a href=&quot;#为什么需要加密？&quot; class=&quot;headerlink&quot; title=&quot;为什么需要加密？&quot;&gt;&lt;/a&gt;为什么需要加密？&lt;/h3&gt;&lt;p&gt;因为HTTP的内容是明文传输的，明文数据会经过中间代理服务器、路由器、WIFI热点、通信服务
      
    
    </summary>
    
      <category term="HTTPS" scheme="http://runnerliu.github.io/categories/HTTPS/"/>
    
    
      <category term="HTTPS" scheme="http://runnerliu.github.io/tags/HTTPS/"/>
    
      <category term="加密" scheme="http://runnerliu.github.io/tags/%E5%8A%A0%E5%AF%86/"/>
    
      <category term="密钥协商" scheme="http://runnerliu.github.io/tags/%E5%AF%86%E9%92%A5%E5%8D%8F%E5%95%86/"/>
    
  </entry>
  
  <entry>
    <title>秒杀系统设计08 - 准备Plan B：如何设计兜底方案?</title>
    <link href="http://runnerliu.github.io/2021/07/04/miaosha08/"/>
    <id>http://runnerliu.github.io/2021/07/04/miaosha08/</id>
    <published>2021-07-04T02:32:42.000Z</published>
    <updated>2021-07-04T02:40:20.976Z</updated>
    
    <content type="html"><![CDATA[<p>这是《如何设计一个秒杀系统》专栏的最后一篇文章，前面我们一起看了很多极致的优化思路，以及架构的优化方案。但是很遗憾，现实中总难免会发生一些这样或者那样的意外，而这些看似不经意的意外，却可能带来非常严重的后果。</p><p>我想对于很多秒杀系统而言，在诸如双十一这样的大流量的迅猛冲击下，都曾经或多或少发生过宕机的情况。当一个系统面临持续的大流量时，它其实很难单靠自身调整来恢复状态，你必须等待流量自然下降或者人为地把流量切走才行，这无疑会严重影响用户的购物体验。</p><p>同时，你也要知道，没有人能够提前预估所有情况，意外无法避免。那么，我们是不是就没办法了呢？当然不是，我们可以在系统达到不可用状态之前就做好流量限制，防止最坏情况的发生。用现在流行的话来说，任何一个系统，都需要“反脆弱”。</p><p>具体到秒杀这一场景下，为了保证系统的高可用，我们必须设计一个 Plan B 方案来兜底，这样在最坏情况发生时我们仍然能够从容应对。今天，我们就来看下兜底方案设计的一些具体思路。</p><h3 id="高可用建设应该从哪里着手"><a href="#高可用建设应该从哪里着手" class="headerlink" title="高可用建设应该从哪里着手"></a>高可用建设应该从哪里着手</h3><p>说到系统的高可用建设，它其实是一个系统工程，需要考虑到系统建设的各个阶段，也就是说它其实贯穿了系统建设的整个生命周期，如下图所示：</p><p><img src="/images/2021-7-4103326.png" alt="2021-7-4103326.png"></p><p>具体来说，系统的高可用建设涉及架构阶段、编码阶段、测试阶段、发布阶段、运行阶段，以及故障发生时。接下来，我们分别看一下。</p><ol><li><strong>架构阶段</strong>：架构阶段主要考虑系统的可扩展性和容错性，要避免系统出现单点问题。例如多机房单元化部署，即使某个城市的某个机房出现整体故障，仍然不会影响整体网站的运转。</li><li><strong>编码阶段</strong>：编码最重要的是保证代码的健壮性，例如涉及远程调用问题时，要设置合理的超时退出机制，防止被其他系统拖垮，也要对调用的返回结果集有预期，防止返回的结果超出程序处理范围，最常见的做法就是对错误异常进行捕获，对无法预料的错误要有默认处理结果。</li><li><strong>测试阶段</strong>：测试主要是保证测试用例的覆盖度，保证最坏情况发生时，我们也有相应的处理流程。</li><li><strong>发布阶段</strong>：发布时也有一些地方需要注意，因为发布时最容易出现错误，因此要有紧急的回滚机制。</li><li><strong>运行阶段</strong>：运行时是系统的常态，系统大部分时间都会处于运行态，运行态最重要的是对系统的监控要准确及时，发现问题能够准确报警并且报警数据要准确详细，以便于排查问题。</li><li><strong>故障发生</strong>：故障发生时首先最重要的就是及时止损，例如由于程序问题导致商品价格错误，那就要及时下架商品或者关闭购买链接，防止造成重大资产损失。然后就是要能够及时恢复服务，并定位原因解决问题。</li></ol><p>为什么系统的高可用建设要放到整个生命周期中全面考虑？因为我们在每个环节中都可能犯错，而有些环节犯的错，你在后面是无法弥补的。例如在架构阶段，你没有消除单点问题，那么系统上线后，遇到突发流量把单点给挂了，你就只能干瞪眼，有时候想加机器都加不进去。所以高可用建设是一个系统工程，必须在每个环节都做好。</p><p>那么针对秒杀系统，我们重点介绍在遇到大流量时，应该从哪些方面来保障系统的稳定运行，所以更多的是看如何针对运行阶段进行处理，这就引出了接下来的内容：降级、限流和拒绝服务。</p><h4 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h4><p>所谓“降级”，就是当系统的容量达到一定程度时，限制或者关闭系统的某些非核心功能，从而把有限的资源保留给更核心的业务。它是一个有目的、有计划的执行过程，所以对降级我们一般需要有一套预案来配合执行。如果我们把它系统化，就可以通过预案系统和开关系统来实现降级。</p><p>降级方案可以这样设计：当秒杀流量达到 5w/s 时，把成交记录的获取从展示 20 条降级到只展示 5 条。“从 20 改到 5”这个操作由一个开关来实现，也就是设置一个能够从开关系统动态获取的系统参数。</p><p>这里，我给出开关系统的示意图。它分为两部分，一部分是开关控制台，它保存了开关的具体配置信息，以及具体执行开关所对应的机器列表；另一部分是执行下发开关数据的 Agent，主要任务就是保证开关被正确执行，即使系统重启后也会生效。</p><p><img src="/images/2021-7-4103414.png" alt="2021-7-4103414.png"></p><p>执行降级无疑是在系统性能和用户体验之间选择了前者，降级后肯定会影响一部分用户的体验，例如在双 11 零点时，如果优惠券系统扛不住，可能会临时降级商品详情的优惠信息展示，把有限的系统资源用在保障交易系统正确展示优惠信息上，即保障用户真正下单时的价格是正确的。所以降级的核心目标是牺牲次要的功能和用户体验来保证核心业务流程的稳定，是一个不得已而为之的举措。</p><h4 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h4><p>如果说降级是牺牲了一部分次要的功能和用户的体验效果，那么限流就是更极端的一种保护措施了。限流就是当系统容量达到瓶颈时，我们需要通过限制一部分流量来保护系统，并做到既可以人工执行开关，也支持自动化保护的措施。</p><p>这里，我同样给出了限流系统的示意图。总体来说，限流既可以是在客户端限流，也可以是在服务端限流。此外，限流的实现方式既要支持 URL 以及方法级别的限流，也要支持基于 QPS 和线程的限流。</p><p>首先，我以内部的系统调用为例，来分别说下客户端限流和服务端限流的优缺点。</p><ul><li><strong>客户端限流</strong>，好处可以限制请求的发出，通过减少发出无用请求从而减少对系统的消耗。缺点就是当客户端比较分散时，没法设置合理的限流阈值：如果阈值设的太小，会导致服务端没有达到瓶颈时客户端已经被限制；而如果设的太大，则起不到限制的作用。</li><li><strong>服务端限流</strong>，好处是可以根据服务端的性能设置合理的阈值，而缺点就是被限制的请求都是无效的请求，处理这些无效的请求本身也会消耗服务器资源。</li></ul><p><img src="/images/2021-7-4103450.png" alt="2021-7-4103450.png"></p><p>在限流的实现手段上来讲，基于 QPS 和线程数的限流应用最多，最大 QPS 很容易通过压测提前获取，例如我们的系统最高支持 1w QPS 时，可以设置 8000 来进行限流保护。线程数限流在客户端比较有效，例如在远程调用时我们设置连接池的线程数，超出这个并发线程请求，就将线程进行排队或者直接超时丢弃。</p><p>限流无疑会影响用户的正常请求，所以必然会导致一部分用户请求失败，因此在系统处理这种异常时一定要设置超时时间，防止因被限流的请求不能 fast fail（快速失败）而拖垮系统。</p><h4 id="拒绝服务"><a href="#拒绝服务" class="headerlink" title="拒绝服务"></a>拒绝服务</h4><p>如果限流还不能解决问题，最后一招就是直接拒绝服务了。</p><p>当系统负载达到一定阈值时，例如 CPU 使用率达到 90% 或者系统 load 值达到 2*CPU 核数时，系统直接拒绝所有请求，这种方式是最暴力但也最有效的系统保护方式。例如秒杀系统，我们在如下几个环节设计过载保护：</p><blockquote><p>在最前端的 Nginx 上设置过载保护，当机器负载达到某个值时直接拒绝 HTTP 请求并返回 503 错误码，在 Java 层同样也可以设计过载保护。</p></blockquote><p>拒绝服务可以说是一种不得已的兜底方案，用以防止最坏情况发生，防止因把服务器压跨而长时间彻底无法提供服务。像这种系统过载保护虽然在过载时无法提供服务，但是系统仍然可以运作，当负载下降时又很容易恢复，所以每个系统和每个环节都应该设置这个兜底方案，对系统做最坏情况下的保护。</p><h3 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h3><p>网站的高可用建设是基础，可以说要深入到各个环节，更要长期规划并进行体系化建设，要在预防（建立常态的压力体系，例如上线前的单机压测到上线后的全链路压测）、管控（做好线上运行时的降级、限流和兜底保护）、监控（建立性能基线来记录性能的变化趋势以及线上机器的负载报警体系，发现问题及时预警）和恢复体系（遇到故障要及时止损，并提供快速的数据订正工具等）等这些地方加强建设，每一个环节可能都有很多事情要做。</p><p>另外，要保证高可用建设的落实，你不仅要做系统建设，还要在组织上做好保障。高可用其实就是在说“稳定性”。稳定性是一个平时不重要，但真出了问题就会要命的事儿，所以很可能平时业务发展良好，稳定性建设就会给业务让路，相关的稳定性负责人员平时根本得不到重视，一旦遇到故障却又成了“背锅侠”。</p><p>而要防止出现这种情况，就必须在组织上有所保障，例如可以让业务负责人背上稳定性 KPI 考核指标，然后在技术部门中建立稳定性建设小组，小组成员由每个业务线的核心力量兼任，他们的 KPI 由稳定性负责人来打分，这样稳定性小组就可以把一些体系化的建设任务落实到具体的业务系统中了。</p><p>Read More:</p><blockquote><p><a href="https://d.shikey.com/jike/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E5%B7%B2%E5%AE%8C%E7%BB%93/20%20%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F-%E8%AE%B8%E4%BB%A4%E6%B3%A2/181007-07%20_%20%E5%87%86%E5%A4%87Plan%20B%EF%BC%9A%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E5%85%9C%E5%BA%95%E6%96%B9%E6%A1%88_.html" target="_blank" rel="noopener">07 | 准备Plan B：如何设计兜底方案?</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这是《如何设计一个秒杀系统》专栏的最后一篇文章，前面我们一起看了很多极致的优化思路，以及架构的优化方案。但是很遗憾，现实中总难免会发生一些这样或者那样的意外，而这些看似不经意的意外，却可能带来非常严重的后果。&lt;/p&gt;
&lt;p&gt;我想对于很多秒杀系统而言，在诸如双十一这样的大流量
      
    
    </summary>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="秒杀系统" scheme="http://runnerliu.github.io/tags/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>秒杀系统设计07 - 秒杀系统“减库存”设计的核心逻辑</title>
    <link href="http://runnerliu.github.io/2021/07/04/miaosha07/"/>
    <id>http://runnerliu.github.io/2021/07/04/miaosha07/</id>
    <published>2021-07-04T02:30:57.000Z</published>
    <updated>2021-07-04T02:40:16.869Z</updated>
    
    <content type="html"><![CDATA[<p>如果要设计一套秒杀系统，那我想你的老板肯定会先对你说：千万不要超卖，这是大前提。</p><p>如果你第一次接触秒杀，那你可能还不太理解，库存 100 件就卖 100 件，在数据库里减到 0 就好了啊，这有什么麻烦的？是的，理论上是这样，但是具体到业务场景中，“减库存”就不是这么简单了。</p><p>例如，我们平常购物都是这样，看到喜欢的商品然后下单，但并不是每个下单请求你都最后付款了。你说系统是用户下单了就算这个商品卖出去了，还是等到用户真正付款了才算卖出了呢？这的确是个问题！</p><p>我们可以先根据减库存是发生在下单阶段还是付款阶段，把减库存做一下划分。</p><h3 id="减库存有哪几种方式"><a href="#减库存有哪几种方式" class="headerlink" title="减库存有哪几种方式"></a>减库存有哪几种方式</h3><p>在正常的电商平台购物场景中，用户的实际购买过程一般分为两步：下单和付款。你想买一台 iPhone 手机，在商品页面点了“立即购买”按钮，核对信息之后点击“提交订单”，这一步称为下单操作。下单之后，你只有真正完成付款操作才能算真正购买，也就是俗话说的“落袋为安”。</p><p>那如果你是架构师，你会在哪个环节完成减库存的操作呢？总结来说，减库存操作一般有如下几个方式：</p><ul><li><strong>下单减库存</strong>，即当买家下单后，在商品的总库存中减去买家购买数量。下单减库存是最简单的减库存方式，也是控制最精确的一种，下单时直接通过数据库的事务机制控制商品库存，这样一定不会出现超卖的情况。但是你要知道，有些人下完单可能并不会付款。</li><li><strong>付款减库存</strong>，即买家下单后，并不立即减库存，而是等到有用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为可能商品已经被其他人买走了。</li><li><strong>预扣库存</strong>，这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如 10 分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。</li></ul><p>以上这几种减库存的方式都会存在一些问题，下面我们一起来看下。</p><h3 id="减库存可能存在的问题"><a href="#减库存可能存在的问题" class="headerlink" title="减库存可能存在的问题"></a>减库存可能存在的问题</h3><p>由于购物过程中存在两步或者多步的操作，因此在不同的操作步骤中减库存，就会存在一些可能被恶意买家利用的漏洞，例如发生恶意下单的情况。</p><p>假如我们采用“下单减库存”的方式，即用户下单后就减去库存，正常情况下，买家下单后付款的概率会很高，所以不会有太大问题。但是有一种场景例外，就是当卖家参加某个活动时，此时活动的有效时间是商品的黄金售卖时间，如果有竞争对手通过恶意下单的方式将该卖家的商品全部下单，让这款商品的库存减为零，那么这款商品就不能正常售卖了。要知道，这些恶意下单的人是不会真正付款的，这正是“下单减库存”方式的不足之处。</p><p>既然“下单减库存”可能导致恶意下单，从而影响卖家的商品销售，那么有没有办法解决呢？你可能会想，采用“付款减库存”的方式是不是就可以了？的确可以。但是，“付款减库存”又会导致另外一个问题：库存超卖。</p><p>假如有 100 件商品，就可能出现 300 人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在做活动的热门商品上。这样一来，就会导致很多买家下单成功但是付不了款，买家的购物体验自然比较差。</p><p>可以看到，不管是“下单减库存”还是“付款减库存”，都会导致商品库存不能完全和实际售卖情况对应起来的情况，看来要把商品准确地卖出去还真是不容易啊！</p><p>那么，既然“下单减库存”和“付款减库存”都有缺点，我们能否把两者相结合，将两次操作进行前后关联起来，下单时先预扣，在规定时间内不付款再释放库存，即采用“预扣库存”这种方式呢？</p><p>这种方案确实可以在一定程度上缓解上面的问题。但是否就彻底解决了呢？其实没有！针对恶意下单这种情况，虽然把有效的付款时间设置为 10 分钟，但是恶意买家完全可以在 10 分钟后再次下单，或者采用一次下单很多件的方式把库存减完。针对这种情况，解决办法还是要结合安全和反作弊的措施来制止。</p><p>例如，给经常下单不付款的买家进行识别打标（可以在被打标的买家下单时不减库存）、给某些类目设置最大购买件数（例如，参加活动的商品一人最多只能买 3 件），以及对重复下单不付款的操作进行次数限制等。</p><p>针对“库存超卖”这种情况，在 10 分钟时间内下单的数量仍然有可能超过库存数量，遇到这种情况我们只能区别对待：对普通的商品下单数量超过库存数量的情况，可以通过补货来解决；但是有些卖家完全不允许库存为负数的情况，那只能在买家付款时提示库存不足。</p><h3 id="大型秒杀中如何减库存？"><a href="#大型秒杀中如何减库存？" class="headerlink" title="大型秒杀中如何减库存？"></a>大型秒杀中如何减库存？</h3><p>目前来看，业务系统中最常见的就是预扣库存方案，像你在买机票、买电影票时，下单后一般都有个“有效付款时间”，超过这个时间订单自动释放，这都是典型的预扣库存方案。而具体到秒杀这个场景，应该采用哪种方案比较好呢？</p><p>由于参加秒杀的商品，一般都是“抢到就是赚到”，所以成功下单后却不付款的情况比较少，再加上卖家对秒杀商品的库存有严格限制，所以秒杀商品采用“下单减库存”更加合理。另外，理论上由于“下单减库存”比“预扣库存”以及涉及第三方支付的“付款减库存”在逻辑上更为简单，所以性能上更占优势。</p><p>“下单减库存”在数据一致性上，主要就是保证大并发请求时库存数据不能为负数，也就是要保证数据库中的库存字段值不能为负数，一般我们有多种解决方案：一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚；另一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行 SQL 语句来报错；再有一种就是使用 CASE WHEN 判断语句，例如这样的 SQL 语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UPDATE item SET inventory = CASE WHEN inventory &gt;= xxx THEN inventory-xxx ELSE inventory END</span><br></pre></td></tr></table></figure><h3 id="秒杀减库存的极致优化"><a href="#秒杀减库存的极致优化" class="headerlink" title="秒杀减库存的极致优化"></a>秒杀减库存的极致优化</h3><p>在交易环节中，“库存”是个关键数据，也是个热点数据，因为交易的各个环节中都可能涉及对库存的查询。但是，我在前面介绍分层过滤时提到过，秒杀中并不需要对库存有精确的一致性读，把库存数据放到缓存（Cache）中，可以大大提升读性能。</p><p>解决大并发读问题，可以采用 LocalCache（即在秒杀系统的单机上缓存商品相关的数据）和对数据进行分层过滤的方式，但是像减库存这种大并发写无论如何还是避免不了，这也是秒杀场景下最为核心的一个技术难题。</p><p><strong>因此，这里我想专门来说一下秒杀场景下减库存的极致优化思路，包括如何在缓存中减库存以及如何在数据库中减库存</strong>。</p><p>秒杀商品和普通商品的减库存还是有些差异的，例如商品数量比较少，交易时间段也比较短，因此这里有一个大胆的假设，即能否把秒杀商品减库存直接放到缓存系统中实现，也就是直接在缓存中减库存或者在一个带有持久化功能的缓存系统（如 Redis）中完成呢？</p><p>如果你的秒杀商品的减库存逻辑非常单一，比如没有复杂的 SKU 库存和总库存这种联动关系的话，我觉得完全可以。但是如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存。</p><p>由于 MySQL 存储数据的特点，同一数据在数据库里肯定是一行存储（MySQL），因此会有大量线程来竞争 InnoDB 行锁，而并发度越高时等待线程会越多，TPS（Transaction Per Second，即每秒处理的消息数）会下降，响应时间（RT）会上升，数据库的吞吐量就会严重受影响。</p><p>这就可能引发一个问题，就是单个热点商品会影响整个数据库的性能， 导致 0.01% 的商品影响 99.99% 的商品的售卖，这是我们不愿意看到的情况。一个解决思路是遵循前面介绍的原则进行隔离，把热点商品放到单独的热点库中。但是这无疑会带来维护上的麻烦，比如要做热点数据的动态迁移以及单独的数据库等。</p><p>而分离热点商品到单独的数据库还是没有解决并发锁的问题，我们应该怎么办呢？要解决并发锁的问题，有两种办法：</p><ul><li><strong>应用层做排队</strong>。按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用太多的数据库连接。</li><li><strong>数据库层做排队</strong>。应用层只能做到单机的排队，但是应用机器数本身很多，这种排队方式控制并发的能力仍然有限，所以如果能在数据库层做全局排队是最理想的。阿里的数据库团队开发了针对这种 MySQL 的 InnoDB 层上的补丁程序（patch），可以在数据库层上对单行记录做到并发排队。</li></ul><p>你可能有疑问了，排队和锁竞争不都是要等待吗，有啥区别？</p><p>如果熟悉 MySQL 的话，你会知道 InnoDB 内部的死锁检测，以及 MySQL Server 和 InnoDB 的切换会比较消耗性能，淘宝的 MySQL 核心团队还做了很多其他方面的优化，如 COMMIT_ON_SUCCESS 和 ROLLBACK_ON_FAIL 的补丁程序，配合在 SQL 里面加提示（hint），在事务里不需要等待应用层提交（COMMIT），而在数据执行完最后一条 SQL 后，直接根据 TARGET_AFFECT_ROW 的结果进行提交或回滚，可以减少网络等待时间（平均约 0.7ms）。据我所知，目前阿里 MySQL 团队已经将包含这些补丁程序的 MySQL 开源。</p><p>另外，数据更新问题除了前面介绍的热点隔离和排队处理之外，还有些场景（如对商品的 lastmodifytime 字段的）更新会非常频繁，在某些场景下这些多条 SQL 是可以合并的，一定时间内只要执行最后一条 SQL 就行了，以便减少对数据库的更新操作。</p><h3 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h3><p>今天，我围绕商品减库存的场景，介绍了减库存的三种实现方案，以及分别存在的问题和可能的缓解办法。最后，我又聚焦秒杀这个场景说了如何实现减库存，以及在这个场景下做到极致优化的一些思路。</p><p>当然减库存还有很多细节问题，例如预扣的库存超时后如何进行库存回补，再比如目前都是第三方支付，如何在付款时保证减库存和成功付款时的状态一致性，这些都是很大的挑战。</p><p>Read More:</p><blockquote><p><a href="https://d.shikey.com/jike/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E5%B7%B2%E5%AE%8C%E7%BB%93/20%20%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F-%E8%AE%B8%E4%BB%A4%E6%B3%A2/181006-06%20_%20%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E2%80%9C%E5%87%8F%E5%BA%93%E5%AD%98%E2%80%9D%E8%AE%BE%E8%AE%A1%E7%9A%84%E6%A0%B8%E5%BF%83%E9%80%BB%E8%BE%91.html" target="_blank" rel="noopener">06 | 秒杀系统“减库存”设计的核心逻辑</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如果要设计一套秒杀系统，那我想你的老板肯定会先对你说：千万不要超卖，这是大前提。&lt;/p&gt;
&lt;p&gt;如果你第一次接触秒杀，那你可能还不太理解，库存 100 件就卖 100 件，在数据库里减到 0 就好了啊，这有什么麻烦的？是的，理论上是这样，但是具体到业务场景中，“减库存”就不
      
    
    </summary>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="秒杀系统" scheme="http://runnerliu.github.io/tags/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>秒杀系统设计06 - 影响性能的因素有哪些？又该如何提高系统的性能？</title>
    <link href="http://runnerliu.github.io/2021/07/04/miaosha06/"/>
    <id>http://runnerliu.github.io/2021/07/04/miaosha06/</id>
    <published>2021-07-04T02:27:58.000Z</published>
    <updated>2021-07-04T02:40:13.970Z</updated>
    
    <content type="html"><![CDATA[<p>前面的几篇文章里，我介绍的内容多少都和优化有关：第一篇介绍了一些指导原则；第二篇和第三篇从动静分离和热点数据两个维度，介绍了如何有针对性地对数据进行区分和优化处理；第四篇介绍了在保证实现基本业务功能的前提下，尽量减少和过滤一些无效请求的思路。</p><p>这几篇文章既是在讲根据指导原则实现的具体案例，也是在讲如何实现能够让整个系统更“快”。我想说的是，优化本身有很多手段，也是一个复杂的系统工程。今天，我就来结合秒杀这一场景，重点给你介绍下服务端的一些优化技巧。</p><h3 id="影响性能的因素"><a href="#影响性能的因素" class="headerlink" title="影响性能的因素"></a>影响性能的因素</h3><p>你想要提升性能，首先肯定要知道哪些因素对于系统性能的影响最大，然后再针对这些具体的因素想办法做优化，是不是这个逻辑？</p><p>那么，哪些因素对性能有影响呢？在回答这个问题之前，我们先定义一下“性能”，服务设备不同对性能的定义也是不一样的，例如 CPU 主要看主频、磁盘主要看 IOPS（Input/Output Operations Per Second，即每秒进行读写操作的次数）。</p><p>而今天我们讨论的主要是系统服务端性能，一般用 QPS（Query Per Second，每秒请求数）来衡量，还有一个影响和 QPS 也息息相关，那就是响应时间（Response Time，RT），它可以理解为服务器处理响应的耗时。</p><p>正常情况下响应时间（RT）越短，一秒钟处理的请求数（QPS）自然也就会越多，这在单线程处理的情况下看起来是线性的关系，即我们只要把每个请求的响应时间降到最低，那么性能就会最高。</p><p>但是你可能想到响应时间总有一个极限，不可能无限下降，所以又出现了另外一个维度，即通过多线程，来处理请求。这样理论上就变成了“总 QPS =（1000ms / 响应时间）× 线程数量”，这样性能就和两个因素相关了，一个是一次响应的服务端耗时，一个是处理请求的线程数。</p><p>接下来，我们一起看看这个两个因素到底会造成什么样的影响。</p><p><strong>首先，我们先来看看响应时间和 QPS 有啥关系</strong>。</p><p>对于大部分的 Web 系统而言，响应时间一般都是由 CPU 执行时间和线程等待时间（比如 RPC、IO 等待、Sleep、Wait 等）组成，即服务器在处理一个请求时，一部分是 CPU 本身在做运算，还有一部分是在各种等待。</p><p>理解了服务器处理请求的逻辑，估计你会说为什么我们不去减少这种等待时间。很遗憾，根据我们实际的测试发现，减少线程等待时间对提升性能的影响没有我们想象得那么大，它并不是线性的提升关系，这点在很多代理服务器（Proxy）上可以做验证。</p><p>如果代理服务器本身没有 CPU 消耗，我们在每次给代理服务器代理的请求加个延时，即增加响应时间，但是这对代理服务器本身的吞吐量并没有多大的影响，因为代理服务器本身的资源并没有被消耗，可以通过增加代理服务器的处理线程数，来弥补响应时间对代理服务器的 QPS 的影响。</p><p>其实，真正对性能有影响的是 CPU 的执行时间。这也很好理解，因为 CPU 的执行真正消耗了服务器的资源。经过实际的测试，如果减少 CPU 一半的执行时间，就可以增加一倍的 QPS。</p><p>也就是说，我们应该致力于减少 CPU 的执行时间。</p><p><strong>其次，我们再来看看线程数对 QPS 的影响</strong>。</p><p>单看“总 QPS”的计算公式，你会觉得线程数越多 QPS 也就会越高，但这会一直正确吗？显然不是，线程数不是越多越好，因为线程本身也消耗资源，也受到其他因素的制约。例如，线程越多系统的线程切换成本就会越高，而且每个线程也都会耗费一定内存。</p><p>那么，设置什么样的线程数最合理呢？其实<strong>很多多线程的场景都有一个默认配置，即“线程数 = 2 * CPU 核数 + 1”</strong>。除去这个配置，还有一个根据最佳实践得出来的公式：</p><blockquote><p>线程数 = [(线程等待时间 + 线程 CPU 时间) / 线程 CPU 时间] × CPU 数量</p></blockquote><p>当然，最好的办法是通过性能测试来发现最佳的线程数。</p><p>换句话说，要提升性能我们就要减少 CPU 的执行时间，另外就是要设置一个合理的并发线程数，通过这两方面来显著提升服务器的性能。</p><p>现在，你知道了如何来快速提升性能，那接下来你估计会问，我应该怎么发现系统哪里最消耗 CPU 资源呢？</p><h3 id="如何发现瓶颈"><a href="#如何发现瓶颈" class="headerlink" title="如何发现瓶颈"></a>如何发现瓶颈</h3><p>就服务器而言，会出现瓶颈的地方有很多，例如 CPU、内存、磁盘以及网络等都可能会导致瓶颈。此外，不同的系统对瓶颈的关注度也不一样，例如对缓存系统而言，制约它的是内存，而对存储型系统来说 I/O 更容易是瓶颈。</p><p><strong>这个专栏中，我们定位的场景是秒杀，它的瓶颈更多地发生在 CPU 上</strong>。</p><p>那么，如何发现 CPU 的瓶颈呢？其实有很多 CPU 诊断工具可以发现 CPU 的消耗，最常用的就是 JProfiler 和 Yourkit 这两个工具，它们可以列出整个请求中每个函数的 CPU 执行时间，可以发现哪个函数消耗的 CPU 时间最多，以便你有针对性地做优化。</p><p>当然还有一些办法也可以近似地统计 CPU 的耗时，例如通过 jstack 定时地打印调用栈，如果某些函数调用频繁或者耗时较多，那么那些函数就会多次出现在系统调用栈里，这样相当于采样的方式也能够发现耗时较多的函数。</p><p>虽说秒杀系统的瓶颈大部分在 CPU，但这并不表示其他方面就一定不出现瓶颈。例如，如果海量请求涌过来，你的页面又比较大，那么网络就有可能出现瓶颈。</p><p>怎样简单地判断 CPU 是不是瓶颈呢？一个办法就是看当 QPS 达到极限时，你的服务器的 CPU 使用率是不是超过了 95%，如果没有超过，那么表示 CPU 还有提升的空间，要么是有锁限制，要么是有过多的本地 I/O 等待发生。</p><p>现在你知道了优化哪些因素，又发现了瓶颈，那么接下来就要关注如何优化了。</p><h3 id="如何优化系统"><a href="#如何优化系统" class="headerlink" title="如何优化系统"></a>如何优化系统</h3><p>对 Java 系统来说，可以优化的地方很多，这里我重点说一下比较有效的几种手段，供你参考，它们是：减少编码、减少序列化、Java 极致优化、并发读优化。接下来，我们分别来看一下。</p><h4 id="减少编码"><a href="#减少编码" class="headerlink" title="减少编码"></a>减少编码</h4><p>Java 的编码运行比较慢，这是 Java 的一大硬伤。在很多场景下，只要涉及字符串的操作（如输入输出操作、I/O 操作）都比较耗 CPU 资源，不管它是磁盘 I/O 还是网络 I/O，因为都需要将字符转换成字节，而这个转换必须编码。</p><p>每个字符的编码都需要查表，而这种查表的操作非常耗资源，所以减少字符到字节或者相反的转换、减少字符编码会非常有成效。减少编码就可以大大提升性能。</p><p>那么如何才能减少编码呢？例如，网页输出是可以直接进行流输出的，即用 resp.getOutputStream() 函数写数据，把一些静态的数据提前转化成字节，等到真正往外写的时候再直接用 OutputStream() 函数写，就可以减少静态数据的编码转换。</p><p>我在《深入分析 Java Web 技术内幕》一书中介绍的“Velocity 优化实践”一章的内容，就是基于把静态的字符串提前编码成字节并缓存，然后直接输出字节内容到页面，从而大大减少编码的性能消耗的，网页输出的性能比没有提前进行字符到字节转换时提升了 30% 左右。</p><h4 id="减少序列化"><a href="#减少序列化" class="headerlink" title="减少序列化"></a>减少序列化</h4><p>序列化也是 Java 性能的一大天敌，减少 Java 中的序列化操作也能大大提升性能。又因为序列化往往是和编码同时发生的，所以减少序列化也就减少了编码。</p><p>序列化大部分是在 RPC 中发生的，因此避免或者减少 RPC 就可以减少序列化，当然当前的序列化协议也已经做了很多优化来提升性能。有一种新的方案，就是可以将多个关联性比较强的应用进行“合并部署”，而减少不同应用之间的 RPC 也可以减少序列化的消耗。</p><p>所谓“合并部署”，就是把两个原本在不同机器上的不同应用合并部署到一台机器上，当然不仅仅是部署在一台机器上，还要在同一个 Tomcat 容器中，且不能走本机的 Socket，这样才能避免序列化的产生。</p><p>另外针对秒杀场景，我们还可以做得更极致一些，接下来我们来看第 3 点：Java 极致优化。</p><h4 id="Java-极致优化"><a href="#Java-极致优化" class="headerlink" title="Java 极致优化"></a>Java 极致优化</h4><p>Java 和通用的 Web 服务器（如 Nginx 或 Apache 服务器）相比，在处理大并发的 HTTP 请求时要弱一点，所以一般我们都会对大流量的 Web 系统做静态化改造，让大部分请求和数据直接在 Nginx 服务器或者 Web 代理服务器（如 Varnish、Squid 等）上直接返回（这样可以减少数据的序列化与反序列化），而 Java 层只需处理少量数据的动态请求。针对这些请求，我们可以使用以下手段进行优化：</p><ul><li>直接使用 Servlet 处理请求。避免使用传统的 MVC 框架，这样可以绕过一大堆复杂且用处不大的处理逻辑，节省 1ms 时间（具体取决于你对 MVC 框架的依赖程度）。</li><li>直接输出流数据。使用 resp.getOutputStream() 而不是 resp.getWriter() 函数，可以省掉一些不变字符数据的编码，从而提升性能；数据输出时推荐使用 JSON 而不是模板引擎（一般都是解释执行）来输出页面。</li></ul><h4 id="并发读优化"><a href="#并发读优化" class="headerlink" title="并发读优化"></a>并发读优化</h4><p>也许有读者会觉得这个问题很容易解决，无非就是放到 Tair 缓存里面。集中式缓存为了保证命中率一般都会采用一致性 Hash，所以同一个 key 会落到同一台机器上。虽然单台缓存机器也能支撑 30w/s 的请求，但还是远不足以应对像“大秒”这种级别的热点商品。那么，该如何彻底解决单点的瓶颈呢？</p><p>答案是采用应用层的 LocalCache，即在秒杀系统的单机上缓存商品相关的数据。</p><p>那么，又如何缓存（Cache）数据呢？你需要划分成动态数据和静态数据分别进行处理：</p><ul><li>像商品中的“标题”和“描述”这些本身不变的数据，会在秒杀开始之前全量推送到秒杀机器上，并一直缓存到秒杀结束；</li><li>像库存这类动态数据，会采用“被动失效”的方式缓存一定时间（一般是数秒），失效后再去缓存拉取最新的数据。</li></ul><p>你可能还会有疑问：像库存这种频繁更新的数据，一旦数据不一致，会不会导致超卖？</p><p>这就要用到前面介绍的读数据的分层校验原则了，读的场景可以允许一定的脏数据，因为这里的误判只会导致少量原本无库存的下单请求被误认为有库存，可以等到真正写数据时再保证最终的一致性，通过在数据的高可用性和一致性之间的平衡，来解决高并发的数据读取问题。</p><h3 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h3><p>性能优化的过程首先要从发现短板开始，除了我今天介绍的一些优化措施外，你还可以在减少数据、数据分级（动静分离），以及减少中间环节、增加预处理等这些环节上做优化。</p><p>首先是“发现短板”，比如考虑以下因素的一些限制：光速（光速：C = 30 万千米 / 秒；光纤：V = C/1.5=20 万千米 / 秒，即数据传输是有物理距离的限制的）、网速（2017 年 11 月知名测速网站 Ookla 发布报告，全国平均上网带宽达到 61.24 Mbps，千兆带宽下 10KB 数据的极限 QPS 为 1.25 万 QPS=1000Mbps/8/10KB）、网络结构（交换机 / 网卡的限制）、TCP/IP、虚拟机（内存 /CPU/IO 等资源的限制）和应用本身的一些瓶颈等。</p><p>其次是减少数据。事实上，有两个地方特别影响性能，一是服务端在处理数据时不可避免地存在字符到字节的相互转化，二是 HTTP 请求时要做 Gzip 压缩，还有网络传输的耗时，这些都和数据大小密切相关。</p><p>再次，就是数据分级，也就是要保证首屏为先、重要信息为先，次要信息则异步加载，以这种方式提升用户获取数据的体验。</p><p>最后就是要减少中间环节，减少字符到字节的转换，增加预处理（提前做字符到字节的转换）去掉不需要的操作。</p><p>此外，要做好优化，你还需要做好应用基线，比如性能基线（何时性能突然下降）、成本基线（去年双 11 用了多少台机器）、链路基线（我们的系统发生了哪些变化），你可以通过这些基线持续关注系统的性能，做到在代码上提升编码质量，在业务上改掉不合理的调用，在架构和调用链路上不断的改进。</p><p>Read More:</p><blockquote><p><a href="https://d.shikey.com/jike/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E5%B7%B2%E5%AE%8C%E7%BB%93/20%20%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F-%E8%AE%B8%E4%BB%A4%E6%B3%A2/181005-05%20_%20%E5%BD%B1%E5%93%8D%E6%80%A7%E8%83%BD%E7%9A%84%E5%9B%A0%E7%B4%A0%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F%E5%8F%88%E8%AF%A5%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%80%A7%E8%83%BD%EF%BC%9F.html" target="_blank" rel="noopener">05 | 影响性能的因素有哪些？又该如何提高系统的性能？</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前面的几篇文章里，我介绍的内容多少都和优化有关：第一篇介绍了一些指导原则；第二篇和第三篇从动静分离和热点数据两个维度，介绍了如何有针对性地对数据进行区分和优化处理；第四篇介绍了在保证实现基本业务功能的前提下，尽量减少和过滤一些无效请求的思路。&lt;/p&gt;
&lt;p&gt;这几篇文章既是在
      
    
    </summary>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="秒杀系统" scheme="http://runnerliu.github.io/tags/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>秒杀系统设计05 - 流量削峰这事应该怎么做？</title>
    <link href="http://runnerliu.github.io/2021/07/04/miaosha05/"/>
    <id>http://runnerliu.github.io/2021/07/04/miaosha05/</id>
    <published>2021-07-04T02:22:23.000Z</published>
    <updated>2021-07-04T02:40:10.766Z</updated>
    
    <content type="html"><![CDATA[<p>如果你看过秒杀系统的流量监控图的话，你会发现它是一条直线，就在秒杀开始那一秒是一条很直很直的线，这是因为秒杀请求在时间上高度集中于某一特定的时间点。这样一来，就会导致一个特别高的流量峰值，它对资源的消耗是瞬时的。</p><p>但是对秒杀这个场景来说，最终能够抢到商品的人数是固定的，也就是说 100 人和 10000 人发起请求的结果都是一样的，并发度越高，无效请求也越多。</p><p>但是从业务上来说，秒杀活动是希望更多的人来参与的，也就是开始之前希望有更多的人来刷页面，但是真正开始下单时，秒杀请求并不是越多越好。因此我们可以设计一些规则，让并发的请求更多地延缓，而且我们甚至可以过滤掉一些无效请求。</p><h3 id="为什么要削峰"><a href="#为什么要削峰" class="headerlink" title="为什么要削峰"></a>为什么要削峰</h3><p>为什么要削峰呢？或者说峰值会带来哪些坏处？</p><p>我们知道服务器的处理资源是恒定的，你用或者不用它的处理能力都是一样的，所以出现峰值的话，很容易导致忙到处理不过来，闲的时候却又没有什么要处理。但是由于要保证服务质量，我们的很多处理资源只能按照忙的时候来预估，而这会导致资源的一个浪费。</p><p>这就好比因为存在早高峰和晚高峰的问题，所以有了错峰限行的解决方案。削峰的存在，一是可以让服务端处理变得更加平稳，二是可以节省服务器的资源成本。针对秒杀这一场景，削峰从本质上来说就是更多地延缓用户请求的发出，以便减少和过滤掉一些无效请求，它遵从“请求数要尽量少”的原则。</p><p>今天，我就来介绍一下流量削峰的一些操作思路：排队、答题、分层过滤。这几种方式都是无损（即不会损失用户的发出请求）的实现方案，当然还有些有损的实现方案，包括我们后面要介绍的关于稳定性的一些办法，比如限流和机器负载保护等一些强制措施也能达到削峰保护的目的，当然这都是不得已的一些措施，因此就不归类到这里了。</p><h4 id="排队"><a href="#排队" class="headerlink" title="排队"></a>排队</h4><p>要对流量进行削峰，最容易想到的解决方案就是用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另一端平滑地将消息推送出去。在这里，消息队列就像“水库”一样， 拦蓄上游的洪水，削减进入下游河道的洪峰流量，从而达到减免洪水灾害的目的。</p><p>用消息队列来缓冲瞬时流量的方案，如下图所示：</p><p><img src="/images/2021-7-4102313.png" alt="2021-7-4102313.png"></p><p>但是，如果流量峰值持续一段时间达到了消息队列的处理上限，例如本机的消息积压达到了存储空间的上限，消息队列同样也会被压垮，这样虽然保护了下游的系统，但是和直接把请求丢弃也没多大的区别。就像遇到洪水爆发时，即使是有水库恐怕也无济于事。</p><p>除了消息队列，类似的排队方式还有很多，例如：</p><ol><li>利用线程池加锁等待也是一种常用的排队方式；</li><li>先进先出、先进后出等常用的内存排队算法的实现方式；</li><li>把请求序列化到文件中，然后再顺序地读文件（例如基于 MySQL binlog 的同步机制）来恢复请求等方式。</li></ol><p>可以看到，这些方式都有一个共同特征，就是把“一步的操作”变成“两步的操作”，其中增加的一步操作用来起到缓冲的作用。</p><p>说到这里你可能会说，这样一来增加了访问请求的路径啊，并不符合我们介绍的“4 要 1 不要”原则。没错，的确看起来不太合理，但是如果不增加一个缓冲步骤，那么在一些场景下系统很可能会直接崩溃，所以最终还是需要你做出妥协和平衡。</p><h4 id="答题"><a href="#答题" class="headerlink" title="答题"></a>答题</h4><p>你是否还记得，最早期的秒杀只是纯粹地刷新页面和点击购买按钮，它是后来才增加了答题功能的。那么，为什么要增加答题功能呢？</p><p>这主要是为了增加购买的复杂度，从而达到两个目的。</p><p>第一个目的是防止部分买家使用秒杀器在参加秒杀时作弊。2011 年秒杀非常火的时候，秒杀器也比较猖獗，因而没有达到全民参与和营销的目的，所以系统增加了答题来限制秒杀器。增加答题后，下单的时间基本控制在 2s 后，秒杀器的下单比例也大大下降。答题页面如下图所示。</p><p><img src="/images/2021-7-4102422.png" alt="2021-7-4102422.png"></p><p>第二个目的其实就是延缓请求，起到对请求流量进行削峰的作用，从而让系统能够更好地支持瞬时的流量高峰。这个重要的功能就是把峰值的下单请求拉长，从以前的 1s 之内延长到 2s~10s。这样一来，请求峰值基于时间分片了。这个时间的分片对服务端处理并发非常重要，会大大减轻压力。而且，由于请求具有先后顺序，靠后的请求到来时自然也就没有库存了，因此根本到不了最后的下单步骤，所以真正的并发写就非常有限了。这种设计思路目前用得非常普遍，如当年支付宝的“咻一咻”、微信的“摇一摇”都是类似的方式。</p><p>这里，我重点说一下秒杀答题的设计思路。</p><p><img src="/images/2021-7-4102454.png" alt="2021-7-4102454.png"></p><p>如上图所示，整个秒杀答题的逻辑主要分为 3 部分。</p><ol><li><strong>题库生成模块</strong>，这个部分主要就是生成一个个问题和答案，其实题目和答案本身并不需要很复杂，重要的是能够防止由机器来算出结果，即防止秒杀器来答题。</li><li><strong>题库的推送模块</strong>，用于在秒杀答题前，把题目提前推送给详情系统和交易系统。题库的推送主要是为了保证每次用户请求的题目是唯一的，目的也是防止答题作弊。</li><li><strong>题目的图片生成模块</strong>，用于把题目生成为图片格式，并且在图片里增加一些干扰因素。这也同样是为防止机器直接来答题，它要求只有人才能理解题目本身的含义。这里还要注意一点，由于答题时网络比较拥挤，我们应该把题目的图片提前推送到 CDN 上并且要进行预热，不然的话当用户真正请求题目时，图片可能加载比较慢，从而影响答题的体验。</li></ol><p>其实真正答题的逻辑比较简单，很好理解：当用户提交的答案和题目对应的答案做比较，如果通过了就继续进行下一步的下单逻辑，否则就失败。我们可以把问题和答案用下面这样的 key 来进行 MD5 加密：</p><ul><li>问题 key：userId+itemId+question_Id+time+PK</li><li>答案 key：userId+itemId+answer+PK</li></ul><p>验证的逻辑如下图所示：</p><p><img src="/images/2021-7-4102527.png" alt="2021-7-4102527.png"></p><p>注意，这里面的验证逻辑，除了验证问题的答案以外，还包括用户本身身份的验证，例如是否已经登录、用户的 Cookie 是否完整、用户是否重复频繁提交等。</p><p>除了做正确性验证，我们还可以对提交答案的时间做些限制，例如从开始答题到接受答案要超过 1s，因为小于 1s 是人为操作的可能性很小，这样也能防止机器答题的情况。</p><h4 id="分层过滤"><a href="#分层过滤" class="headerlink" title="分层过滤"></a>分层过滤</h4><p>前面介绍的排队和答题要么是少发请求，要么对发出来的请求进行缓冲，而针对秒杀场景还有一种方法，就是对请求进行分层过滤，从而过滤掉一些无效的请求。分层过滤其实就是采用“漏斗”式设计来处理请求的，如下图所示。</p><p><img src="/images/2021-7-4102644.png" alt="2021-7-4102644.png"></p><p>假如请求分别经过 CDN、前台读系统（如商品详情系统）、后台系统（如交易系统）和数据库这几层，那么：</p><ul><li>大部分数据和流量在用户浏览器或者 CDN 上获取，这一层可以拦截大部分数据的读取；</li><li>经过第二层（即前台系统）时数据（包括强一致性的数据）尽量得走 Cache，过滤一些无效的请求；</li><li>再到第三层后台系统，主要做数据的二次检验，对系统做好保护和限流，这样数据量和请求就进一步减少；</li><li>最后在数据层完成数据的强一致性校验。</li></ul><p>这样就像漏斗一样，尽量把数据量和请求量一层一层地过滤和减少了。</p><p><strong>分层过滤的核心思想是：在不同的层次尽可能地过滤掉无效请求，让“漏斗”最末端的才是有效请求</strong>。而要达到这种效果，我们就必须对数据做分层的校验。</p><p>分层校验的基本原则是：</p><ol><li>将动态请求的读数据缓存（Cache）在 Web 端，过滤掉无效的数据读；</li><li>对读数据不做强一致性校验，减少因为一致性校验产生瓶颈的问题；</li><li>对写数据进行基于时间的合理分片，过滤掉过期的失效请求；</li><li>对写请求做限流保护，将超出系统承载能力的请求过滤掉；</li><li>对写数据进行强一致性校验，只保留最后有效的数据。</li></ol><p>分层校验的目的是：在读系统中，尽量减少由于一致性校验带来的系统瓶颈，但是尽量将不影响性能的检查条件提前，如用户是否具有秒杀资格、商品状态是否正常、用户答题是否正确、秒杀是否已经结束、是否非法请求、营销等价物是否充足等；在写数据系统中，主要对写的数据（如“库存”）做一致性检查，最后在数据库层保证数据的最终准确性（如“库存”不能减为负数）。</p><h3 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h3><p>今天，我介绍了如何在网站面临大流量冲击时进行请求的削峰，并主要介绍了削峰的 3 种处理方式：一个是通过队列来缓冲请求，即控制请求的发出；一个是通过答题来延长请求发出的时间，在请求发出后承接请求时进行控制，最后再对不符合条件的请求进行过滤；最后一种是对请求进行分层过滤。</p><p>其中，队列缓冲方式更加通用，它适用于内部上下游系统之间调用请求不平缓的场景，由于内部系统的服务质量要求不能随意丢弃请求，所以使用消息队列能起到很好的削峰和缓冲作用。</p><p>而答题更适用于秒杀或者营销活动等应用场景，在请求发起端就控制发起请求的速度，因为越到后面无效请求也会越多，所以配合后面介绍的分层拦截的方式，可以更进一步减少无效请求对系统资源的消耗。</p><p>分层过滤非常适合交易性的写请求，比如减库存或者拼车这种场景，在读的时候需要知道还有没有库存或者是否还有剩余空座位。但是由于库存和座位又是不停变化的，所以读的数据是否一定要非常准确呢？其实不一定，你可以放一些请求过去，然后在真正减的时候再做强一致性保证，这样既过滤一些请求又解决了强一致性读的瓶颈。</p><p>不过，在削峰的处理方式上除了采用技术手段，其实还可以采用业务手段来达到一定效果，例如在零点开启大促的时候由于流量太大导致支付系统阻塞，这个时候可以采用发放优惠券、发起抽奖活动等方式，将一部分流量分散到其他地方，这样也能起到缓冲流量的作用。</p><p>Read More:</p><blockquote><p><a href="https://d.shikey.com/jike/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E5%B7%B2%E5%AE%8C%E7%BB%93/20%20%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F-%E8%AE%B8%E4%BB%A4%E6%B3%A2/181004-04%20_%20%E6%B5%81%E9%87%8F%E5%89%8A%E5%B3%B0%E8%BF%99%E4%BA%8B%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F.html" target="_blank" rel="noopener">04 | 流量削峰这事应该怎么做？</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如果你看过秒杀系统的流量监控图的话，你会发现它是一条直线，就在秒杀开始那一秒是一条很直很直的线，这是因为秒杀请求在时间上高度集中于某一特定的时间点。这样一来，就会导致一个特别高的流量峰值，它对资源的消耗是瞬时的。&lt;/p&gt;
&lt;p&gt;但是对秒杀这个场景来说，最终能够抢到商品的人数
      
    
    </summary>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="秒杀系统" scheme="http://runnerliu.github.io/tags/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>秒杀系统设计04 - 二八原则：有针对性地处理好系统的“热点数据”</title>
    <link href="http://runnerliu.github.io/2021/07/04/miaosha04/"/>
    <id>http://runnerliu.github.io/2021/07/04/miaosha04/</id>
    <published>2021-07-04T02:19:42.000Z</published>
    <updated>2021-07-04T02:40:07.284Z</updated>
    
    <content type="html"><![CDATA[<p>假设你的系统中存储有几十亿上百亿的商品，而每天有千万级的商品被上亿的用户访问，那么肯定有一部分被大量用户访问的热卖商品，这就是我们常说的“热点商品”。</p><p>这些热点商品中最极端的例子就是秒杀商品，它们在很短时间内被大量用户执行访问、添加购物车、下单等操作，这些操作我们就称为“热点操作”。那么问题来了：这些热点对系统有啥影响，我们非要关注这些热点吗？</p><h3 id="为什么要关注热点"><a href="#为什么要关注热点" class="headerlink" title="为什么要关注热点"></a>为什么要关注热点</h3><p>我们一定要关注热点，因为热点会对系统产生一系列的影响。</p><p>首先，热点请求会大量占用服务器处理资源，虽然这个热点可能只占请求总量的亿分之一，然而却可能抢占 90% 的服务器资源，如果这个热点请求还是没有价值的无效请求，那么对系统资源来说完全是浪费。</p><p>其次，即使这些热点是有效的请求，我们也要识别出来做针对性的优化，从而用更低的代价来支撑这些热点请求。</p><p>既然热点对系统来说这么重要，那么热点到底包含哪些内容呢？</p><h3 id="什么是“热点”"><a href="#什么是“热点”" class="headerlink" title="什么是“热点”"></a>什么是“热点”</h3><p>热点分为<strong>热点操作</strong>和<strong>热点数据</strong>。所谓“热点操作”，例如大量的刷新页面、大量的添加购物车、双十一零点大量的下单等都属于此类操作。对系统来说，这些操作可以抽象为“读请求”和“写请求”，这两种热点请求的处理方式大相径庭，读请求的优化空间要大一些，而写请求的瓶颈一般都在存储层，优化的思路就是根据 CAP 理论做平衡，这个内容我在“减库存”一文再详细介绍。</p><p>而“热点数据”比较好理解，那就是用户的热点请求对应的数据。而热点数据又分为“静态热点数据”和“动态热点数据”。</p><p>所谓“静态热点数据”，就是能够提前预测的热点数据。例如，我们可以通过卖家报名的方式提前筛选出来，通过报名系统对这些热点商品进行打标。另外，我们还可以通过大数据分析来提前发现热点商品，比如我们分析历史成交记录、用户的购物车记录，来发现哪些商品可能更热门、更好卖，这些都是可以提前分析出来的热点。</p><p>所谓“动态热点数据”，就是不能被提前预测到的，系统在运行过程中临时产生的热点。例如，卖家在抖音上做了广告，然后商品一下就火了，导致它在短时间内被大量购买。</p><p>由于热点操作是用户的行为，我们不好改变，但能做一些限制和保护，所以本文我主要针对热点数据来介绍如何进行优化。</p><h3 id="发现热点数据"><a href="#发现热点数据" class="headerlink" title="发现热点数据"></a>发现热点数据</h3><p>前面，我介绍了如何对单个秒杀商品的页面数据进行动静分离，以便针对性地对静态数据做优化处理，那么另外一个关键的问题来了：如何发现这些秒杀商品，或者更准确地说，如何发现热点商品呢？</p><p>你可能会说“参加秒杀的商品就是秒杀商品啊”，没错，关键是系统怎么知道哪些商品参加了秒杀活动呢？所以，你要有一个机制提前来区分普通商品和秒杀商品。</p><p>我们从发现静态热点和发现动态热点两个方面来看一下。</p><h4 id="发现静态热点数据"><a href="#发现静态热点数据" class="headerlink" title="发现静态热点数据"></a>发现静态热点数据</h4><p>如前面讲的，静态热点数据可以通过商业手段，例如强制让卖家通过报名参加的方式提前把热点商品筛选出来，实现方式是通过一个运营系统，把参加活动的商品数据进行打标，然后通过一个后台系统对这些热点商品进行预处理，如提前进行缓存。但是这种通过报名提前筛选的方式也会带来新的问题，即增加卖家的使用成本，而且实时性较差，也不太灵活。</p><p>不过，除了提前报名筛选这种方式，你还可以通过技术手段提前预测，例如对买家每天访问的商品进行大数据计算，然后统计出 TOP N 的商品，我们可以认为这些 TOP N 的商品就是热点商品。</p><h4 id="发现动态热点数据"><a href="#发现动态热点数据" class="headerlink" title="发现动态热点数据"></a>发现动态热点数据</h4><p>我们可以通过卖家报名或者大数据预测这些手段来提前预测静态热点数据，但这其中有一个痛点，就是实时性较差，如果我们的系统能在秒级内自动发现热点商品那就完美了。</p><p>能够动态地实时发现热点不仅对秒杀商品，对其他热卖商品也同样有价值，所以我们需要想办法实现热点的动态发现功能。</p><p>这里我给出一个动态热点发现系统的具体实现。</p><ol><li>构建一个异步的系统，它可以收集交易链路上各个环节中的中间件产品的热点 Key，如 Nginx、缓存、RPC 服务框架等这些中间件（一些中间件产品本身已经有热点统计模块）。</li><li>建立一个热点上报和可以按照需求订阅的热点服务的下发规范，主要目的是通过交易链路上各个系统（包括详情、购物车、交易、优惠、库存、物流等）访问的时间差，把上游已经发现的热点透传给下游系统，提前做好保护。比如，对于大促高峰期，详情系统是最早知道的，在统一接入层上 Nginx 模块统计的热点 URL。</li><li>将上游系统收集的热点数据发送到热点服务台，然后下游系统（如交易系统）就会知道哪些商品会被频繁调用，然后做热点保护。</li></ol><p>这里我给出了一个图，其中用户访问商品时经过的路径有很多，我们主要是依赖前面的导购页面（包括首页、搜索页面、商品详情、购物车等）提前识别哪些商品的访问量高，通过这些系统中的中间件来收集热点数据，并记录到日志中。</p><p><img src="/images/2021-7-4102102.png" alt="2021-7-4102102.png"></p><p>我们通过部署在每台机器上的 Agent 把日志汇总到聚合和分析集群中，然后把符合一定规则的热点数据，通过订阅分发系统再推送到相应的系统中。你可以是把热点数据填充到 Cache 中，或者直接推送到应用服务器的内存中，还可以对这些数据进行拦截，总之下游系统可以订阅这些数据，然后根据自己的需求决定如何处理这些数据。</p><p>打造热点发现系统时，我根据以往经验总结了几点注意事项。</p><ol><li>这个热点服务后台抓取热点数据日志最好采用异步方式，因为“异步”一方面便于保证通用性，另一方面又不影响业务系统和中间件产品的主流程。</li><li>热点服务发现和中间件自身的热点保护模块并存，每个中间件和应用还需要保护自己。热点服务台提供热点数据的收集和订阅服务，便于把各个系统的热点数据透明出来。</li><li>热点发现要做到接近实时（3s 内完成热点数据的发现），因为只有做到接近实时，动态发现才有意义，才能实时地对下游系统提供保护。</li></ol><h3 id="处理热点数据"><a href="#处理热点数据" class="headerlink" title="处理热点数据"></a>处理热点数据</h3><p>处理热点数据通常有几种思路：<strong>一是优化，二是限制，三是隔离</strong>。</p><p>先来说说优化。优化热点数据最有效的办法就是缓存热点数据，如果热点数据做了动静分离，那么可以长期缓存静态数据。但是，缓存热点数据更多的是“临时”缓存，即不管是静态数据还是动态数据，都用一个队列短暂地缓存数秒钟，由于队列长度有限，可以采用 LRU 淘汰算法替换。</p><p>再来说说限制。限制更多的是一种保护机制，限制的办法也有很多，例如对被访问商品的 ID 做一致性 Hash，然后根据 Hash 做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。</p><p>最后介绍一下隔离。秒杀系统设计的第一个原则就是将这种热点数据隔离出来，不要让 1% 的请求影响到另外的 99%，隔离出来后也更方便对这 1% 的请求做针对性的优化。</p><p>具体到“秒杀”业务，我们可以在以下几个层次实现隔离。</p><ol><li><strong>业务隔离</strong>。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就有了已知热点，因此可以提前做好预热。</li><li><strong>系统隔离</strong>。系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外 99% 分开。秒杀可以申请单独的域名，目的也是让请求落到不同的集群中。</li><li><strong>数据隔离</strong>。秒杀所调用的数据大部分都是热点数据，比如会启用单独的 Cache 集群或者 MySQL 数据库来放热点数据，目的也是不想 0.01% 的数据有机会影响 99.99% 数据。</li></ol><p>当然了，实现隔离有很多种办法。比如，你可以按照用户来区分，给不同的用户分配不同的 Cookie，在接入层，路由到不同的服务接口中；再比如，你还可以在接入层针对 URL 中的不同 Path 来设置限流策略。服务层调用不同的服务接口，以及数据层通过给数据打标来区分等等这些措施，其目的都是把已经识别出来的热点请求和普通的请求区分开。</p><h3 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h3><p>本文与数据的动静分离不一样，它从另外一个维度对数据进行了区分处理。你要明白，区分的目的主要还是对读热点数据加以优化，对照“4 要 1 不要”原则，它可以减少请求量，也可以减少请求的路径。因为缓存的数据都是经过多个请求，或者从多个系统中获取的数据经过计算后的结果。</p><p>热点的发现和隔离不仅对“秒杀”这个场景有意义，对其他的高性能分布式系统也非常有价值，尤其是热点的隔离非常重要。我介绍了业务层面的隔离和数据层面的隔离方式，最重要最简单的方式就是独立出来一个集群，单独处理热点数据。</p><p>但是能够独立出来一个集群的前提还是首先能够发现热点，为此我介绍了发现热点的几种方式，比如人工标识、大数据统计计算，以及实时热点发现方案，希望能够给你启发。</p><p>Read More:</p><blockquote><p><a href="https://d.shikey.com/jike/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E5%B7%B2%E5%AE%8C%E7%BB%93/20%20%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F-%E8%AE%B8%E4%BB%A4%E6%B3%A2/181003-03%20_%20%E4%BA%8C%E5%85%AB%E5%8E%9F%E5%88%99%EF%BC%9A%E6%9C%89%E9%92%88%E5%AF%B9%E6%80%A7%E5%9C%B0%E5%A4%84%E7%90%86%E5%A5%BD%E7%B3%BB%E7%BB%9F%E7%9A%84%E2%80%9C%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE%E2%80%9D.html" target="_blank" rel="noopener">03 | 二八原则：有针对性地处理好系统的“热点数据”</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;假设你的系统中存储有几十亿上百亿的商品，而每天有千万级的商品被上亿的用户访问，那么肯定有一部分被大量用户访问的热卖商品，这就是我们常说的“热点商品”。&lt;/p&gt;
&lt;p&gt;这些热点商品中最极端的例子就是秒杀商品，它们在很短时间内被大量用户执行访问、添加购物车、下单等操作，这些操作
      
    
    </summary>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="秒杀系统" scheme="http://runnerliu.github.io/tags/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>秒杀系统设计03 - 如何才能做好动静分离？有哪些方案可选？</title>
    <link href="http://runnerliu.github.io/2021/07/04/miaosha03/"/>
    <id>http://runnerliu.github.io/2021/07/04/miaosha03/</id>
    <published>2021-07-04T02:14:24.000Z</published>
    <updated>2021-07-04T02:40:02.285Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇文章中，我介绍了秒杀系统在架构上要考虑的几个原则，我估计你很快就会问：“知易行难，这些原则应该怎么应用到系统中呢？”别急，从这篇文章开始，我就会逐一介绍秒杀系统的各个关键环节中涉及的关键技术。</p><p>今天我们就先来讨论第一个关键点：数据的动静分离。不知道你之前听过这个解决方案吗？不管你有没有听过，我都建议你先停下来思考动静分离的价值。如果你的系统还没有开始应用动静分离的方案，那你也可以想想为什么没有，是之前没有想到，还是说业务体量根本用不着？</p><p>不过我可以确信地说，如果你在一个业务飞速发展的公司里，并且你在深度参与公司内类秒杀类系统的架构或者开发工作，那么你迟早会想到动静分离的方案。为什么？很简单，<strong>秒杀的场景中，对于系统的要求其实就三个字：快、准、稳</strong>。</p><p>那怎么才能“快”起来呢？我觉得抽象起来讲，就只有两点，一点是提高单次请求的效率，一点是减少没必要的请求。今天我们聊到的“动静分离”其实就是瞄着这个大方向去的。</p><p>不知道你是否还记得，最早的秒杀系统其实是要刷新整体页面的，但后来秒杀的时候，你只要点击“刷新抢宝”按钮就够了，这种变化的本质就是动静分离，分离之后，客户端大幅度减少了请求的数据量。这不自然就“快”了吗？</p><h3 id="何为动静数据"><a href="#何为动静数据" class="headerlink" title="何为动静数据"></a>何为动静数据</h3><p>那到底什么才是动静分离呢？所谓“动静分离”，其实就是把用户请求的数据（如 HTML 页面）划分为“动态数据”和“静态数据”。</p><p>简单来说，<strong>“动态数据”和“静态数据”的主要区别就是看页面中输出的数据是否和 URL、浏览者、时间、地域相关，以及是否含有 Cookie 等私密数据</strong>。比如说：</p><ol><li>很多媒体类的网站，某一篇文章的内容不管是你访问还是我访问，它都是一样的。所以它就是一个典型的静态数据，但是它是个动态页面。</li><li>我们如果现在访问淘宝的首页，每个人看到的页面可能都是不一样的，淘宝首页中包含了很多根据访问者特征推荐的信息，而这些个性化的数据就可以理解为动态数据了。</li></ol><p>这里再强调一下，我们所说的静态数据，不能仅仅理解为传统意义上完全存在磁盘上的 HTML 页面，它也可能是经过 Java 系统产生的页面，但是它输出的页面本身不包含上面所说的那些因素。也就是所谓“动态”还是“静态”，并不是说数据本身是否动静，而是数据中是否含有和访问者相关的个性化数据。</p><p>还有一点要注意，就是页面中“不包含”，指的是“页面的 HTML 源码中不含有”，这一点务必要清楚。</p><p>理解了静态数据和动态数据，我估计你很容易就能想明白“动静分离”这个方案的来龙去脉了。分离了动静数据，我们就可以对分离出来的静态数据做缓存，有了缓存之后，静态数据的“访问效率”自然就提高了。</p><p>那么，怎样对静态数据做缓存呢？我在这里总结了几个重点。</p><p><strong>第一，你应该把静态数据缓存到离用户最近的地方</strong>。静态数据就是那些相对不会变化的数据，因此我们可以把它们缓存起来。缓存到哪里呢？常见的就三种，用户浏览器里、CDN 上或者在服务端的 Cache 中。你应该根据情况，把它们尽量缓存到离用户最近的地方。</p><p><strong>第二，静态化改造就是要直接缓存 HTTP 连接</strong>。相较于普通的数据缓存而言，你肯定还听过系统的静态化改造。静态化改造是直接缓存 HTTP 连接而不是仅仅缓存数据，如下图所示，Web 代理服务器根据请求 URL，直接取出对应的 HTTP 响应头和响应体然后直接返回，这个响应过程简单得连 HTTP 协议都不用重新组装，甚至连 HTTP 请求头也不需要解析。</p><p><img src="/images/2021-7-4101533.png" alt="2021-7-4101533.png"></p><p><strong>第三，让谁来缓存静态数据也很重要</strong>。不同语言写的 Cache 软件处理缓存数据的效率也各不相同。以 Java 为例，因为 Java 系统本身也有其弱点（比如不擅长处理大量连接请求，每个连接消耗的内存较多，Servlet 容器解析 HTTP 协议较慢），所以你可以不在 Java 层做缓存，而是直接在 Web 服务器层上做，这样你就可以屏蔽 Java 语言层面的一些弱点；而相比起来，Web 服务器（如 Nginx、Apache、Varnish）也更擅长处理大并发的静态文件请求。</p><h3 id="如何做动静分离的改造"><a href="#如何做动静分离的改造" class="headerlink" title="如何做动静分离的改造"></a>如何做动静分离的改造</h3><p>理解了动静态数据的“why”和“what”，接下来我们就要看“how”了。我们如何把动态页面改造成适合缓存的静态页面呢？其实也很简单，就是去除前面所说的那几个影响因素，把它们单独分离出来，做动静分离。</p><p>下面，我以典型的商品详情系统为例来详细介绍。这里，你可以先打开京东或者淘宝的商品详情页，看看这个页面里都有哪些动静数据。我们从以下 5 个方面来分离出动态内容。</p><ol><li><strong>URL 唯一化</strong>。商品详情系统天然地就可以做到 URL 唯一化，比如每个商品都由 ID 来标识，那么 <a href="http://item.xxx.com/item.htm?id=xxxx" target="_blank" rel="noopener">http://item.xxx.com/item.htm?id=xxxx</a> 就可以作为唯一的 URL 标识。为啥要 URL 唯一呢？前面说了我们是要缓存整个 HTTP 连接，那么以什么作为 Key 呢？就以 URL 作为缓存的 Key，例如以 id=xxx 这个格式进行区分。</li><li><strong>分离浏览者相关的因素</strong>。浏览者相关的因素包括是否已登录，以及登录身份等，这些相关因素我们可以单独拆分出来，通过动态请求来获取。</li><li><strong>分离时间因素</strong>。服务端输出的时间也通过动态请求获取。</li><li><strong>异步化地域因素</strong>。详情页面上与地域相关的因素做成异步方式获取，当然你也可以通过动态请求方式获取，只是这里通过异步获取更合适。</li><li><strong>去掉 Cookie</strong>。服务端输出的页面包含的 Cookie 可以通过代码软件来删除，如 Web 服务器 Varnish 可以通过 unset req.http.cookie 命令去掉 Cookie。注意，这里说的去掉 Cookie 并不是用户端收到的页面就不含 Cookie 了，而是说，在缓存的静态数据中不含有 Cookie。</li></ol><p>分离出动态内容之后，如何组织这些内容页就变得非常关键了。这里我要提醒你一点，因为这其中很多动态内容都会被页面中的其他模块用到，如判断该用户是否已登录、用户 ID 是否匹配等，所以这个时候我们应该将这些信息 JSON 化（用 JSON 格式组织这些数据），以方便前端获取。</p><p>前面我们介绍里用缓存的方式来处理静态数据。而动态内容的处理通常有两种方案：ESI（Edge Side Includes）方案和 CSI（Client Side Include）方案。</p><ol><li><strong>ESI 方案（或者 SSI）</strong>：即在 Web 代理服务器上做动态内容请求，并将请求插入到静态页面中，当用户拿到页面时已经是一个完整的页面了。这种方式对服务端性能有些影响，但是用户体验较好。</li><li><strong>CSI 方案</strong>。即单独发起一个异步 JavaScript 请求，以向服务端获取动态内容。这种方式服务端性能更佳，但是用户端页面可能会延时，体验稍差。</li></ol><h3 id="动静分离的几种架构方案"><a href="#动静分离的几种架构方案" class="headerlink" title="动静分离的几种架构方案"></a>动静分离的几种架构方案</h3><p>前面我们通过改造把静态数据和动态数据做了分离，那么如何在系统架构上进一步对这些动态和静态数据重新组合，再完整地输出给用户呢？</p><p>这就涉及对用户请求路径进行合理的架构了。根据架构上的复杂度，有 3 种方案可选：</p><ol><li>实体机单机部署；</li><li>统一 Cache 层；</li><li>上 CDN。</li></ol><h4 id="方案-1：实体机单机部署"><a href="#方案-1：实体机单机部署" class="headerlink" title="方案 1：实体机单机部署"></a>方案 1：实体机单机部署</h4><p>这种方案是将虚拟机改为实体机，以增大 Cache 的容量，并且采用了一致性 Hash 分组的方式来提升命中率。这里将 Cache 分成若干组，是希望能达到命中率和访问热点的平衡。Hash 分组越少，缓存的命中率肯定就会越高，但短板是也会使单个商品集中在一个分组中，容易导致 Cache 被击穿，所以我们应该适当增加多个相同的分组，来平衡访问热点和命中率的问题。</p><p>这里我给出了实体机单机部署方案的结构图，如下：</p><p><img src="/images/2021-7-4101659.png" alt="2021-7-4101659.png"></p><p>实体机单机部署有以下几个优点：</p><ol><li>没有网络瓶颈，而且能使用大内存；</li><li>既能提升命中率，又能减少 Gzip 压缩；</li><li>减少 Cache 失效压力，因为采用定时失效方式，例如只缓存 3 秒钟，过期即自动失效。</li></ol><p>这个方案中，虽然把通常只需要虚拟机或者容器运行的 Java 应用换成实体机，优势很明显，它会增加单机的内存容量，但是一定程度上也造成了 CPU 的浪费，因为单个的 Java 进程很难用完整个实体机的 CPU。</p><p>另外就是，一个实体机上部署了 Java 应用又作为 Cache 来使用，这造成了运维上的高复杂度，所以这是一个折中的方案。如果你的公司里，没有更多的系统有类似需求，那么这样做也比较合适，如果你们有多个业务系统都有静态化改造的需求，那还是建议把 Cache 层单独抽出来公用比较合理，如下面的方案 2 所示。</p><h4 id="方案-2：统一-Cache-层"><a href="#方案-2：统一-Cache-层" class="headerlink" title="方案 2：统一 Cache 层"></a>方案 2：统一 Cache 层</h4><p>所谓统一 Cache 层，就是将单机的 Cache 统一分离出来，形成一个单独的 Cache 集群。统一 Cache 层是个更理想的可推广方案，该方案的结构图如下：</p><p><img src="/images/2021-7-4101741.png" alt="2021-7-4101741.png"></p><p>将 Cache 层单独拿出来统一管理可以减少运维成本，同时也方便接入其他静态化系统。此外，它还有一些优点。</p><ol><li>单独一个 Cache 层，可以减少多个应用接入时使用 Cache 的成本。这样接入的应用只要维护自己的 Java 系统就好，不需要单独维护 Cache，而只关心如何使用即可。</li><li>统一 Cache 的方案更易于维护，如后面加强监控、配置的自动化，只需要一套解决方案就行，统一起来维护升级也比较方便。</li><li>可以共享内存，最大化利用内存，不同系统之间的内存可以动态切换，从而能够有效应对各种攻击。</li></ol><p>这种方案虽然维护上更方便了，但是也带来了其他一些问题，比如缓存更加集中，导致：</p><ol><li>Cache 层内部交换网络成为瓶颈；</li><li>缓存服务器的网卡也会是瓶颈；</li><li>机器少风险较大，挂掉一台就会影响很大一部分缓存数据。</li></ol><p>要解决上面这些问题，可以再对 Cache 做 Hash 分组，即一组 Cache 缓存的内容相同，这样能够避免热点数据过度集中导致新的瓶颈产生。</p><h4 id="方案-3：上-CDN"><a href="#方案-3：上-CDN" class="headerlink" title="方案 3：上 CDN"></a>方案 3：上 CDN</h4><p>在将整个系统做动静分离后，我们自然会想到更进一步的方案，就是将 Cache 进一步前移到 CDN 上，因为 CDN 离用户最近，效果会更好。</p><p>但是要想这么做，有以下几个问题需要解决。</p><ol><li><strong>失效问题</strong>。前面我们也有提到过缓存时效的问题，不知道你有没有理解，我再来解释一下。谈到静态数据时，我说过一个关键词叫“相对不变”，它的言外之意是“可能会变化”。比如一篇文章，现在不变，但如果你发现个错别字，是不是就会变化了？如果你的缓存时效很长，那用户端在很长一段时间内看到的都是错的。所以，这个方案中也是，我们需要保证 CDN 可以在秒级时间内，让分布在全国各地的 Cache 同时失效，这对 CDN 的失效系统要求很高。</li><li><strong>命中率问题</strong>。Cache 最重要的一个衡量指标就是“高命中率”，不然 Cache 的存在就失去了意义。同样，如果将数据全部放到全国的 CDN 上，必然导致 Cache 分散，而 Cache 分散又会导致访问请求命中同一个 Cache 的可能性降低，那么命中率就成为一个问题。</li><li><strong>发布更新问题</strong>。如果一个业务系统每周都有日常业务需要发布，那么发布系统必须足够简洁高效，而且你还要考虑有问题时快速回滚和排查问题的简便性。</li></ol><p>从前面的分析来看，将商品详情系统放到全国的所有 CDN 节点上是不太现实的，因为存在失效问题、命中率问题以及系统的发布更新问题。那么是否可以选择若干个节点来尝试实施呢？答案是“可以”，但是这样的节点需要满足几个条件：</p><ol><li>靠近访问量比较集中的地区；</li><li>离主站相对较远；</li><li>节点到主站间的网络比较好，而且稳定；</li><li>节点容量比较大，不会占用其他 CDN 太多的资源。</li></ol><p>最后，还有一点也很重要，那就是：节点不要太多。</p><p>基于上面几个因素，选择 CDN 的二级 Cache 比较合适，因为二级 Cache 数量偏少，容量也更大，让用户的请求先回源的 CDN 的二级 Cache 中，如果没命中再回源站获取数据，部署方式如下图所示：</p><p><img src="/images/2021-7-4101827.png" alt="2021-7-4101827.png"></p><p>使用 CDN 的二级 Cache 作为缓存，可以达到和当前服务端静态化 Cache 类似的命中率，因为节点数不多，Cache 不是很分散，访问量也比较集中，这样也就解决了命中率问题，同时能够给用户最好的访问体验，是当前比较理想的一种 CDN 化方案。</p><p>除此之外，CDN 化部署方案还有以下几个特点：</p><ol><li>把整个页面缓存在用户浏览器中；</li><li>如果强制刷新整个页面，也会请求 CDN；</li><li>实际有效请求，只是用户对“刷新抢宝”按钮的点击。</li></ol><p>这样就把 90% 的静态数据缓存在了用户端或者 CDN 上，当真正秒杀时，用户只需要点击特殊的“刷新抢宝”按钮，而不需要刷新整个页面。这样一来，系统只是向服务端请求很少的有效数据，而不需要重复请求大量的静态数据。</p><p>秒杀的动态数据和普通详情页面的动态数据相比更少，性能也提升了 3 倍以上。所以“抢宝”这种设计思路，让我们不用刷新页面就能够很好地请求到服务端最新的动态数据。</p><h3 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h3><p>今天，我主要介绍了实现动静分离的几种思路，并由易到难给出了几种架构方案，以及它们各自的优缺点。可以看到，不同的架构方案会引入不同的问题，比如我们把缓存数据从 CDN 上移到用户的浏览器里，针对秒杀这个场景是没问题的，但针对一般的商品可否也这样做呢？</p><p>你可能会问，存储在浏览器或 CDN 上，有多大区别？我的回答是：区别很大！因为在 CDN 上，我们可以做主动失效，而在用户的浏览器里就更不可控，如果用户不主动刷新的话，你很难主动地把消息推送给用户的浏览器。</p><p>另外，在什么地方把静态数据和动态数据合并并渲染出一个完整的页面也很关键，假如在用户的浏览器里合并，那么服务端可以减少渲染整个页面的 CPU 消耗。如果在服务端合并的话，就要考虑缓存的数据是否进行 Gzip 压缩了：如果缓存 Gzip 压缩后的静态数据可以减少缓存的数据量，但是进行页面合并渲染时就要先解压，然后再压缩完整的页面数据输出给用户；如果缓存未压缩的静态数据，这样不用解压静态数据，但是会增加缓存容量。虽然这些都是细节问题，但你在设计架构方案时都需要考虑清楚。</p><p>Read More:</p><blockquote><p><a href="https://d.shikey.com/jike/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E5%B7%B2%E5%AE%8C%E7%BB%93/20%20%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F-%E8%AE%B8%E4%BB%A4%E6%B3%A2/181002-02%20_%20%E5%A6%82%E4%BD%95%E6%89%8D%E8%83%BD%E5%81%9A%E5%A5%BD%E5%8A%A8%E9%9D%99%E5%88%86%E7%A6%BB%EF%BC%9F%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%B9%E6%A1%88%E5%8F%AF%E9%80%89%EF%BC%9F.html" target="_blank" rel="noopener">02 | 如何才能做好动静分离？有哪些方案可选？</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;上一篇文章中，我介绍了秒杀系统在架构上要考虑的几个原则，我估计你很快就会问：“知易行难，这些原则应该怎么应用到系统中呢？”别急，从这篇文章开始，我就会逐一介绍秒杀系统的各个关键环节中涉及的关键技术。&lt;/p&gt;
&lt;p&gt;今天我们就先来讨论第一个关键点：数据的动静分离。不知道你之前
      
    
    </summary>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="秒杀系统" scheme="http://runnerliu.github.io/tags/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>秒杀系统设计02 - 设计秒杀系统时应该注意的5个架构原则</title>
    <link href="http://runnerliu.github.io/2021/07/04/miaosha02/"/>
    <id>http://runnerliu.github.io/2021/07/04/miaosha02/</id>
    <published>2021-07-04T02:08:30.000Z</published>
    <updated>2021-07-04T02:39:59.389Z</updated>
    
    <content type="html"><![CDATA[<p>说起秒杀，我想你肯定不陌生，这两年，从双十一购物到春节抢红包，再到 12306 抢火车票，“秒杀”的场景处处可见。简单来说，秒杀就是在同一个时刻有大量的请求争抢购买同一个商品并完成交易的过程，用技术的行话来说就是大量的并发读和并发写。</p><p>不管是哪一门语言，并发都是程序员们最为头疼的部分。同样，对于一个软件而言也是这样，你可以很快增删改查做出一个秒杀系统，但是要让它支持高并发访问就没那么容易了。比如说，如何让系统面对百万级的请求流量不出故障？如何保证高并发情况下数据的一致性写？完全靠堆服务器来解决吗？这显然不是最好的解决方案。</p><p>在我看来，<strong>秒杀系统本质上就是一个满足大并发、高性能和高可用的分布式系统</strong>。今天，我们就来聊聊，如何在满足一个良好架构的分布式系统基础上，针对秒杀这种业务做到极致的性能改进。</p><h3 id="架构原则：“4-要-1-不要”"><a href="#架构原则：“4-要-1-不要”" class="headerlink" title="架构原则：“4 要 1 不要”"></a>架构原则：“4 要 1 不要”</h3><p>如果你是一个架构师，你首先要勾勒出一个轮廓，想一想如何构建一个超大流量并发读写、高性能，以及高可用的系统，这其中有哪些要素需要考虑。我把这些要素总结为“4 要 1 不要”。</p><h4 id="数据要尽量少"><a href="#数据要尽量少" class="headerlink" title="数据要尽量少"></a>数据要尽量少</h4><p>所谓“数据要尽量少”，首先是指用户请求的数据能少就少。请求的数据包括上传给系统的数据和系统返回给用户的数据（通常就是网页）。</p><p>为啥“数据要尽量少”呢？因为首先这些数据在网络上传输需要时间，其次不管是请求数据还是返回数据都需要服务器做处理，而服务器在写网络时通常都要做压缩和字符编码，这些都非常消耗 CPU，所以减少传输的数据量可以显著减少 CPU 的使用。例如，我们可以简化秒杀页面的大小，去掉不必要的页面装修效果，等等。</p><p>其次，“数据要尽量少”还要求系统依赖的数据能少就少，包括系统完成某些业务逻辑需要读取和保存的数据，这些数据一般是和后台服务以及数据库打交道的。调用其他服务会涉及数据的序列化和反序列化，而这也是 CPU 的一大杀手，同样也会增加延时。而且，数据库本身也容易成为一个瓶颈，所以和数据库打交道越少越好，数据越简单、越小则越好。</p><h4 id="请求数要尽量少"><a href="#请求数要尽量少" class="headerlink" title="请求数要尽量少"></a>请求数要尽量少</h4><p>用户请求的页面返回后，浏览器渲染这个页面还要包含其他的额外请求，比如说，这个页面依赖的 CSS/JavaScript、图片，以及 Ajax 请求等等都定义为“额外请求”，这些额外请求应该尽量少。因为浏览器每发出一个请求都多少会有一些消耗，例如建立连接要做三次握手，有的时候有页面依赖或者连接数限制，一些请求（例如 JavaScript）还需要串行加载等。另外，如果不同请求的域名不一样的话，还涉及这些域名的 DNS 解析，可能会耗时更久。所以你要记住的是，减少请求数可以显著减少以上这些因素导致的资源消耗。</p><p>例如，减少请求数最常用的一个实践就是合并 CSS 和 JavaScript 文件，把多个 JavaScript 文件合并成一个文件，在 URL 中用逗号隔开（<a href="https://g.xxx.com/tm/xx-b/4.0.94/mods/??module-preview/index.xtpl.js,module-jhs/index.xtpl.js,module-focus/index.xtpl.js）。这种方式在服务端仍然是单个文件各自存放，只是服务端会有一个组件解析这个" target="_blank" rel="noopener">https://g.xxx.com/tm/xx-b/4.0.94/mods/??module-preview/index.xtpl.js,module-jhs/index.xtpl.js,module-focus/index.xtpl.js）。这种方式在服务端仍然是单个文件各自存放，只是服务端会有一个组件解析这个</a> URL，然后动态把这些文件合并起来一起返回。</p><h4 id="路径要尽量短"><a href="#路径要尽量短" class="headerlink" title="路径要尽量短"></a>路径要尽量短</h4><p>所谓“路径”，就是用户发出请求到返回数据这个过程中，需求经过的中间的节点数。</p><p>通常，这些节点可以表示为一个系统或者一个新的 Socket 连接（比如代理服务器只是创建一个新的 Socket 连接来转发请求）。每经过一个节点，一般都会产生一个新的 Socket 连接。</p><p>然而，每增加一个连接都会增加新的不确定性。从概率统计上来说，加入一次请求经过 5 个节点，每个节点的可用性是 99.9% 的话，那么整个请求的可用性是：99.9% 的 5 次方，约等于 99.5%。</p><p>所以缩短请求路径不仅可以增加可用性，同样可以有效提升性能（减少中间节点可以减少数据的序列化与反序列化），并减少延时（可以减少网络传输耗时）。</p><p>要缩短访问路径有一种办法，就是多个相互强依赖的应用合并部署在一起，把远程过程调用（RPC）变成 JVM 内部之间的方法调用。在《大型网站技术架构演进与性能优化》一书中，我也有一章介绍了这种技术的详细实现。</p><h4 id="依赖要尽量少"><a href="#依赖要尽量少" class="headerlink" title="依赖要尽量少"></a>依赖要尽量少</h4><p>所谓依赖，指的是要完成一次用户请求必须依赖的系统或者服务，这里的依赖指的是强依赖。</p><p>举个例子，比如说你要展示秒杀页面，而这个页面必须强依赖商品信息、用户信息，还有其他如优惠券、成交列表等这些对秒杀不是非要不可的信息（弱依赖），这些弱依赖在紧急情况下就可以去掉。</p><p>要减少依赖，我们可以给系统进行分级，比如 0 级系统、1 级系统、2 级系统、3 级系统，0 级系统如果是最重要的系统，那么 0 级系统强依赖的系统也同样是最重要的系统，以此类推。</p><p>注意，0 级系统要尽量减少对 1 级系统的强依赖，防止重要的系统被不重要的系统拖垮。例如支付系统是 0 级系统，而优惠券是 1 级系统的话，在极端情况下可以把优惠券给降级，防止支付系统被优惠券这个 1 级系统给拖垮。</p><h4 id="不要有单点"><a href="#不要有单点" class="headerlink" title="不要有单点"></a>不要有单点</h4><p>系统中的单点可以说是系统架构上的一个大忌，因为单点意味着没有备份，风险不可控，我们设计分布式系统最重要的原则就是“消除单点”。</p><p>那如何避免单点呢？我认为关键点是避免将服务的状态和机器绑定，即把服务无状态化，这样服务就可以在机器中随意移动。</p><p>如何那把服务的状态和机器解耦呢？这里也有很多实现方式。例如把和机器相关的配置动态化，这些参数可以通过配置中心来动态推送，在服务启动时动态拉取下来，我们在这些配置中心设置一些规则来方便地改变这些映射关系。</p><p>应用无状态化是有效避免单点的一种方式，但是像存储服务本身很难无状态化，因为数据要存储在磁盘上，本身就要和机器绑定，那么这种场景一般要通过冗余多个备份的方式来解决单点问题。</p><p>前面介绍了这些设计上的一些原则，但是你有没有发现，我一直说的是“尽量”而不是“绝对”？</p><p>我想你肯定会问是不是请求最少就一定最好，我的答案是“不一定”。我们曾经把有些 CSS 内联进页面里，这样做可以减少依赖一个 CSS 的请求从而加快首页的渲染，但是同样也增大了页面的大小，又不符合“数据要尽量少”的原则，这种情况下我们为了提升首屏的渲染速度，只把首屏的 HTML 依赖的 CSS 内联进来，其他 CSS 仍然放到文件中作为依赖加载，尽量实现首屏的打开速度与整个页面加载性能的平衡。</p><p>所以说，<strong>架构是一种平衡的艺术，而最好的架构一旦脱离了它所适应的场景，一切都将是空谈</strong>。我希望你记住的是，这里所说的几点都只是一个个方向，你应该尽量往这些方向上去努力，但也要考虑平衡其他因素。</p><h3 id="不同场景下的不同架构案例"><a href="#不同场景下的不同架构案例" class="headerlink" title="不同场景下的不同架构案例"></a>不同场景下的不同架构案例</h3><p>前面我说了一些架构上的原则，那么针对“秒杀”这个场景，怎样才是一个好的架构呢？下面我以淘宝早期秒杀系统架构的演进为主线，来帮你梳理不同的请求体量下，我认为的最佳秒杀系统架构。</p><p>如果你想快速搭建一个简单的秒杀系统，只需要把你的商品购买页面增加一个“定时上架”功能，仅在秒杀开始时才让用户看到购买按钮，当商品的库存卖完了也就结束了。这就是当时第一个版本的秒杀系统实现方式。</p><p>但随着请求量的加大（比如从 1w/s 到了 10w/s 的量级），这个简单的架构很快就遇到了瓶颈，因此需要做架构改造来提升系统性能。这些架构改造包括：</p><ol><li>把秒杀系统独立出来单独打造一个系统，这样可以有针对性地做优化，例如这个独立出来的系统就减少了店铺装修的功能，减少了页面的复杂度；</li><li>在系统部署上也独立做一个机器集群，这样秒杀的大流量就不会影响到正常的商品购买集群的机器负载；</li><li>将热点数据（如库存数据）单独放到一个缓存系统中，以提高“读性能”；</li><li>增加秒杀答题，防止有秒杀器抢单。</li></ol><p>此时的系统架构变成了下图这个样子。最重要的就是，秒杀详情成为了一个独立的新系统，另外核心的一些数据放到了缓存（Cache）中，其他的关联系统也都以独立集群的方式进行部署。</p><p><img src="/images/2021-7-4101018.png" alt="2021-7-4101018.png"></p><p>然而这个架构仍然支持不了超过 100w/s 的请求量，所以为了进一步提升秒杀系统的性能，我们又对架构做进一步升级，比如：</p><ol><li>对页面进行彻底的动静分离，使得用户秒杀时不需要刷新整个页面，而只需要点击抢宝按钮，借此把页面刷新的数据降到最少；</li><li>在服务端对秒杀商品进行本地缓存，不需要再调用依赖系统的后台服务获取数据，甚至不需要去公共的缓存集群中查询数据，这样不仅可以减少系统调用，而且能够避免压垮公共缓存集群。</li><li>增加系统限流保护，防止最坏情况发生。</li></ol><p>经过这些优化，系统架构变成了下图中的样子。在这里，我们对页面进行了进一步的静态化，秒杀过程中不需要刷新整个页面，而只需要向服务端请求很少的动态数据。而且，最关键的详情和交易系统都增加了本地缓存，来提前缓存秒杀商品的信息，热点数据库也做了独立部署，等等。</p><p><img src="/images/2021-7-4101136.png" alt="2021-7-4101136.png"></p><p>从前面的几次升级来看，其实越到后面需要定制的地方越多，也就是越“不通用”。例如，把秒杀商品缓存在每台机器的内存中，这种方式显然不适合太多的商品同时进行秒杀的情况，因为单机的内存始终有限。所以要取得极致的性能，就要在其他地方（比如，通用性、易用性、成本等方面）有所牺牲。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>来让我们回顾下前面的内容，我首先介绍了构建大并发、高性能、高可用系统中几种通用的优化思路，并抽象总结为“4 要 1 不要”原则，也就是：数据要尽量少、请求数要尽量少、路径要尽量短、依赖要尽量少，以及不要有单点。当然，这几点是你要努力的方向，具体操作时还是要密切结合实际的场景和具体条件来进行。</p><p>然后，我给出了实际构建秒杀系统时，根据不同级别的流量，由简单到复杂打造的几种系统架构，希望能供你参考。当然，这里面我没有说具体的解决方案，比如缓存用什么、页面静态化用什么，因为这些对于架构来说并不重要，作为架构师，你应该时刻提醒自己主线是什么。</p><p>说了这么多，总体上我希望给你一个方向，就是想构建大并发、高性能、高可用的系统应该从哪几个方向上去努力，然后在不同性能要求的情况下系统架构应该从哪几个方面去做取舍。同时你也要明白，越追求极致性能，系统定制开发就会越多，同时系统的通用性也就会越差。</p><p>Read More:</p><blockquote><p><a href="https://d.shikey.com/jike/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E5%B7%B2%E5%AE%8C%E7%BB%93/20%20%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F-%E8%AE%B8%E4%BB%A4%E6%B3%A2/181001-01%20_%20%E8%AE%BE%E8%AE%A1%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E6%97%B6%E5%BA%94%E8%AF%A5%E6%B3%A8%E6%84%8F%E7%9A%845%E4%B8%AA%E6%9E%B6%E6%9E%84%E5%8E%9F%E5%88%99.html" target="_blank" rel="noopener">01 | 设计秒杀系统时应该注意的5个架构原则</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;说起秒杀，我想你肯定不陌生，这两年，从双十一购物到春节抢红包，再到 12306 抢火车票，“秒杀”的场景处处可见。简单来说，秒杀就是在同一个时刻有大量的请求争抢购买同一个商品并完成交易的过程，用技术的行话来说就是大量的并发读和并发写。&lt;/p&gt;
&lt;p&gt;不管是哪一门语言，并发都
      
    
    </summary>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="秒杀系统" scheme="http://runnerliu.github.io/tags/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>秒杀系统设计01 - 秒杀系统架构设计都有哪些关键点？</title>
    <link href="http://runnerliu.github.io/2021/07/04/miaosha01/"/>
    <id>http://runnerliu.github.io/2021/07/04/miaosha01/</id>
    <published>2021-07-04T02:04:40.000Z</published>
    <updated>2021-07-04T02:39:55.873Z</updated>
    
    <content type="html"><![CDATA[<p>你好，我是许令波，花名“君山”。说起来我的职业生涯算是比较简单，2009 年大学毕业后就进入了淘宝，一直工作了七年多。这七年多的时间里，我有幸看到了淘宝业务的快速增长，并且以开发者的身份参与其中。</p><p>说实话，作为一名程序员，我的技术能力也在公司业务的快速增长过程中得到了历练，并积累了一些大流量高并发网站架构设计和优化的经验，尤其是针对“秒杀”这个场景。因为我确信，那个时候我们肯定是对系统做了足够多的极致优化，才能扛住当时洪峰般的流量请求。</p><p>记得早期的时候，淘宝商品详情系统的 PV 还差不多是 1 亿的样子，但是到 2016 年差不多已经升至 50 亿了。尤其是 2012 年到 2014 年那个时间段，“秒杀”活动特别流行，用户的参与热情一浪高过一浪，系统要面对的流量也是成倍增长。</p><p>而每一次的秒杀活动对技术团队来说都是一次考验。现在想起来，那个时候我们整个团队，无所畏惧，逐步迭代创新，然后解决一个个难题的过程，也是极具挑战性和成就感的事情。</p><p>记得有一年，为了应对“双十一”，我们整个商品详情团队对系统做了很多优化，我们自认为已经是整个公司最牛的系统了，性能也已经是“业界之巅”。</p><p>但是那年“双十一”的晚上，我们的系统还是遇到了瓶颈。当时老大就跑过来盯着我们，问我们什么时候能够恢复，我们整个团队都承担着巨大的心理压力。</p><p>事后我们复盘宕机的原因，发现当时的秒杀流量远远超过了我们的预想，我们根本没想到大家的参与热情能有那么高。于是我们按照这个增长率去预估下一年的流量和服务器，粗算下来，我记得差不多要增加 2000 台服务器，简直不可思议。</p><p>怎么可能真正增加这么多机器，所以这也就倒逼我们必须找出一些特殊的手段来优化系统。后面，经过一段时间的调研和分析，我们想到了把整个系统进行动静分离改造的解决方案。</p><p>秒杀系统也差不多那个时候才从商品详情系统独立出来成为一个独立产品的。因为我见证了秒杀系统的建设过程，所以也有颇多感慨。秒杀系统的迭代又是一个升级打怪的过程，我们也都是遇到问题解决问题，逐一优化。</p><p>那么，如何才能更好地理解秒杀系统呢？我觉得作为一个程序员，你首先需要从高维度出发，从整体上思考问题。在我看来，<strong>秒杀其实主要解决两个问题，一个是并发读，一个是并发写</strong>。并发读的核心优化理念是尽量减少用户到服务端来“读”数据，或者让他们读更少的数据；并发写的处理原则也一样，它要求我们在数据库层面独立出来一个库，做特殊的处理。另外，我们还要针对秒杀系统做一些保护，针对意料之外的情况设计兜底方案，以防止最坏的情况发生。</p><p>而从一个架构师的角度来看，要想打造并维护一个超大流量并发读写、高性能、高可用的系统，在整个用户请求路径上从浏览器到服务端我们要遵循几个原则，就是要保证用户请求的数据尽量少、请求数尽量少、路径尽量短、依赖尽量少，并且不要有单点。这些关键点我会在后面的文章里重点讲解。</p><p><strong>其实，秒杀的整体架构可以概括为“稳、准、快”几个关键字。</strong></p><p>所谓“稳”，就是整个系统架构要满足高可用，流量符合预期时肯定要稳定，就是超出预期时也同样不能掉链子，你要保证秒杀活动顺利完成，即秒杀商品顺利地卖出去，这个是最基本的前提。</p><p>然后就是“准”，就是秒杀 10 台 iPhone，那就只能成交 10 台，多一台少一台都不行。一旦库存不对，那平台就要承担损失，所以“准”就是要求保证数据的一致性。</p><p>最后再看“快”，“快”其实很好理解，它就是说系统的性能要足够高，否则你怎么支撑这么大的流量呢？不光是服务端要做极致的性能优化，而且在整个请求链路上都要做协同的优化，每个地方快一点，整个系统就完美了。</p><p>所以从技术角度上看“稳、准、快”，就对应了我们架构上的高可用、一致性和高性能的要求，我们的专栏也将主要围绕这几个方面来展开，具体如下。</p><ul><li><strong>高性能。</strong> 秒杀涉及大量的并发读和并发写，因此支持高并发访问这点非常关键。本专栏将从设计数据的动静分离方案、热点的发现与隔离、请求的削峰与分层过滤、服务端的极致优化这 4 个方面重点介绍。</li><li><strong>一致性。</strong> 秒杀中商品减库存的实现方式同样关键。可想而知，有限数量的商品在同一时刻被很多倍的请求同时来减库存，减库存又分为“拍下减库存”“付款减库存”以及预扣等几种，在大并发更新的过程中都要保证数据的准确性，其难度可想而知。因此，我将用一篇文章来专门讲解如何设计秒杀减库存方案。</li><li><strong>高可用。</strong> 虽然我介绍了很多极致的优化思路，但现实中总难免出现一些我们考虑不到的情况，所以要保证系统的高可用和正确性，我们还要设计一个 PlanB 来兜底，以便在最坏情况发生时仍然能够从容应对。专栏的最后，我将带你思考可以从哪些环节来设计兜底方案。</li></ul><p>Read More:</p><blockquote><p><a href="https://d.shikey.com/jike/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E5%B7%B2%E5%AE%8C%E7%BB%93/20%20%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F-%E8%AE%B8%E4%BB%A4%E6%B3%A2/180925-%E5%BC%80%E7%AF%87%E8%AF%8D%20_%20%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B%E5%85%B3%E9%94%AE%E7%82%B9%EF%BC%9F.html" target="_blank" rel="noopener">开篇词 | 秒杀系统架构设计都有哪些关键点？</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;你好，我是许令波，花名“君山”。说起来我的职业生涯算是比较简单，2009 年大学毕业后就进入了淘宝，一直工作了七年多。这七年多的时间里，我有幸看到了淘宝业务的快速增长，并且以开发者的身份参与其中。&lt;/p&gt;
&lt;p&gt;说实话，作为一名程序员，我的技术能力也在公司业务的快速增长过程
      
    
    </summary>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    
      <category term="秒杀系统" scheme="http://runnerliu.github.io/tags/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="架构设计" scheme="http://runnerliu.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>GO系列 - 数据类型</title>
    <link href="http://runnerliu.github.io/2021/06/29/go-datatype/"/>
    <id>http://runnerliu.github.io/2021/06/29/go-datatype/</id>
    <published>2021-06-29T15:11:31.000Z</published>
    <updated>2021-06-29T15:41:08.833Z</updated>
    
    <content type="html"><![CDATA[<p>Go 语言按类别有以下几种数据类型：</p><table><thead><tr><th style="text-align:left">序号</th><th style="text-align:left">类型和描述</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><strong>布尔型</strong> <br>布尔型的值只可以是常量 true 或者 false。一个简单的例子：var b bool = true。</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><strong>数字类型</strong> <br>整型 int 和浮点型 float32、float64，Go 语言支持整型和浮点型数字，并且支持复数，其中位的运算采用补码。</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left"><strong>字符串类型</strong> <br>字符串就是一串固定长度的字符连接起来的字符序列。Go 的字符串是由单个字节连接起来的。Go 语言的字符串的字节使用 UTF-8 编码标识 Unicode 文本。</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left"><strong>派生类型</strong> <br>包括：(a) 指针类型 (b) 数组类型 (c) 结构化类型 (d) Channel 类型 (e) 函数类型 (f) 切片类型 (g) 接口类型 (h) Map 类型</td></tr></tbody></table><h3 id="数字类型"><a href="#数字类型" class="headerlink" title="数字类型"></a>数字类型</h3><table><thead><tr><th style="text-align:left">序号</th><th style="text-align:left">类型和描述</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><strong>uint8</strong> <br>无符号 8 位整型 (0 到 255)</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><strong>uint16</strong> <br>无符号 16 位整型 (0 到 65535)</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left"><strong>uint32</strong> <br>无符号 32 位整型 (0 到 4294967295)</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left"><strong>uint64</strong> <br>无符号 64 位整型 (0 到 18446744073709551615)</td></tr><tr><td style="text-align:left">5</td><td style="text-align:left"><strong>int8</strong> <br>有符号 8 位整型 (-128 到 127)</td></tr><tr><td style="text-align:left">6</td><td style="text-align:left"><strong>int16</strong> <br>有符号 16 位整型 (-32768 到 32767)</td></tr><tr><td style="text-align:left">7</td><td style="text-align:left"><strong>int32</strong> <br>有符号 32 位整型 (-2147483648 到 2147483647)</td></tr><tr><td style="text-align:left">8</td><td style="text-align:left"><strong>int64</strong> <br>有符号 64 位整型 (-9223372036854775808 到 9223372036854775807)</td></tr></tbody></table><h3 id="浮点型"><a href="#浮点型" class="headerlink" title="浮点型"></a>浮点型</h3><table><thead><tr><th style="text-align:left">序号</th><th style="text-align:left">类型和描述</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><strong>float32</strong> <br>IEEE-754 32位浮点型数</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><strong>float64</strong> <br>IEEE-754 64位浮点型数</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left"><strong>complex64</strong> <br>32 位实数和虚数</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left"><strong>complex128</strong> <br>64 位实数和虚数</td></tr></tbody></table><h3 id="其他数字类型"><a href="#其他数字类型" class="headerlink" title="其他数字类型"></a>其他数字类型</h3><table><thead><tr><th style="text-align:left">序号</th><th style="text-align:left">类型和描述</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><strong>byte</strong> <br>类似 uint8</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><strong>rune</strong> <br>类似 int32</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left"><strong>uint</strong> <br>32 或 64 位</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left"><strong>int</strong> <br>与 uint 一样大小</td></tr><tr><td style="text-align:left">5</td><td style="text-align:left"><strong>uintptr</strong> <br>无符号整型，用于存放一个指针</td></tr></tbody></table><p>Read More:</p><blockquote><p><a href="https://www.tutorialspoint.com/go/go_data_types.htm" target="_blank" rel="noopener">Go - Data Types</a></p><p><a href="https://www.runoob.com/go/go-data-types.html" target="_blank" rel="noopener">Go 语言数据类型</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Go 语言按类别有以下几种数据类型：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:left&quot;&gt;序号&lt;/th&gt;
&lt;th style=&quot;text-align:left&quot;&gt;类型和描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tb
      
    
    </summary>
    
      <category term="GO" scheme="http://runnerliu.github.io/categories/GO/"/>
    
    
      <category term="GO" scheme="http://runnerliu.github.io/tags/GO/"/>
    
  </entry>
  
  <entry>
    <title>Mysql系列 - 数据类型</title>
    <link href="http://runnerliu.github.io/2021/06/29/mysql-datatype/"/>
    <id>http://runnerliu.github.io/2021/06/29/mysql-datatype/</id>
    <published>2021-06-29T14:17:07.000Z</published>
    <updated>2021-06-29T15:06:19.725Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL支持多种类型，大致可以分为三类：数值、日期/时间和字符串（字符）类型。</p><h3 id="数值类型"><a href="#数值类型" class="headerlink" title="数值类型"></a>数值类型</h3><table><thead><tr><th style="text-align:left">类型</th><th style="text-align:left">存储字节数</th><th style="text-align:left">范围（有符号）</th><th style="text-align:left">范围（无符号）</th><th style="text-align:left">用途</th></tr></thead><tbody><tr><td style="text-align:left">TINYINT</td><td style="text-align:left">1</td><td style="text-align:left">-2^7 ~ 2^7 - 1</td><td style="text-align:left">0 ~ 2^8 - 1</td><td style="text-align:left">小整数值</td></tr><tr><td style="text-align:left">SMALLINT</td><td style="text-align:left">2</td><td style="text-align:left">-2^15 ~ 2^15 - 1</td><td style="text-align:left">0 ~ 2^16 - 1</td><td style="text-align:left">大整数值</td></tr><tr><td style="text-align:left">MEDIUMINT</td><td style="text-align:left">3</td><td style="text-align:left">-2^23 ~ 2^23 - 1</td><td style="text-align:left">0 ~ 2^24 - 1</td><td style="text-align:left">大整数值</td></tr><tr><td style="text-align:left">INT或INTEGER</td><td style="text-align:left">4</td><td style="text-align:left">-2^31 ~ 2^31 - 1</td><td style="text-align:left">0 ~ 2^32 - 1</td><td style="text-align:left">大整数值</td></tr><tr><td style="text-align:left">BIGINT</td><td style="text-align:left">8</td><td style="text-align:left">-2^63 ~ 2^63 - 1</td><td style="text-align:left">0 ~ 2^64 - 1</td><td style="text-align:left">极大整数值</td></tr><tr><td style="text-align:left">FLOAT</td><td style="text-align:left">4</td><td style="text-align:left">-3.402823466E+38 ~ -1.175494 351E-38)<br>0<br>1.175494351E-38 ~ 3.402823466351E+38</td><td style="text-align:left">0<br>1.175494351E-38 ~ 3.402823466E+38</td><td style="text-align:left">单精度 浮点数值</td></tr><tr><td style="text-align:left">DOUBLE</td><td style="text-align:left">8</td><td style="text-align:left">-1.7976931348623157E+308 ~ -2.225073858507201 4E-308<br>0<br>2.2250738585072014E-308 ~ 1.7976931348623157E+308</td><td style="text-align:left">0<br>2.2250738585072014E-308 ~ 1.7976931348623157E+308</td><td style="text-align:left">双精度 浮点数值</td></tr><tr><td style="text-align:left">DECIMAL</td><td style="text-align:left">DECIMAL(M,D) ，如果M&gt;D，为M+2，否则为D+2</td><td style="text-align:left">依赖于M和D的值</td><td style="text-align:left">依赖于M和D的值</td><td style="text-align:left">小数值</td></tr></tbody></table><p><strong>Double 和 Float 彼此的区别：</strong></p><ul><li><p>在内存中占有的字节数不同，单精度内存占4个字节，双精度内存占8个字节</p></li><li><p>有效数字位数不同（尾数），单精度小数点后有效位数7位,  双精度小数点后有效位数16位</p></li><li><p>数值取值范围不同，根据IEEE标准来计算</p></li><li><p>在程序中处理速度不同，一般来说，CPU处理单精度浮点数的速度比处理双精度浮点数快</p></li></ul><p><strong>Double 和 Float 彼此的优缺点：</strong></p><ul><li><p>Float单精度</p><ul><li>优点：Float单精度在一些处理器上比Double双精度更快而且只占用Double双精度一半的空间</li><li>缺点：但是当值很大或很小的时候，它将变得不精确</li></ul></li><li><p>Double双精度</p><ul><li>优点：Double 跟 Float比较, 必然是 Double 精度高，尾数可以有 16 位，而  Float 尾数精度只有 7 位</li><li>缺点：Double 双精度是消耗内存的，并且是 Float 单精度的两倍，Double 的运算速度比 Float 慢得多，因为Double 尾数比Float  的尾数多，所以计算起来必然是有开销的</li></ul></li></ul><h3 id="日期-时间类型"><a href="#日期-时间类型" class="headerlink" title="日期/时间类型"></a>日期/时间类型</h3><table><thead><tr><th style="text-align:left">类型</th><th style="text-align:left">存储字节数</th><th style="text-align:left">范围</th><th style="text-align:left">格式</th><th style="text-align:left">用途</th></tr></thead><tbody><tr><td style="text-align:left">DATE</td><td style="text-align:left">3</td><td style="text-align:left">1000-01-01 ~ 9999-12-31</td><td style="text-align:left">YYYY-MM-DD</td><td style="text-align:left">日期值</td></tr><tr><td style="text-align:left">TIME</td><td style="text-align:left">3</td><td style="text-align:left">-838:59:59 ~ 838:59:59</td><td style="text-align:left">HH:MM:SS</td><td style="text-align:left">时间值或持续时间</td></tr><tr><td style="text-align:left">YEAR</td><td style="text-align:left">1</td><td style="text-align:left">1901 ~ 2155</td><td style="text-align:left">YYYY</td><td style="text-align:left">年份值</td></tr><tr><td style="text-align:left">DATETIME</td><td style="text-align:left">8</td><td style="text-align:left">1000-01-01 00:00:00 ~ 9999-12-31 23:59:59</td><td style="text-align:left">YYYY-MM-DD HH:MM:SS</td><td style="text-align:left">混合日期和时间值</td></tr><tr><td style="text-align:left">TIMESTAMP</td><td style="text-align:left">4</td><td style="text-align:left">1970-01-01 00:00:01 UTC ~2038-01-19 03:14:07 UTC</td><td style="text-align:left">YYYYMMDD HHMMSS</td><td style="text-align:left">混合日期和时间值，时间戳</td></tr></tbody></table><h3 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h3><table><thead><tr><th style="text-align:left">类型</th><th style="text-align:left">存储字节数</th><th style="text-align:left">用途</th></tr></thead><tbody><tr><td style="text-align:left">CHAR</td><td style="text-align:left">0 ~ 255</td><td style="text-align:left">定长字符串</td></tr><tr><td style="text-align:left">VARCHAR</td><td style="text-align:left">0 ~ 65535</td><td style="text-align:left">变长字符串</td></tr><tr><td style="text-align:left">TINYBLOB</td><td style="text-align:left">0 ~ 255</td><td style="text-align:left">不超过 255 个字符的二进制字符串</td></tr><tr><td style="text-align:left">TINYTEXT</td><td style="text-align:left">0 ~ 255</td><td style="text-align:left">短文本字符串</td></tr><tr><td style="text-align:left">BLOB</td><td style="text-align:left">0 ~ 65535</td><td style="text-align:left">二进制形式的长文本数据</td></tr><tr><td style="text-align:left">TEXT</td><td style="text-align:left">0 ~ 65535</td><td style="text-align:left">长文本数据</td></tr><tr><td style="text-align:left">MEDIUMBLOB</td><td style="text-align:left">0 ~ 16777215</td><td style="text-align:left">二进制形式的中等长度文本数据</td></tr><tr><td style="text-align:left">MEDIUMTEXT</td><td style="text-align:left">0 ~ 16777 215</td><td style="text-align:left">中等长度文本数据</td></tr><tr><td style="text-align:left">LONGBLOB</td><td style="text-align:left">0 ~ 4294967295</td><td style="text-align:left">二进制形式的极大文本数据</td></tr><tr><td style="text-align:left">LONGTEXT</td><td style="text-align:left">0 ~ 4294967295</td><td style="text-align:left">极大文本数据</td></tr><tr><td style="text-align:left">ENUM</td><td style="text-align:left">0 ~ 65535</td><td style="text-align:left">枚举类型，只能存一个枚举字符串值</td></tr></tbody></table><p>Read More:</p><blockquote><p><a href="https://www.jianshu.com/p/672049b65691" target="_blank" rel="noopener">MySQL 之数据类型</a></p><p><a href="https://dev.mysql.com/doc/refman/8.0/en/data-types.html" target="_blank" rel="noopener">Chapter 11 Data Types</a></p><p><a href="https://www.runoob.com/mysql/mysql-data-types.html" target="_blank" rel="noopener">MySQL 数据类型</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;MySQL支持多种类型，大致可以分为三类：数值、日期/时间和字符串（字符）类型。&lt;/p&gt;
&lt;h3 id=&quot;数值类型&quot;&gt;&lt;a href=&quot;#数值类型&quot; class=&quot;headerlink&quot; title=&quot;数值类型&quot;&gt;&lt;/a&gt;数值类型&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;
      
    
    </summary>
    
      <category term="MySQL" scheme="http://runnerliu.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://runnerliu.github.io/tags/MySQL/"/>
    
      <category term="数据类型" scheme="http://runnerliu.github.io/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>I/O多路复用</title>
    <link href="http://runnerliu.github.io/2021/06/21/io-multiplexing/"/>
    <id>http://runnerliu.github.io/2021/06/21/io-multiplexing/</id>
    <published>2021-06-21T13:58:34.000Z</published>
    <updated>2021-06-21T14:50:22.364Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是IO多路复用"><a href="#什么是IO多路复用" class="headerlink" title="什么是IO多路复用"></a>什么是IO多路复用</h3><p>多路：多个socket连接或多个文件描述符</p><p>复用：复用同一个线程</p><p>简单理解：单线程或单进程同时监测若干个文件描述符是否可以执行IO操作的能力</p><h3 id="IO多路复用解决的问题"><a href="#IO多路复用解决的问题" class="headerlink" title="IO多路复用解决的问题"></a>IO多路复用解决的问题</h3><p>应用程序通常需要处理来自多条事件流中的事件，比如我现在用的电脑，需要同时处理键盘鼠标的输入、中断信号等等事件，再比如web服务器如nginx，需要同时处理来来自N个客户端的事件。</p><p>而CPU单核在同一时刻只能做一件事情，一种解决办法是对CPU进行分时复用，多个事件流将CPU切割成多个时间片，不同事件流的时间片交替进行。在计算机系统中，我们用线程或者进程来表示一条执行流，通过不同的线程或进程在操作系统内部的调度，来做到对CPU处理的分时复用。这样多个事件流就可以并发进行，不需要一个等待另一个太久，在用户看起来他们似乎就是并行在做一样。</p><p>但凡事都是有成本的。线程/进程也一样，有这么几个方面：</p><ul><li>线程/进程创建成本</li><li>CPU切换不同线程/进程成本 </li><li>多线程的资源竞争</li></ul><p>有没有一种可以在单线程/进程中处理多个事件流的方法呢？这就是IO多路复用要解决的问题。因此IO多路复用解决的本质问题是在<strong>用更少的资源完成更多的事</strong>。</p><h3 id="解释几个概念"><a href="#解释几个概念" class="headerlink" title="解释几个概念"></a>解释几个概念</h3><p>在介绍IO多路复用的实现之前，我们先来解释几个概念。</p><h4 id="用户空间-内核空间"><a href="#用户空间-内核空间" class="headerlink" title="用户空间/内核空间"></a>用户空间/内核空间</h4><p>现代操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。 操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操作系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。</p><p>针对Linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。</p><h4 id="进程切换"><a href="#进程切换" class="headerlink" title="进程切换"></a>进程切换</h4><p>为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的，并且进程切换是非常耗费资源的。</p><p>从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：</p><ol><li>保存处理机上下文，包括程序计数器和其他寄存器</li><li>更新PCB信息</li><li>把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列</li><li>选择另一个进程执行，并更新其PCB</li><li>更新内存管理的数据结构</li><li>恢复处理机上下文</li></ol><h4 id="进程阻塞"><a href="#进程阻塞" class="headerlink" title="进程阻塞"></a>进程阻塞</h4><p>正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得了CPU资源），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。</p><h4 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h4><p>文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。</p><h4 id="缓存I-O"><a href="#缓存I-O" class="headerlink" title="缓存I/O"></a>缓存I/O</h4><p>缓存I/O又称为标准I/O，大多数文件系统的默认I/O操作都是缓存I/O。在Linux的缓存I/O机制中，操作系统会将I/O的数据缓存在文件系统的页缓存中，即数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。</p><h3 id="IO多路复用的实现"><a href="#IO多路复用的实现" class="headerlink" title="IO多路复用的实现"></a>IO多路复用的实现</h3><h4 id="select"><a href="#select" class="headerlink" title="select"></a>select</h4><p>它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以<strong>select具有O(n)的无差别轮询复杂度</strong>，同时处理的流越多，无差别轮询时间就越长。</p><p>select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：</p><ul><li>单个进程所打开的FD是有限制的，通过 <code>FD_SETSIZE</code> 设置，默认1024</li><li><p>每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大，需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大</p></li><li><p>对 socket 扫描时是线性扫描，采用轮询的方法，效率较低（高并发）</p></li></ul><h4 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h4><p>poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， <strong>但是它没有最大连接数的限制</strong>，原因是它是基于链表来存储的。</p><p>poll与select类似，其缺点也是相同的：</p><ul><li>每次调用 poll ，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大</li><li>对 socket 扫描是线性扫描，采用轮询的方法，效率较低（高并发时）</li></ul><h4 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h4><p>epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时我们对这些流的操作都是有意义的，其复杂度降低到了O(1)。</p><p>epoll的优点如下：</p><ul><li>没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）</li><li>效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll</li><li>内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销</li></ul><h5 id="epoll函数接口"><a href="#epoll函数接口" class="headerlink" title="epoll函数接口"></a>epoll函数接口</h5><p>当某一进程调用epoll_create方法时，Linux内核会创建一个eventpoll结构体，这个结构体中有两个成员与epoll的使用方式密切相关。eventpoll结构体如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;sys/epoll.h&gt;</span><br><span class="line"></span><br><span class="line">// 数据结构</span><br><span class="line">// 每一个epoll对象都有一个独立的eventpoll结构体</span><br><span class="line">// 用于存放通过epoll_ctl方法向epoll对象中添加进来的事件</span><br><span class="line">// epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可</span><br><span class="line">struct eventpoll &#123;</span><br><span class="line">    /*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*/</span><br><span class="line">    struct rb_root  rbr;</span><br><span class="line">    /*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*/</span><br><span class="line">    struct list_head rdlist;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">// API</span><br><span class="line">int epoll_create(int size); // 内核中间加一个 ep 对象，把所有需要监听的 socket 都放到 ep 对象中</span><br><span class="line">int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // epoll_ctl 负责把 socket 增加、删除到内核红黑树</span><br><span class="line">int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);// epoll_wait 负责检测可读队列，没有可读 socket 则阻塞进程</span><br></pre></td></tr></table></figure><p>每一个epoll对象都有一个独立的eventpoll结构体，用于存放通过epoll_ctl方法向epoll对象中添加进来的事件。这些事件都会挂载在红黑树中，如此，重复添加的事件就可以通过红黑树而高效的识别出来(红黑树的插入时间效率是logn，其中n为红黑树元素个数)。</p><p>而所有添加到epoll中的事件都会与设备（网卡）驱动程序建立回调关系，也就是说，当相应的事件发生时会调用这个回调方法。这个回调方法在内核中叫ep_poll_callback,它会将发生的事件添加到rdlist双链表中。</p><p>在epoll中，对于每一个事件，都会建立一个epitem结构体，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">struct epitem&#123;</span><br><span class="line">    struct rb_node  rbn;//红黑树节点</span><br><span class="line">    struct list_head    rdllink;//双向链表节点</span><br><span class="line">    struct epoll_filefd  ffd;  //事件句柄信息</span><br><span class="line">    struct eventpoll *ep;    //指向其所属的eventpoll对象</span><br><span class="line">    struct epoll_event event; //期待发生的事件类型</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。</p><h4 id="select-poll-epoll之间的区别"><a href="#select-poll-epoll之间的区别" class="headerlink" title="select/poll/epoll之间的区别"></a>select/poll/epoll之间的区别</h4><p>select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。<strong>但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的</strong>，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 </p><p>epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现。</p><table><thead><tr><th></th><th>select</th><th>poll</th><th>epoll</th></tr></thead><tbody><tr><td>操作方式</td><td>遍历</td><td>遍历</td><td>回调</td></tr><tr><td>数据结构</td><td>bitmap</td><td>数组</td><td>红黑树</td></tr><tr><td>最大连接数</td><td>1024/2048</td><td>无上限</td><td>无上限</td></tr><tr><td>最大支持文件描述符数</td><td>有最大值限制</td><td>65535</td><td>65535</td></tr><tr><td>fd拷贝</td><td>每次调用select，都需要把fd集合从用户态拷贝到内核态</td><td>每次调用poll，都需要把fd集合从用户态拷贝到内核态</td><td>fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝</td></tr><tr><td>工作模式</td><td>LT</td><td>LT</td><td>ET</td></tr><tr><td>工作效率</td><td>每次调用都进行线性遍历，时间复杂度为O(n)</td><td>每次调用都进行线性遍历，时间复杂度为O(n)</td><td>事件通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到readyList里面，时间复杂度O(1)</td></tr></tbody></table><h3 id="常见的IO多路复用方案"><a href="#常见的IO多路复用方案" class="headerlink" title="常见的IO多路复用方案"></a>常见的IO多路复用方案</h3><p>redis: Linux下 epoll(level-triggered)，没有epoll用select</p><p>nginx: Linux下 epoll(edge-triggered)，没有epoll用select</p><p>Read More:</p><blockquote><p><a href="https://juejin.cn/post/6882984260672847879#heading-12" target="_blank" rel="noopener">彻底理解 IO 多路复用实现机制</a></p><p><a href="https://zhuanlan.zhihu.com/p/115220699" target="_blank" rel="noopener">一文看懂IO多路复用</a></p><p><a href="https://www.zhihu.com/question/28594409" target="_blank" rel="noopener">I/O多路复用技术（multiplexing）是什么？</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;什么是IO多路复用&quot;&gt;&lt;a href=&quot;#什么是IO多路复用&quot; class=&quot;headerlink&quot; title=&quot;什么是IO多路复用&quot;&gt;&lt;/a&gt;什么是IO多路复用&lt;/h3&gt;&lt;p&gt;多路：多个socket连接或多个文件描述符&lt;/p&gt;
&lt;p&gt;复用：复用同一个线程&lt;/p
      
    
    </summary>
    
      <category term="Linux" scheme="http://runnerliu.github.io/categories/Linux/"/>
    
    
      <category term="Linux" scheme="http://runnerliu.github.io/tags/Linux/"/>
    
      <category term="IO多路复用" scheme="http://runnerliu.github.io/tags/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>Redis系列 - 缓存雪崩、击穿、穿透、预热、更新</title>
    <link href="http://runnerliu.github.io/2021/05/23/redis-cachedown/"/>
    <id>http://runnerliu.github.io/2021/05/23/redis-cachedown/</id>
    <published>2021-05-23T13:31:09.000Z</published>
    <updated>2021-05-23T14:13:18.308Z</updated>
    
    <content type="html"><![CDATA[<h4 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h4><h5 id="产生原因"><a href="#产生原因" class="headerlink" title="产生原因"></a>产生原因</h5><p>在某一时刻缓存出现大规模的key失效，导致大量的请求直接打到了数据库上，进而导致数据库压力巨大，在高并发的情况下，瞬间就会将数据库打死宕机，这时如果运维临时重启数据库，马上又会有新的流量把数据库打死。这就是缓存雪崩。主要有以下两种原因：</p><ul><li>Redis宕机</li><li>缓存的key都在同一时间失效</li></ul><h5 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><ul><li>均匀过期：设置不同的过期时间，让缓存失效的时间尽量均匀，避免相同的过期时间导致缓存雪崩，造成大量数据库的访问</li><li>分级缓存：第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都不同</li><li>热点数据缓存永远不过期<ul><li>物理不过期，针对热点key不设置过期时间</li><li>逻辑过期，把过期时间存在key对应的value里，由后台任务周期性扫描过期时间刷新缓存</li></ul></li><li>保证Redis缓存的高可用，防止Redis宕机导致缓存雪崩的问题。可以使用 主从+ 哨兵，Redis集群来避免 Redis 全盘崩溃的情况。</li><li>在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降</li><li>使用熔断机制，限流降级。当流量达到一定的阈值，直接返回“系统繁忙”之类的提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果</li><li>开启Redis持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载数据恢复内存中的数据</li></ul><h4 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h4><h5 id="产生原因-1"><a href="#产生原因-1" class="headerlink" title="产生原因"></a>产生原因</h5><p>缓存击穿是某个热点的key失效，大并发集中对热点key进行请求，就会造成大量请求读缓存没读到数据，从而导致高并发访问数据库，引起数据库压力剧增。这种现象就叫做缓存击穿。</p><h5 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h5><ul><li>在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降</li><li>热点数据缓存永远不过期<ul><li>物理不过期，针对热点key不设置过期时间</li><li>逻辑过期，把过期时间存在key对应的value里，由后台任务周期性扫描过期时间刷新缓存</li></ul></li></ul><h4 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h4><h5 id="产生原因-2"><a href="#产生原因-2" class="headerlink" title="产生原因"></a>产生原因</h5><p>缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至导致数据库承受不住而宕机崩溃。</p><h5 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h5><ul><li>将无效的key存放进Redis中：当出现Redis查不到数据，数据库也查不到数据的情况，我们就把这个key保存到Redis中，设置value=”null”，并设置其过期时间较短，后面再出现查询这个key的请求的时候，直接返回null，就不需要再查询数据库了。但这种处理方式是有问题的，假如传进来的这个不存在的Key值每次都是随机的，那存进Redis也没有意义</li><li>对用户的请求参数进行合法性检验</li><li>使用布隆过滤器：如果布隆过滤器判定某个 key 不存在布隆过滤器中，那么就一定不存在，如果判定某个 key 存在，那么很大可能是存在（存在一定的误判率）。于是我们可以在缓存之前再加一个布隆过滤器，将数据库中的所有key都存储在布隆过滤器中，在查询Redis前先去布隆过滤器查询 key 是否存在，如果不存在就直接返回，不让其访问数据库，从而避免了对底层存储系统的查询压力</li></ul><h4 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h4><h5 id="产生原因-3"><a href="#产生原因-3" class="headerlink" title="产生原因"></a>产生原因</h5><p>缓存预热是指系统上线后，提前将相关的缓存数据加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据。如果不进行预热，那么Redis初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。</p><h5 id="解决方案-3"><a href="#解决方案-3" class="headerlink" title="解决方案"></a>解决方案</h5><ul><li>数据量不大的时候，工程启动的时候进行加载缓存动作</li><li>数据量大的时候，设置一个定时任务脚本，进行缓存的刷新</li><li>数据量太大的时候，优先保证热点数据进行提前加载到缓存</li></ul><h4 id="缓存更新"><a href="#缓存更新" class="headerlink" title="缓存更新"></a>缓存更新</h4><h5 id="产生原因-4"><a href="#产生原因-4" class="headerlink" title="产生原因"></a>产生原因</h5><p>缓存服务（Redis）和数据服务（数据库）是相互独立且异构的系统，在更新缓存或更新数据的时候无法做到原子性的同时更新两边的数据，因此在并发读写或第二步操作异常时会遇到各种数据不一致的问题。</p><p>缓存本身就是通过牺牲强一致性来提高性能，因此使用缓存提升性能，就会有数据更新的延迟性。这就需要我们在评估需求和设计阶段根据实际场景去做权衡了。</p><h5 id="解决方案-4"><a href="#解决方案-4" class="headerlink" title="解决方案"></a>解决方案</h5><p>缓存更新有四种方式：Cache Aside、Read Through、Write Through、Write Behind Caching。</p><h6 id="Cache-Aside"><a href="#Cache-Aside" class="headerlink" title="Cache Aside"></a>Cache Aside</h6><ul><li><p>失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。</p></li><li><p>命中：应用程序从cache中取数据，取到后返回。</p></li><li><p>更新：先把数据存到数据库中，成功后，再让缓存失效。</p></li></ul><h6 id="Read-Through"><a href="#Read-Through" class="headerlink" title="Read Through"></a>Read Through</h6><p>在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。</p><h6 id="Write-Through"><a href="#Write-Through" class="headerlink" title="Write Through"></a>Write Through</h6><p>当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）。</p><h6 id="Write-Behind-Caching"><a href="#Write-Behind-Caching" class="headerlink" title="Write Behind Caching"></a>Write Behind Caching</h6><p>又称 Write Back，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。</p><p>Read More:</p><blockquote><p><a href="https://segmentfault.com/a/1190000022029639" target="_blank" rel="noopener">Redis 缓存雪崩、击穿、穿透</a></p><p><a href="https://blog.csdn.net/a745233700/article/details/88088669" target="_blank" rel="noopener">Redis的缓存雪崩、缓存击穿、缓存穿透与缓存预热、缓存降级</a></p><p><a href="https://cloud.tencent.com/developer/article/1666384" target="_blank" rel="noopener">Redis系列 | 缓存穿透、击穿、雪崩、预热、更新、降级</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;缓存雪崩&quot;&gt;&lt;a href=&quot;#缓存雪崩&quot; class=&quot;headerlink&quot; title=&quot;缓存雪崩&quot;&gt;&lt;/a&gt;缓存雪崩&lt;/h4&gt;&lt;h5 id=&quot;产生原因&quot;&gt;&lt;a href=&quot;#产生原因&quot; class=&quot;headerlink&quot; title=&quot;产生原因&quot;&gt;&lt;/a
      
    
    </summary>
    
      <category term="Redis" scheme="http://runnerliu.github.io/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://runnerliu.github.io/tags/Redis/"/>
    
      <category term="缓存雪崩" scheme="http://runnerliu.github.io/tags/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/"/>
    
      <category term="缓存击穿" scheme="http://runnerliu.github.io/tags/%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/"/>
    
      <category term="缓存穿透" scheme="http://runnerliu.github.io/tags/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/"/>
    
      <category term="缓存预热" scheme="http://runnerliu.github.io/tags/%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD/"/>
    
      <category term="缓存更新" scheme="http://runnerliu.github.io/tags/%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
  <entry>
    <title>Mysql系列 - 回表查询和覆盖索引</title>
    <link href="http://runnerliu.github.io/2021/05/23/mysql-huibiao/"/>
    <id>http://runnerliu.github.io/2021/05/23/mysql-huibiao/</id>
    <published>2021-05-23T08:07:13.000Z</published>
    <updated>2021-06-03T01:40:25.233Z</updated>
    
    <content type="html"><![CDATA[<h4 id="回表查询"><a href="#回表查询" class="headerlink" title="回表查询"></a>回表查询</h4><p>通俗的讲就是，如果索引的列在 Select 所需获得的列中或者根据一次索引查询就能获得记录就不需要回表，如果 Select 所需获得列中有大量的非索引列，索引就需要到表中找到相应的列的信息，这就叫回表查询。</p><p>InnoDB聚集（聚簇）索引的叶子节点存储行记录，非叶子节点存储主键索引，因此， InnoDB必须要有且只有一个聚集索引：</p><p>（1）如果表定义了主键，则PK就是聚集索引；<br>（2）如果表没有定义主键，则第一个非空唯一索引（not NULL unique）列是聚集索引；<br>（3）否则，InnoDB会创建一个隐藏的row-id作为聚集索引；</p><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>建表如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create table user(</span><br><span class="line">    -&gt; id int(10) auto_increment,</span><br><span class="line">    -&gt; name varchar(30),</span><br><span class="line">    -&gt; age tinyint(4),</span><br><span class="line">    -&gt; primary key (id),</span><br><span class="line">    -&gt; index idx_age (age)</span><br><span class="line">    -&gt; )engine=innodb charset=utf8mb4;</span><br></pre></td></tr></table></figure><p>其中，id 字段是聚簇索引（主键索引），age 字段是普通索引（二级索引）</p><p>表中数据如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from user;</span><br><span class="line">+----+--------+------+</span><br><span class="line">| id | name  | age |</span><br><span class="line">+----+--------+------+</span><br><span class="line">| 1 | 张三  |  30 |</span><br><span class="line">| 2 | 李四  |  20 |</span><br><span class="line">| 3 | 王五  |  40 |</span><br><span class="line">| 4 | 刘八  |  10 |</span><br><span class="line">+----+--------+------+</span><br></pre></td></tr></table></figure><p>索引存储结构如下：</p><p>id是主键，聚簇索引结构如下</p><p><img src="/images/2021-5-23T161315.png" alt="2021-5-23T161315.png"></p><p>age是普通索引，非聚簇索引结构如下</p><p><img src="/images/2021-5-23T161415.png" alt="2021-5-23T161415.png"></p><p>如果查询条件为主键，则只需扫描一次B+树即可通过聚簇索引定位到要查找的行记录数据。如：<code>select * from user where id = 1</code></p><p><img src="/images/2021-5-23T161516.png" alt="2021-5-23T161516.png"></p><p>如果查询条件为普通索引（非聚簇索引），需要扫描两次B+树，第一次扫描通过普通索引定位到聚簇索引的值，然后第二次扫描通过聚簇索引的值定位到要查找的行记录数据。 如：<code>select * from user where age = 30</code></p><blockquote><p>先通过普通索引 age=30 定位到主键值 id=1</p><p>再通过聚集索引 id=1 定位到行记录数据</p></blockquote><p><img src="/images/2021-5-23T161626.png" alt="2021-5-23T161626.png"></p><p><img src="/images/2021-5-23T161710.png" alt="2021-5-23T161710.png"></p><h4 id="索引覆盖"><a href="#索引覆盖" class="headerlink" title="索引覆盖"></a>索引覆盖</h4><p>只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表，速度更快。</p><p>常见的方法是将被查询的字段建立到联合索引里去。</p><p>实现：<code>select id,age from user where age = 10</code></p><p>explain分析：因为age是普通索引，使用到了age索引，通过一次扫描B+树即可查询到相应的结果，这样就实现了覆盖索引</p><p><img src="/images/2021-5-23T161927.png" alt="2021-5-23T161927.png"></p><p>实现：<code>select id,age,name from user where age = 10</code></p><p>explain分析：age是普通索引，但name列不在索引树上，所以通过age索引在查询到id和age的值后，需要进行回表再查询name的值。此时的Extra列的NULL表示进行了回表查询</p><p><img src="/images/2021-5-23T162010.png" alt="2021-5-23T162010.png"></p><p>因此，为了实现索引覆盖，需要建组合索引 <code>idx_age_name(age,name)</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">drop index idx_age on user;</span><br><span class="line">create index idx_age_name on user(`age`,`name`);</span><br></pre></td></tr></table></figure><p>explain分析：此时字段age和name是组合索引idx_age_name，查询的字段id、age、name的值刚刚都在索引树上，只需扫描一次组合索引B+树即可，这就是实现了索引覆盖，此时的Extra字段为Using index表示使用了索引覆盖。</p><p><img src="/images/2021-5-23T162101.png" alt="2021-5-23T162101.png"></p><p>Read More:</p><blockquote><p><a href="https://juejin.cn/post/6844904062329028621" target="_blank" rel="noopener">MySQL 的覆盖索引与回表</a></p><p><a href="https://www.jianshu.com/p/d0d3de6832b9" target="_blank" rel="noopener">回表与覆盖索引，索引下推</a></p><p><a href="https://blog.csdn.net/CPLASF_/article/details/108799381" target="_blank" rel="noopener">mysql-回表查询是什么</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;回表查询&quot;&gt;&lt;a href=&quot;#回表查询&quot; class=&quot;headerlink&quot; title=&quot;回表查询&quot;&gt;&lt;/a&gt;回表查询&lt;/h4&gt;&lt;p&gt;通俗的讲就是，如果索引的列在 Select 所需获得的列中或者根据一次索引查询就能获得记录就不需要回表，如果 Select 
      
    
    </summary>
    
      <category term="MySQL" scheme="http://runnerliu.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://runnerliu.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Mysql系列 - 锁</title>
    <link href="http://runnerliu.github.io/2021/05/23/mysql-lock/"/>
    <id>http://runnerliu.github.io/2021/05/23/mysql-lock/</id>
    <published>2021-05-23T06:28:06.000Z</published>
    <updated>2021-07-04T02:44:46.824Z</updated>
    
    <content type="html"><![CDATA[<p>我们都知道事务的ACID性质（参考<a href="https://runnerliu.github.io/2017/08/28/mysqltransaction/">Mysql系列 - 事务</a>），数据库为了维护这些性质，尤其是一致性(C)和隔离性(I)，一般使用加锁这种方式，同时数据库又是个高并发的应用，同一时间会有大量的并发访问，如果加锁过度，会极大的降低并发处理能力。所以对于加锁的处理，可以说就是数据库对于事务处理的精髓所在。</p><h4 id="一次封锁or两段锁"><a href="#一次封锁or两段锁" class="headerlink" title="一次封锁or两段锁"></a>一次封锁or两段锁</h4><p>因为有大量的并发访问，为了预防死锁，一般应用中推荐使用一次封锁法，就是在方法的开始阶段，已经预先知道会用到哪些数据，然后全部锁住，在方法运行之后，再全部解锁。这种方式可以有效的避免循环死锁，但在数据库中却不适用，因为在事务开始阶段，数据库并不知道会用到哪些数据。</p><p>数据库遵循的是两段锁协议，将事务分成两个阶段，加锁阶段和解锁阶段（所以叫两段锁）：</p><ul><li>加锁阶段：在该阶段可以进行加锁操作。在对任何数据进行读操作之前要申请并获得S锁（共享锁，其它事务可以继续加共享锁，但不能加排它锁），在进行写操作之前要申请并获得X锁（排它锁，其它事务不能再获得任何锁）。加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。</li><li>解锁阶段：当事务释放了一个封锁以后，事务进入解锁阶段，在该阶段只能进行解锁操作不能再进行加锁操作。</li></ul><p>两段锁虽然无法避免死锁，但是可以保证事务的并发调度是串行化（串行化很重要，尤其是在数据恢复和备份的时候）的。</p><h4 id="锁类型"><a href="#锁类型" class="headerlink" title="锁类型"></a>锁类型</h4><p>从锁定资源的角度来看，MySQL 中的锁分为：</p><ul><li>表级锁：对整张表加锁。开销小，加锁快，不会出现死锁，锁定粒度大，发生锁冲突的概率最高，并发度最低。适合以查询为主。</li><li>行级锁：对行记录加锁。开销大，加锁慢，会出现死锁，锁定粒度最小，发生锁冲突的概率最低，并发度也最高。适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用。</li><li>页面锁：开销和加锁时间界于表锁和行锁之间，会出现死锁，锁定粒度界于表锁和行锁之间，并发度一般</li></ul><h5 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h5><p>InnoDB加行锁时通过给索引上的索引项加锁来实现，这种行锁实现特点意味着，只有通过索引条件检索条件数据，InnoDB才使用行锁，否则InnoDB将使用表锁。</p><p>行锁的加锁算法：</p><ul><li>记录锁 Record Locks：对单个记录的索引项加锁，即使表没有建立索引，InnoDB也会创建一个隐藏的聚簇索引(隐藏的递增主键索引)，并使用此索引进行记录锁定。</li><li>间隙锁 Gap Locks：锁定一个范围，但不包含记录本身，间隙锁作用在索引记录之间的间隔，又或者作用在第一个索引之前，最后一个索引之后的间隙。</li><li>Next-key锁：Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身。当查询的索引含有唯一属性时，InnoDB存储引擎会对Next-Key Lock 进行优化，将其降级为 Record Lock，即仅锁住索引本身，而不是范围。</li></ul><h5 id="意向共享锁"><a href="#意向共享锁" class="headerlink" title="意向共享锁"></a>意向共享锁</h5><p>一个事务给一个数据行加共享锁时，必须先获得表的意向共享锁</p><h5 id="共享锁"><a href="#共享锁" class="headerlink" title="共享锁"></a>共享锁</h5><p>共享锁又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁，共享锁可以同时加上多个。</p><p>加了共享锁后，该事务只能对数据进行读取而不能修改，并且其它事务只能加共享锁，不能加排他锁。</p><p>加锁方式：在执行语句后面加上 <code>lock in share mode</code> 就代表对某些资源加上共享锁了。</p><h5 id="意向排它锁"><a href="#意向排它锁" class="headerlink" title="意向排它锁"></a>意向排它锁</h5><p>一个事务给一个数据行加排他锁时，必须先获得表的意向排他锁</p><h5 id="排他锁"><a href="#排他锁" class="headerlink" title="排他锁"></a>排他锁</h5><p>排他锁又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，和其他的排他锁、共享锁都相斥。</p><p>事务对数据加上排他锁时，只允许此事务读取和修改此数据，并且其它事务不能对该数据加任何锁。</p><h5 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h5><p>悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。</p><p>悲观锁认为数据随时会被修改，因此每次读取数据之前都会上锁，防止其它事务读取或修改数据（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程），应用于数据更新比较频繁的场景。</p><p>悲观锁的实现方式：</p><ul><li>实现悲观锁时，我们必须先使用<code>set autocommit=0;</code>，关闭mysql的AutoCommit属性。因为我们查询出数据之后就要将该数据锁定，关闭自动提交后，我们需要手动开启事务。</li></ul><p>悲观锁的优点：</p><ul><li>悲观锁保证了数据处理时的安全性。</li></ul><p>悲观锁的缺点：</p><ul><li>加锁造成了开销增加，并且增加了死锁的机会。降低了并发性。</li></ul><h5 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h5><p>乐观锁不是数据库自带的，需要我们自己去实现。乐观锁是指操作数据库时（更新操作），想法很乐观，认为这次的操作不会导致冲突，在操作数据时，并不进行任何其他的特殊处理（也就是不加锁），而在进行更新后，再去判断是否有冲突，适用于读多写少的场景。</p><p>乐观锁的实现方式：</p><ul><li>版本号机制：加一个版本号或者时间戳字段，每次数据更新时同时更新这个字段。一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。</li><li>CAS算法：Compare And Swap（比较与交换），是一种有名的无锁算法。先读取想要更新的字段或者所有字段，更新的时候比较一下，只有字段没有变化才进行更新。一般情况下是一个自旋操作，即不断的重试。</li></ul><p>乐观锁的优点：</p><ul><li>乐观锁机制避免了长事务中的数据库加锁开销，大大提升了大并发量下的系统整体性能表现。</li></ul><p>乐观锁的缺点：</p><ul><li>ABA问题：如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 “ABA”问题。</li><li>循环时间长开销大：自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。</li></ul><h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><p>死锁是指两个或两个以上事务在执行过程中因争抢锁资源而造成的互相等待（形成环路）的现象。<strong>表级锁不会产生死锁</strong>，所以解决死锁主要还是针对于最常用的InnoDB。</p><p>死锁的解决：</p><ul><li><p>查出阻塞的进程，将其kill掉，将资源释放</p></li><li><p>设置锁的超时时间：InnoDB 行锁的等待时间，单位秒。可在会话级别设置，RDS 实例该参数的默认值为 50s。生产环境不推荐使用过大的 <code>innodb_lock_wait_timeout</code> 参数值该参数支持在会话级别修改，方便应用在会话级别单独设置某些特殊操作的行锁等待超时时</p></li><li><p>如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会</p></li><li><p>在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率</p></li><li><p>对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率，<strong>不推荐</strong></p></li></ul><p>Read More:</p><blockquote><p><a href="https://tech.meituan.com/2014/08/20/innodb-lock.html" target="_blank" rel="noopener">Innodb中的事务隔离级别和锁的关系</a></p><p><a href="https://www.jianshu.com/p/4f2311f38040" target="_blank" rel="noopener">深入理解MySQL数据库各种锁（总结）</a></p><p><a href="https://segmentfault.com/a/1190000022839728" target="_blank" rel="noopener">面试官：小伙子，给我说一下mysql 乐观锁和悲观锁吧</a></p><p><a href="https://zhuanlan.zhihu.com/p/29150809" target="_blank" rel="noopener">MySQL锁总结</a></p><p><a href="https://learnku.com/articles/39212?order_by=vote_count&amp;" target="_blank" rel="noopener">一张图彻底搞懂 MySQL 的锁机制</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我们都知道事务的ACID性质（参考&lt;a href=&quot;https://runnerliu.github.io/2017/08/28/mysqltransaction/&quot;&gt;Mysql系列 - 事务&lt;/a&gt;），数据库为了维护这些性质，尤其是一致性(C)和隔离性(I)，一般使用加锁
      
    
    </summary>
    
      <category term="MySQL" scheme="http://runnerliu.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://runnerliu.github.io/tags/MySQL/"/>
    
      <category term="Lock" scheme="http://runnerliu.github.io/tags/Lock/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ如何处理消息丢失</title>
    <link href="http://runnerliu.github.io/2021/05/18/rocketmq-msglost/"/>
    <id>http://runnerliu.github.io/2021/05/18/rocketmq-msglost/</id>
    <published>2021-05-18T14:28:36.000Z</published>
    <updated>2021-07-04T02:46:54.415Z</updated>
    
    <content type="html"><![CDATA[<h4 id="消息的发送过程"><a href="#消息的发送过程" class="headerlink" title="消息的发送过程"></a>消息的发送过程</h4><p><img src="/images/2021-5-18T223009.png" alt="2021-5-18T223009.png"></p><ul><li><p>生产阶段：Producer 新建消息，然后通过网络将消息投递给 MQ Broker</p></li><li><p>存储阶段：消息将会存储在 Broker 端磁盘中</p></li><li><p>消费阶段：Consumer 将会从 Broker 拉取消息</p></li></ul><p>以上任一阶段都可能会丢失消息，我们只要找到这三个阶段丢失消息原因，采用合理的办法避免丢失，就可以彻底解决消息丢失的问题。</p><h4 id="生产阶段"><a href="#生产阶段" class="headerlink" title="生产阶段"></a>生产阶段</h4><p>生产者（Producer） 通过网络发送消息给 Broker，当 Broker 收到之后，将会返回确认响应信息给 Producer。所以生产者只要接收到返回的确认响应，就代表消息在生产阶段未丢失。</p><h5 id="同步发送"><a href="#同步发送" class="headerlink" title="同步发送"></a>同步发送</h5><p>有三种Send方法，同步发送、异步发送、单向发送。我们可以采取同步发送的方式进行发送消息，发消息的时候会同步阻塞等待broker返回的结果，如果没成功，则不会收到SendResult，这种是最可靠的。其次是异步发送，在回调方法里可以得知是否发送成功。单向发送是最不靠谱的一种发送方式，我们无法保证消息真正可达。</p><h5 id="失败重试"><a href="#失败重试" class="headerlink" title="失败重试"></a>失败重试</h5><p>发送消息如果失败或者超时了，则会自动重试。默认是重试三次，可以根据API进行更改，比如改为10次：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">producer.setRetryTimesWhenSendFailed(10);</span><br></pre></td></tr></table></figure><h4 id="存储阶段"><a href="#存储阶段" class="headerlink" title="存储阶段"></a>存储阶段</h4><p>MQ持久化消息分为两种：同步刷盘和异步刷盘。</p><h5 id="同步刷盘"><a href="#同步刷盘" class="headerlink" title="同步刷盘"></a>同步刷盘</h5><p>默认情况是异步刷盘，Broker收到消息后会先存到Cache里然后立马通知Producer成功，然后Broker启动异步线程的去持久化到磁盘中，但是Broker还没持久化到磁盘就宕机的话，消息就丢失了。同步刷盘的话是收到消息存到Cache后并不会通知Producer说消息已经OK了，而是会等到持久化到磁盘中后才会通知Producer说消息完事了。这也保障了消息不会丢失，但是性能不如异步高。看业务场景取舍。</p><h5 id="主从同步复制"><a href="#主从同步复制" class="headerlink" title="主从同步复制"></a>主从同步复制</h5><p>即使Broker设置了同步刷盘策略，但是Broker刷完盘后磁盘坏了，这会导致盘上的消息全TM丢了。但是如果即使是1主1从了，但是Master刷完盘后还没来得及同步给Slave就磁盘坏了，也会导致消息丢失。所以我们还可以配置不仅是等Master刷完盘就通知Producer，而是等Master和Slave都刷完盘后才去通知Producer说消息OK了。</p><h4 id="消费阶段"><a href="#消费阶段" class="headerlink" title="消费阶段"></a>消费阶段</h4><p>消费者从 broker 拉取消息，然后执行相应的业务逻辑。一旦执行成功，将会返回 <code>ConsumeConcurrentlyStatus.CONSUME_SUCCESS</code> 状态给 Broker。如果 Broker 未收到消费确认响应或收到其他状态，消费者下次还会再次拉取到该条消息，进行重试。这样的方式有效避免了消费者消费过程发生异常，或者消息在网络传输中丢失的情况。</p><p>Read More:</p><blockquote><p><a href="https://www.cnblogs.com/goodAndyxublog/p/12563813.html" target="_blank" rel="noopener">面试官再问我如何保证 RocketMQ 不丢失消息,这回我笑了！</a></p><p><a href="https://blog.csdn.net/weixin_39601088/article/details/111343167" target="_blank" rel="noopener">udp怎么保证不丢包_从入门到入土（三）RocketMQ 怎么保证的消息不丢失？</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;消息的发送过程&quot;&gt;&lt;a href=&quot;#消息的发送过程&quot; class=&quot;headerlink&quot; title=&quot;消息的发送过程&quot;&gt;&lt;/a&gt;消息的发送过程&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;/images/2021-5-18T223009.png&quot; alt=&quot;2021-
      
    
    </summary>
    
      <category term="MQ" scheme="http://runnerliu.github.io/categories/MQ/"/>
    
    
      <category term="RocketMQ" scheme="http://runnerliu.github.io/tags/RocketMQ/"/>
    
      <category term="MQ" scheme="http://runnerliu.github.io/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>Websocket与Socket的区别</title>
    <link href="http://runnerliu.github.io/2021/05/18/websocket-socket/"/>
    <id>http://runnerliu.github.io/2021/05/18/websocket-socket/</id>
    <published>2021-05-18T14:01:07.000Z</published>
    <updated>2021-05-18T14:19:42.425Z</updated>
    
    <content type="html"><![CDATA[<p>WebSocket protocol 是HTML5一种新的协议，同HTTP一样也是应用层的协议，是建立在TCP之上的，它实现了浏览器与服务器全双工通信。客户端与服务端的握手需要借助HTTP请求完成。</p><p>Socket其实并不是一个协议，而是为了方便使用TCP或UDP而抽象出来的一层，是位于应用层和传输控制层之间的一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。</p><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><ul><li>Socket是传输控制层协议，WebSocket是应用层协议</li><li>Socket是一组接口，WebSocket是一个与HTTP属于同一层次的应用层协议，可与服务端进行全双工通信</li></ul><p>欢迎阅读 <a href="http://localhost:4000/2021/05/15/websocket-socketio/" target="_blank" rel="noopener">聊聊WebSocket与Socket.IO</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;WebSocket protocol 是HTML5一种新的协议，同HTTP一样也是应用层的协议，是建立在TCP之上的，它实现了浏览器与服务器全双工通信。客户端与服务端的握手需要借助HTTP请求完成。&lt;/p&gt;
&lt;p&gt;Socket其实并不是一个协议，而是为了方便使用TCP或UD
      
    
    </summary>
    
      <category term="WebSocket" scheme="http://runnerliu.github.io/categories/WebSocket/"/>
    
    
      <category term="WebSocket" scheme="http://runnerliu.github.io/tags/WebSocket/"/>
    
      <category term="Socket" scheme="http://runnerliu.github.io/tags/Socket/"/>
    
  </entry>
  
  <entry>
    <title>聊聊WebSocket与Socket.IO</title>
    <link href="http://runnerliu.github.io/2021/05/15/websocket-socketio/"/>
    <id>http://runnerliu.github.io/2021/05/15/websocket-socketio/</id>
    <published>2021-05-15T05:16:30.000Z</published>
    <updated>2021-05-15T09:41:43.405Z</updated>
    
    <content type="html"><![CDATA[<h4 id="什么是WebSocket"><a href="#什么是WebSocket" class="headerlink" title="什么是WebSocket"></a>什么是WebSocket</h4><p><a href="https://zh.wikipedia.org/wiki/WebSocket" target="_blank" rel="noopener">WebSocket</a> 是与HTTP不同的一种网络传输协议，是HTML5新增加的一种通信协议，目前流行的浏览器都支持该协议，例如 Chrome，Safrie，Firefox，Opera，IE等等。WebSocket的产生背景主要是为了方便客户端与服务器之间的双向通信，是一种全双工的数据通信机制。</p><h4 id="早期客户端与服务端通信方式"><a href="#早期客户端与服务端通信方式" class="headerlink" title="早期客户端与服务端通信方式"></a>早期客户端与服务端通信方式</h4><h5 id="Polling（短轮询）"><a href="#Polling（短轮询）" class="headerlink" title="Polling（短轮询）"></a>Polling（短轮询）</h5><p><img src="/images/2021-5-15T171622.png" alt="2021-5-15T171622.png"></p><p>这种方式下，Client 每隔一段时间都会向 Server 发送 HTTP 请求，服务器收到请求后，将最新的数据发回给 Client。一开始必须通过提交表单的形式，这样的后果就是传输很多冗余的数据，浪费了带宽。后来 Ajax 出现，减少了传输数据量。</p><p>如图所示，在 Client 向 Server 发送一个请求活动结束后，Server 中的数据发生了改变，所以 Client 向 Server 发送的第二次请求中，Server 会将最新的数据返回给 Client。</p><p>但这种方式也存在弊端。比如在某个时间段 Server 没有更新数据，但 Client 仍然每隔一段时间发送请求来询问，所以这段时间内的询问都是无效的，这样浪费了网络带宽。将发送请求的间隔时间加大会缓解这种浪费，但如果 Server 更新数据很快时，这样又不能满足数据的实时性。</p><h5 id="Comet"><a href="#Comet" class="headerlink" title="Comet"></a>Comet</h5><p>鉴于（短）轮询的弊端，一种基于 HTTP 长连接的 “服务器推” 的技术产生了，这种技术被命名为 Comet。其与（短）轮询主要区别就是，在轮询方式下，要想取得数据，必须首先发送请求，在实时性要求较高的情况下，只能增加向 Server 请求的频率；而 Comet 则不同，Client 与 Server 端保持一个长连接，只有数据发生改变时，Server 才主动将数据推送给 Client。Comet 又可以被细分为两种实现方式，一种是长轮询机制，一种是流技术。</p><h6 id="Long-Polling（长轮询）"><a href="#Long-Polling（长轮询）" class="headerlink" title="Long-Polling（长轮询）"></a>Long-Polling（长轮询）</h6><p><img src="/images/2021-5-15T171920.png" alt="2021-5-15T171920.png"></p><p>Client 向 Server 发出请求，Server 接收到请求后，Server 并不一定立即发送回应给 Client，而是看数据是否更新，如果数据已经更新了的话，那就立即将数据返回给 Client；但如果数据没有更新，那就把这个请求保持住，等待有新的数据到来时，才将数据返回给 Client。</p><p>当然了，如果 Server 的数据长时间没有更新，一段时间后，请求便会超时，Client 收到超时信息后，再立即发送一个新的请求给 Server。</p><p>如图所示，在长轮询机制下，Client 向 Server 发送了请求后，Server会等数据更新完才会将数据返回，而不是像（短）轮询一样不管数据有没有更新然后立即返回。</p><p>这种方式也有弊端。当 Server 向 Client 发送数据后，必须等待下一次请求才能将新的数据发送出去，这样 Client 接收到新数据的间隔最短时间便是 2 * RTT（往返时间），这样便无法应对 server 端数据更新频率较快的情况。</p><h6 id="HTTP-Streaming"><a href="#HTTP-Streaming" class="headerlink" title="HTTP Streaming"></a>HTTP Streaming</h6><p><img src="/images/2021-5-15T172057.png" alt="2021-5-15T172057.png"></p><p>流技术基于 Iframe。Iframe 是 HTML 标记，这个标记的 src 属性会保持对指定 Server 的长连接请求，Server 就可以不断地向 Client 返回数据。</p><p>可以看出，流技术与长轮询的区别是长轮询本质上还是一种轮询方式，只不过连接的时间有所增加，想要向 Server 获取新的数据，Client 只能一遍遍的发送请求；而流技术是一直保持连接，不需要 Client 请求，当数据发生改变时，Server 自动的将数据发送给 Client。</p><p>如图所示，Client 与 Server 建立连接之后，便不会断开。当数据发生变化，Server 便将数据发送给 Client。</p><p>但这种方式有一个明显的不足之处，网页会一直显示未加载完成的状态，虽然我没有强迫症，但这点还是难以忍受。</p><h4 id="WebSocket-原理"><a href="#WebSocket-原理" class="headerlink" title="WebSocket 原理"></a>WebSocket 原理</h4><p>写到现在，大家会发现，前人推出那么多的解决方案，想要解决的唯一的问题便是怎么让 Server 将最新的数据以最快的速度发送给 Client。但 HTTP 是个懒惰的协议，Server 只有收到请求才会做出回应，否则什么事都不干。因此，为了彻底解决这个 Server 主动向 Client 发送数据的问题，WebSocket应运而生。<strong>WebSocket 是一个全新的、独立的协议，基于 TCP 协议，与 HTTP 协议兼容却不会融入 HTTP 协议，仅仅作为 HTML5 的一部分</strong>。</p><p><img src="/images/2021-5-15T172947.png" alt="2021-5-15T172947.png"></p><p>那 WebSocket 与 HTTP 什么关系呢？简单来说，WebSocket 是一种协议，是一种与 HTTP 同等的网络协议，两者都是应用层协议，都基于 TCP 协议。但是 WebSocket 是一种双向通信协议，在建立连接之后，WebSocket 的 Server 与 Client 都能主动向对方发送或接收数据。同时，WebSocket 在建立连接时需要借助 HTTP 协议，连接建立好了之后 Client 与 Server 之间的双向通信就与 HTTP 无关了。</p><p><img src="/images/2021-5-15T172730.png" alt="2021-5-15T172730.png"></p><p>相比于传统 HTTP 的每次“请求-应答”都要 Client 与 Server 建立连接的模式，WebSocket 是一种长连接的模式。一旦 WebSocket 连接建立后，除非 Client 或者 Server 中有一端主动断开连接，否则每次数据传输之前都不需要 HTTP 那样请求数据。从上面的图可以看出，Client 第一次需要与 Server 建立连接，当 Server 确认连接之后，两者便一直处于连接状态。直到一方断开连接，WebSocket 连接才断开。</p><h4 id="WebSocket的优势"><a href="#WebSocket的优势" class="headerlink" title="WebSocket的优势"></a>WebSocket的优势</h4><ul><li>较少的控制开销。在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小。在不包含扩展的情况下，对于服务器到客户端的内容，此头部大小只有2至10字节（和数据包长度有关）；对于客户端到服务器的内容，此头部还需要加上额外的4字节的掩码。相对于HTTP请求每次都要携带完整的头部，此项开销显著减少了。</li><li>更强的实时性。由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少；即使是和Comet等类似的长轮询比较，其也能在短时间内更多次地传递数据。</li><li>保持连接状态。与HTTP不同的是，Websocket需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。而HTTP请求可能需要在每个请求都携带状态信息（如身份认证等）。</li><li>更好的二进制支持。Websocket定义了二进制帧，相对HTTP，可以更轻松地处理二进制内容。</li><li>可以支持扩展。Websocket定义了扩展，用户可以扩展协议、实现部分自定义的子协议。如部分浏览器支持压缩等。</li><li>更好的压缩效果。相对于HTTP压缩，Websocket在适当的扩展支持下，可以沿用之前内容的上下文，在传递类似的数据时，可以显著地提高压缩率。</li></ul><h4 id="什么是Socket-IO"><a href="#什么是Socket-IO" class="headerlink" title="什么是Socket.IO"></a>什么是Socket.IO</h4><p><a href="https://zh.wikipedia.org/wiki/Socket.IO" target="_blank" rel="noopener">Socket.IO</a> 是一个封装了 Websocket、基于 Node 的 JavaScript 框架，包含 Client 的 JavaScript 和 Server 的 Node。其屏蔽了所有底层细节，让顶层调用非常简单。其不仅支持 WebSocket，还支持许多种轮询机制以及其他实时通信方式，并封装了通用的接口。这些方式包含 Adobe Flash Socket、Ajax 长轮询、Ajax multipart streaming 、持久 Iframe、JSONP 轮询等。换句话说，当 Socket.IO 检测到当前环境不支持 WebSocket 时，能够自动地选择最佳的方式来实现网络的实时通信。</p><p>Read More:</p><blockquote><p><a href="https://zhuanlan.zhihu.com/p/23467317" target="_blank" rel="noopener">WebSocket 与 Socket.IO</a></p><p><a href="https://www.jianshu.com/p/144b997e57b4" target="_blank" rel="noopener">（一）websocket和socket.io介绍</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;什么是WebSocket&quot;&gt;&lt;a href=&quot;#什么是WebSocket&quot; class=&quot;headerlink&quot; title=&quot;什么是WebSocket&quot;&gt;&lt;/a&gt;什么是WebSocket&lt;/h4&gt;&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.
      
    
    </summary>
    
      <category term="WebSocket" scheme="http://runnerliu.github.io/categories/WebSocket/"/>
    
    
      <category term="WebSocket" scheme="http://runnerliu.github.io/tags/WebSocket/"/>
    
      <category term="Socket.IO" scheme="http://runnerliu.github.io/tags/Socket-IO/"/>
    
  </entry>
  
  <entry>
    <title>Mysql系列 - 索引</title>
    <link href="http://runnerliu.github.io/2021/02/20/mysql-index/"/>
    <id>http://runnerliu.github.io/2021/02/20/mysql-index/</id>
    <published>2021-02-20T08:54:14.000Z</published>
    <updated>2021-06-03T01:40:28.922Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p> 索引是存储引擎用于快速找到记录的一种数据结构</p></blockquote><p>这是MySQL官方对于索引的定义，可以看到索引是一种数据结构，那么我们应该怎样理解索引呢？一个常见的例子就是书的目录。我们都已经养成了看目录的习惯，拿到一本书时，我们首先会先去查看他的目录，并且当我们要查找某个内容时，我们会在目录中查找，然后找到该片段对应的页码，再根据相应的页码去书中查找。如果没有索引(目录)的话，我们就只能一页一页的去查找了。</p><h3 id="索引优缺点"><a href="#索引优缺点" class="headerlink" title="索引优缺点"></a>索引优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li>减少查询需要扫描的数据量(加快了查询速度)</li><li>减少服务器的排序操作和创建临时表的操作(加快了groupby和orderby等操作)</li><li>将服务器的随机IO变为顺序IO(加快查询速度)</li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li>索引占用磁盘或者内存空间</li><li>减慢了插入更新操作的速度</li></ul><h3 id="索引类型"><a href="#索引类型" class="headerlink" title="索引类型"></a>索引类型</h3><p>从存储结构划分</p><ul><li>Btree索引（B+tree，B-tree)</li><li>哈希索引</li><li>全文索引 </li><li>RTree</li></ul><p>从应用层次划分</p><ul><li>普通索引：即一个索引只包含单个列，一个表可以有多个单列索引。<code>ALTER TABLE table_name ADD INDEX index_name (column)</code></li><li>唯一索引：索引列的值必须唯一，但允许有空值。<code>ALTER TABLE table_name ADD UNIQUE (column)</code></li><li>主键索引：特殊的唯一索引，不允许为空，只能有一个，一般是在建表时指定。<code>ALTER TABLE table_name ADD PRIMARY KEY (column)</code></li><li>组合索引：在多个字段上创建索引，遵循<strong>最左前缀原则</strong>。<code>ALTER TABLE table_name ADD INDEX index_name (column1,column2,column3)</code></li></ul><p>从表记录的排列顺序和索引的排列顺序是否一致划分</p><ul><li>聚集索引：表记录的排列顺序和索引的排列顺序一致，查询效率快，因为只要找到第一个索引值记录，其余的连续性的记录在物理表中也会连续存放，一起就可以查询到。</li><li>非聚集索引：表记录的排列顺序和索引的排列顺序不一致，非聚集索引在叶子节点存储的是主键和索引列，当我们使用非聚集索引查询数据时，需要拿到叶子上的主键再去表中查到想要查找的数据。这个过程就是回表。</li></ul><p>聚集索引和非聚集索引区别：</p><blockquote><p>聚集索引在叶子节点存储的是表中的数据，非聚集索引在叶子节点存储的是主键和索引列。</p></blockquote><p>比如汉语字典，想要查「阿」字，只需要翻到字典前几页，a开头的位置，接着「啊」「爱」都会出来。也就是说，字典的正文部分本身就是一个目录，不需要再去查其他目录来找到需要找的内容。我们把这种正文内容本身就是一种按照一定规则排列的目录称为聚集索引。</p><p>比如要查“玉”字，我们可以看到在查部首之后的检字表中“玉”的页码是587页，然后是珏，是251页。很显然，在字典中这两个字并没有挨着，现在看到的连续的“玉、珏、莹”三字实际上就是他们在非聚集索引中的排序，是字典正文中的字在非聚集索引中的映射。我们可以通过这种方式来找到所需要的字，但它需要两个过程，先找到目录中的结果，然后再翻到结果所对应的页码。我们把这种目录纯粹是目录，正文纯粹是正文的排序方式称为非聚集索引。</p><h3 id="索引建立原则"><a href="#索引建立原则" class="headerlink" title="索引建立原则"></a>索引建立原则</h3><ul><li><strong>索引并非越多越好</strong>，大量索引不仅占用磁盘空间，而且会影响INSERT、DELETE、UPDATE等语句的性能，表数据更改的同时，索引也会进行调整和更新</li><li><strong>避免对经常更新的表进行过多的索引</strong>，并且索引中的列尽可能少。而对经常用于查询的字段应该创建索引，但要避免添加不必要的字段</li><li><strong>数据量小的表最好不要使用索引</strong>，由于数据较少，查询花费的时间可能比遍历索引的时间还要短，索引可能不会产生优化效果</li><li><strong>在条件表达式中经常用到的不同值较多的列上建立索引，在不同值很少的列上不要建立索引</strong>。比如在学生表的“性别”字段上只有“男”与“女”两个不同值，因此就无须建立索引。如果建立索引，不但不会提高查询效率，反而会严重降低数据更新速度</li><li><strong>当唯一性是某种数据本身的特征时，指定唯一索引</strong>。使用唯一索引需能确保定义的列的数据完整性，以提高查询速度</li><li><strong>在频繁进行排序或分组（即进行group by或order by操作）的列上建立索引</strong>，如果待排序的列有多个，可以在这些列上建立组合索引</li><li><strong>搜索的索引列，不一定是所要选择的列</strong>。换句话说，最适合索引的列是出现在WHERE子句中的列，或连接子句中指定的列，而不是出现在SELECT关键字后的选择列表中的列</li><li><strong>使用短索引</strong>。如果对字符串列进行索引，应该指定一个前缀长度，只要有可能就应该这样做。例如，有一个CHAR(200)列，如果在前10个或20个字符内，多数值是唯一的，那么就不要对整个列进行索引。对前10个或20个字符进行索引能够节省大量索引空间，也可能会使查询更快。较小的索引涉及的磁盘 IO 较少，较短的值比较起来更快。更为重要的是，对于较短的键值，索引高速缓存中的块能容纳更多的键值，因此，MySQL 也可以在内存中容纳更多的值。这样就增加了找到行而不用读取索引中较多块的可能性</li><li><strong>利用最左前缀</strong>。在创建一个n列的索引时，实际是创建了MySQL可利用的n个索引。多列索引可起几个索引的作用，因为可利用索引中最左边的列集来匹配行。这样的列集称为最左前缀</li><li>对于InnoDB存储引擎的表，记录默认会按照一定的顺序保存，如果有明确定义的主键，则按照主键顺序保存。如果没有主键，但是有唯一索引，那么就是按照唯一索引的顺序保存。如果既没有主键又没有唯一索引，那么表中会自动生成一个内部列，按照这个列的顺序保存。按照主键或者内部列进行的访问是最快的，所以<strong>InnoDB表尽量自己指定主键</strong>，当表中同时有几个列都是唯一的，都可以作为主键的时候，要选择最常作为访问条件的列作为主键，提高查询的效率。另外，还需要注意，InnoDB 表的普通索引都会保存主键的键值，所以主键要尽可能选择较短的数据类型，可以有效地减少索引的磁盘占用，提高索引的缓存效果</li></ul><h3 id="索引失效"><a href="#索引失效" class="headerlink" title="索引失效"></a>索引失效</h3><ul><li>使用!=、&lt;&gt; 导致索引失效</li><li>类型不一致导致的索引失效：查询时字段值类型必须与表字段类型一致，避免进行类型转换</li><li>函数导致的索引失效：避免查询语句中使用函数</li><li>运算符导致的索引失效：如果对列进行<code>+，-，*，/，!</code>运算，则索引失效</li><li>OR引起的索引失效：OR导致索引是在特定情况下的，并不是所有的OR都是使索引失效，如果OR连接的是同一个字段，那么索引不会失效，反之索引失效</li><li>模糊搜索导致的索引失效：like语句使用”xxx%”会走索引，使用”%xxx”或”%xxx%”不走索引</li><li>尽量少用is null、is not null</li></ul><h3 id="慢查询优化"><a href="#慢查询优化" class="headerlink" title="慢查询优化"></a>慢查询优化</h3><ul><li>先运行看看是否真的很慢，注意设置SQL_NO_CACHE</li><li>where条件单表查，锁定最小返回记录表。把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高</li><li>explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）</li><li>order by limit 形式的sql语句让排序的表优先查</li><li>了解业务方使用场景</li><li>加索引时参照建索引的几大原则</li><li>观察结果，不符合预期继续从0分析</li></ul><p>Read More:</p><blockquote><p><a href="https://juejin.cn/post/6844903909899632654#heading-2" target="_blank" rel="noopener">详解Mysql索引原理及其优化</a></p><p><a href="https://segmentfault.com/a/1190000023911554" target="_blank" rel="noopener">导致MySQL索引失效的几种常见写法</a></p><p><a href="https://www.cnblogs.com/zsql/p/13808417.html" target="_blank" rel="noopener">Mysql索引（一篇就够le）</a></p><p><a href="https://tech.meituan.com/2014/06/30/mysql-index.html" target="_blank" rel="noopener">MySQL索引原理及慢查询优化</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt; 索引是存储引擎用于快速找到记录的一种数据结构&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这是MySQL官方对于索引的定义，可以看到索引是一种数据结构，那么我们应该怎样理解索引呢？一个常见的例子就是书的目录。我们都已经养成了看目录的习惯，拿到一本书
      
    
    </summary>
    
      <category term="MySQL" scheme="http://runnerliu.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://runnerliu.github.io/tags/MySQL/"/>
    
      <category term="索引" scheme="http://runnerliu.github.io/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
</feed>
